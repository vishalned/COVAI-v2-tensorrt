2021-07-14 12:39:42.069977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-14 12:39:45.232516: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-07-14 12:39:45.232632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
==24337== NVPROF is profiling process 24337, command: python main.py test test
2021-07-14 12:39:45.385838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:45.386416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-07-14 12:39:45.386438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-14 12:39:45.388538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-07-14 12:39:45.389886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-07-14 12:39:45.390802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-07-14 12:39:45.391046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-07-14 12:39:45.393188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-07-14 12:39:45.393625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-07-14 12:39:45.393769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-07-14 12:39:45.393876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:45.394470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:45.395029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-07-14 12:39:45.395312: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-14 12:39:45.395500: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-07-14 12:39:45.395626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:45.396202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-07-14 12:39:45.396225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-14 12:39:45.396248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-07-14 12:39:45.396260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-07-14 12:39:45.396281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-07-14 12:39:45.396293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-07-14 12:39:45.396304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-07-14 12:39:45.396316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-07-14 12:39:45.396328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-07-14 12:39:45.396388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:45.396943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:45.397455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-07-14 12:39:45.397485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-07-14 12:39:46.655943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-14 12:39:46.655979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-07-14 12:39:46.655987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-07-14 12:39:46.656217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:46.656814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:46.657367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-14 12:39:46.657894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13926 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
2021-07-14 12:39:53.584781: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-07-14 12:39:53.655948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz
2021-07-14 12:39:54.650015: I tensorflow/compiler/tf2tensorrt/common/utils.cc:58] Linked TensorRT version: 7.1.3
2021-07-14 12:39:54.665300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libnvinfer.so.7
2021-07-14 12:39:54.665335: I tensorflow/compiler/tf2tensorrt/common/utils.cc:60] Loaded TensorRT version: 7.1.3
2021-07-14 12:39:54.666363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libnvinfer_plugin.so.7
2021-07-14 12:39:55.522995: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] TF-TRT Warning: DefaultLogger Setting layouts of network and plugin input/output tensors to linear, as 3D operators are found and 3D non-linear IO formats are not supported, yet.
2021-07-14 12:40:49.299923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-07-14 12:40:50.453227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-07-14 12:40:50.455381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-07-14 12:40:50.505852: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] TF-TRT Warning: DefaultLogger Setting layouts of network and plugin input/output tensors to linear, as 3D operators are found and 3D non-linear IO formats are not supported, yet.
2021-07-14 12:40:53.562424: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] TF-TRT Warning: DefaultLogger Setting layouts of network and plugin input/output tensors to linear, as 3D operators are found and 3D non-linear IO formats are not supported, yet.
2021-07-14 12:40:57.154401: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] TF-TRT Warning: DefaultLogger Setting layouts of network and plugin input/output tensors to linear, as 3D operators are found and 3D non-linear IO formats are not supported, yet.
2021-07-14 12:41:02.847718: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] TF-TRT Warning: DefaultLogger Setting layouts of network and plugin input/output tensors to linear, as 3D operators are found and 3D non-linear IO formats are not supported, yet.
2021-07-14 12:41:18.146464: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger ../rtSafe/safeContext.cpp (110) - cuBLAS Error in initializeCommonContext: 3 (Could not initialize cublas, please check cuda installation.)
2021-07-14 12:41:18.147416: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger ../rtSafe/safeContext.cpp (110) - cuBLAS Error in initializeCommonContext: 3 (Could not initialize cublas, please check cuda installation.)
2021-07-14 12:41:18.147504: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:758] TF-TRT Warning: Engine creation for PartitionedCall/TRTEngineOp_0_4 failed. The native segment will be used instead. Reason: Internal: Failed to build TensorRT engine
2021-07-14 12:41:18.147524: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4
processing dcm to nii
output of ggo at  /home/ubuntu/uploads/test/test/nifti
completed loading files
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.90969360e-01, 3.88059160e-03, 4.41268692e-03,
           7.37388327e-04],
          [9.95483994e-01, 2.35454249e-03, 1.69737195e-03,
           4.64121083e-04],
          [9.96633708e-01, 1.56613591e-03, 1.40545319e-03,
           3.94775881e-04],
          ...,
          [9.97906327e-01, 1.24839856e-03, 5.63786598e-04,
           2.81592249e-04],
          [9.96782184e-01, 1.88766490e-03, 1.03205862e-03,
           2.98120751e-04],
          [9.89789903e-01, 5.62301744e-03, 3.84772103e-03,
           7.39321345e-04]],

         [[9.98352289e-01, 8.11326434e-04, 6.49023976e-04,
           1.87367492e-04],
          [9.99172091e-01, 3.42863699e-04, 2.82450288e-04,
           2.02576077e-04],
          [9.99555171e-01, 1.54854570e-04, 1.72638480e-04,
           1.17262054e-04],
          ...,
          [9.99287665e-01, 3.53776326e-04, 2.23116163e-04,
           1.35415728e-04],
          [9.99279082e-01, 2.82035064e-04, 3.28375754e-04,
           1.10519199e-04],
          [9.97766614e-01, 6.94689224e-04, 1.34520116e-03,
           1.93501226e-04]],

         [[9.98976588e-01, 5.42602153e-04, 3.18202132e-04,
           1.62638025e-04],
          [9.99574840e-01, 2.07766367e-04, 1.18474432e-04,
           9.89090768e-05],
          [9.99778688e-01, 1.04307699e-04, 6.51186565e-05,
           5.19710193e-05],
          ...,
          [9.99637485e-01, 2.29922836e-04, 7.82438656e-05,
           5.43789429e-05],
          [9.99575675e-01, 2.07329314e-04, 1.53707442e-04,
           6.32243245e-05],
          [9.99029279e-01, 3.83637787e-04, 4.78033820e-04,
           1.09105727e-04]],

         ...,

         [[9.99155879e-01, 4.73781110e-04, 2.21732873e-04,
           1.48548716e-04],
          [9.99482870e-01, 2.59929628e-04, 1.33623689e-04,
           1.23520207e-04],
          [9.99690294e-01, 1.52171924e-04, 8.71975208e-05,
           7.02985708e-05],
          ...,
          [9.99603570e-01, 2.56814033e-04, 8.70152653e-05,
           5.26455224e-05],
          [9.99352515e-01, 3.54730553e-04, 2.13887179e-04,
           7.88378529e-05],
          [9.98740613e-01, 5.00596128e-04, 6.28752634e-04,
           1.29958178e-04]],

         [[9.97219324e-01, 1.54355599e-03, 8.73732031e-04,
           3.63488303e-04],
          [9.98717904e-01, 6.07722905e-04, 4.37086506e-04,
           2.37412605e-04],
          [9.99365866e-01, 3.17767437e-04, 2.13385763e-04,
           1.02989594e-04],
          ...,
          [9.99473155e-01, 3.06776172e-04, 1.55864735e-04,
           6.42324303e-05],
          [9.99003708e-01, 4.89084807e-04, 4.00185498e-04,
           1.06979736e-04],
          [9.97343481e-01, 9.25065018e-04, 1.55428459e-03,
           1.77137641e-04]],

         [[9.89263237e-01, 5.90088218e-03, 3.40875518e-03,
           1.42713671e-03],
          [9.91416633e-01, 4.81180334e-03, 2.77801440e-03,
           9.93568334e-04],
          [9.96298015e-01, 2.11407128e-03, 1.17970735e-03,
           4.08165128e-04],
          ...,
          [9.97413456e-01, 1.60538801e-03, 7.39885087e-04,
           2.41281625e-04],
          [9.96474087e-01, 2.13139877e-03, 1.09752407e-03,
           2.96934915e-04],
          [9.90250707e-01, 3.62023665e-03, 5.56868920e-03,
           5.60319051e-04]]],


        [[[9.98140812e-01, 8.48050346e-04, 7.08350970e-04,
           3.02785193e-04],
          [9.99183595e-01, 4.23703750e-04, 1.95945438e-04,
           1.96814406e-04],
          [9.99404907e-01, 3.17542348e-04, 1.46189806e-04,
           1.31451103e-04],
          ...,
          [9.99751508e-01, 1.49698230e-04, 4.12963054e-05,
           5.75614358e-05],
          [9.99641299e-01, 1.91385217e-04, 1.00912483e-04,
           6.63850151e-05],
          [9.97629225e-01, 1.36691227e-03, 6.34464377e-04,
           3.69414018e-04]],

         [[9.99612629e-01, 1.88394697e-04, 1.21604869e-04,
           7.74537766e-05],
          [9.99843478e-01, 7.52926935e-05, 3.33323551e-05,
           4.78447146e-05],
          [9.99864221e-01, 5.08892990e-05, 2.89224135e-05,
           5.59750806e-05],
          ...,
          [9.99837518e-01, 7.97434841e-05, 3.66441527e-05,
           4.61035161e-05],
          [9.99811351e-01, 7.86388046e-05, 5.79576408e-05,
           5.20091053e-05],
          [9.99686480e-01, 1.04076120e-04, 1.39950658e-04,
           6.95980707e-05]],

         [[9.99827981e-01, 8.12411017e-05, 4.81030620e-05,
           4.25850121e-05],
          [9.99903202e-01, 3.46821726e-05, 2.11776896e-05,
           4.09284221e-05],
          [9.99924779e-01, 2.52665086e-05, 1.69827817e-05,
           3.29861577e-05],
          ...,
          [9.99908090e-01, 4.14832102e-05, 1.79968429e-05,
           3.24738103e-05],
          [9.99879718e-01, 5.14065978e-05, 3.61160855e-05,
           3.27670859e-05],
          [9.99837518e-01, 5.22109476e-05, 6.03007029e-05,
           4.99279049e-05]],

         ...,

         [[9.99840021e-01, 6.55929907e-05, 4.69144106e-05,
           4.74544759e-05],
          [9.99862909e-01, 5.18988672e-05, 3.53283576e-05,
           4.99341259e-05],
          [9.99908090e-01, 3.41601481e-05, 2.24165578e-05,
           3.53021969e-05],
          ...,
          [9.99893308e-01, 5.55038168e-05, 2.35961397e-05,
           2.75555794e-05],
          [9.99757469e-01, 1.15011688e-04, 7.62415511e-05,
           5.12825063e-05],
          [9.99761403e-01, 8.78873398e-05, 8.29036726e-05,
           6.78757424e-05]],

         [[9.99658227e-01, 1.44048827e-04, 1.00073223e-04,
           9.76665906e-05],
          [9.99780238e-01, 7.34309142e-05, 7.67378733e-05,
           6.96288189e-05],
          [9.99840140e-01, 5.51305930e-05, 4.62608659e-05,
           5.84047048e-05],
          ...,
          [9.99868751e-01, 7.03212354e-05, 2.71149529e-05,
           3.37896709e-05],
          [9.99690890e-01, 1.55945527e-04, 9.43158811e-05,
           5.87905415e-05],
          [9.99656439e-01, 1.18908138e-04, 1.57305520e-04,
           6.73638351e-05]],

         [[9.98331487e-01, 6.95671712e-04, 6.85703824e-04,
           2.87215895e-04],
          [9.99097109e-01, 2.98544765e-04, 3.87807988e-04,
           2.16516768e-04],
          [9.99459922e-01, 1.99913600e-04, 2.06349054e-04,
           1.33826557e-04],
          ...,
          [9.99557555e-01, 2.08765196e-04, 1.42053847e-04,
           9.16559875e-05],
          [9.99262512e-01, 3.44001513e-04, 2.63825554e-04,
           1.29659937e-04],
          [9.97646511e-01, 5.92233089e-04, 1.45374134e-03,
           3.07451788e-04]]],


        [[[9.98616457e-01, 6.01104053e-04, 5.96757920e-04,
           1.85745550e-04],
          [9.99649525e-01, 1.57404225e-04, 1.06942680e-04,
           8.60727523e-05],
          [9.99685526e-01, 1.39159965e-04, 9.40442187e-05,
           8.12789585e-05],
          ...,
          [9.99861836e-01, 6.86894127e-05, 3.28847673e-05,
           3.66241511e-05],
          [9.99795973e-01, 8.69541109e-05, 7.16407085e-05,
           4.53890643e-05],
          [9.98587608e-01, 7.04236212e-04, 4.24204016e-04,
           2.83941772e-04]],

         [[9.99797761e-01, 1.02052662e-04, 6.82123355e-05,
           3.20337458e-05],
          [9.99919295e-01, 2.57341799e-05, 2.36277629e-05,
           3.13353885e-05],
          [9.99839544e-01, 4.68242761e-05, 5.71124183e-05,
           5.64681468e-05],
          ...,
          [9.99875069e-01, 4.44915095e-05, 3.21049483e-05,
           4.83964650e-05],
          [9.99842286e-01, 5.98649422e-05, 5.59838372e-05,
           4.19217577e-05],
          [9.99843597e-01, 4.16058101e-05, 7.10060267e-05,
           4.37171038e-05]],

         [[9.99840260e-01, 6.56835909e-05, 5.02004295e-05,
           4.38946336e-05],
          [9.99902725e-01, 2.30816731e-05, 2.42360748e-05,
           4.99459275e-05],
          [9.99838114e-01, 3.29560353e-05, 4.67631617e-05,
           8.21128488e-05],
          ...,
          [9.99899983e-01, 3.25449437e-05, 2.30338901e-05,
           4.44021643e-05],
          [9.99846458e-01, 3.90848545e-05, 5.26280382e-05,
           6.18044069e-05],
          [9.99833107e-01, 3.64234475e-05, 6.36323966e-05,
           6.67096538e-05]],

         ...,

         [[9.99825656e-01, 6.63942265e-05, 6.21844447e-05,
           4.57461501e-05],
          [9.99873281e-01, 2.94771507e-05, 3.86010761e-05,
           5.86190727e-05],
          [9.99846935e-01, 3.34973192e-05, 5.17992994e-05,
           6.77956923e-05],
          ...,
          [9.99898672e-01, 3.37972888e-05, 3.05815629e-05,
           3.69209993e-05],
          [9.99782622e-01, 6.71354137e-05, 7.75821463e-05,
           7.27611186e-05],
          [9.99738991e-01, 6.37351186e-05, 9.06712594e-05,
           1.06521467e-04]],

         [[9.99766290e-01, 8.33273589e-05, 8.20772766e-05,
           6.83084218e-05],
          [9.99835253e-01, 3.92250440e-05, 4.99539892e-05,
           7.54956418e-05],
          [9.99835491e-01, 4.29708198e-05, 5.20710091e-05,
           6.93866095e-05],
          ...,
          [9.99869108e-01, 4.82633441e-05, 3.32486306e-05,
           4.93800362e-05],
          [9.99737680e-01, 1.00908546e-04, 9.44888307e-05,
           6.68987341e-05],
          [9.99701321e-01, 8.85981863e-05, 1.23944686e-04,
           8.61089866e-05]],

         [[9.99347627e-01, 2.56603351e-04, 2.49254168e-04,
           1.46515828e-04],
          [9.99561608e-01, 1.27805877e-04, 1.62802826e-04,
           1.47689119e-04],
          [9.99677896e-01, 1.06732856e-04, 1.26658750e-04,
           8.86931593e-05],
          ...,
          [9.99727547e-01, 1.00403377e-04, 9.87687381e-05,
           7.33482448e-05],
          [9.99521255e-01, 2.03895295e-04, 1.61796837e-04,
           1.13093934e-04],
          [9.98022079e-01, 4.92896361e-04, 1.17348658e-03,
           3.11538664e-04]]],


        ...,


        [[[9.99219537e-01, 3.93745140e-04, 2.64899281e-04,
           1.21732221e-04],
          [9.99803841e-01, 9.56311196e-05, 4.29995453e-05,
           5.76066268e-05],
          [9.99816120e-01, 9.56781805e-05, 3.97907970e-05,
           4.83625154e-05],
          ...,
          [9.99806583e-01, 1.17670570e-04, 2.98453069e-05,
           4.60105512e-05],
          [9.99777734e-01, 1.30299741e-04, 5.03305491e-05,
           4.16700168e-05],
          [9.98107672e-01, 1.04508991e-03, 5.30740654e-04,
           3.16494174e-04]],

         [[9.99779403e-01, 1.14590614e-04, 5.89784286e-05,
           4.70642772e-05],
          [9.99875069e-01, 4.88046608e-05, 2.78625012e-05,
           4.83175172e-05],
          [9.99897361e-01, 3.57331082e-05, 2.45911815e-05,
           4.23187339e-05],
          ...,
          [9.99829173e-01, 8.96658239e-05, 2.97550650e-05,
           5.14367603e-05],
          [9.99860168e-01, 7.46370933e-05, 3.73213006e-05,
           2.78907191e-05],
          [9.99865770e-01, 4.50858752e-05, 5.95297060e-05,
           2.96433700e-05]],

         [[9.99819577e-01, 8.40369685e-05, 4.84685079e-05,
           4.79233859e-05],
          [9.99882698e-01, 3.06434631e-05, 2.28173976e-05,
           6.38131314e-05],
          [9.99907136e-01, 2.46393593e-05, 1.80104580e-05,
           5.01429713e-05],
          ...,
          [9.99879241e-01, 5.19434907e-05, 2.16281514e-05,
           4.71304302e-05],
          [9.99845862e-01, 6.44321262e-05, 3.94166309e-05,
           5.02214425e-05],
          [9.99849916e-01, 3.56039200e-05, 6.15156023e-05,
           5.29638528e-05]],

         ...,

         [[9.98147845e-01, 1.09975552e-03, 6.07724243e-04,
           1.44615857e-04],
          [9.98636782e-01, 7.52970984e-04, 5.21153852e-04,
           8.90444935e-05],
          [9.99378324e-01, 3.19837302e-04, 2.57900509e-04,
           4.38565730e-05],
          ...,
          [9.92628574e-01, 5.47910016e-03, 1.76006008e-03,
           1.32326924e-04],
          [9.92397368e-01, 3.83586413e-03, 3.72250867e-03,
           4.42546007e-05],
          [9.87487793e-01, 5.69526991e-03, 6.55002892e-03,
           2.66850111e-04]],

         [[9.91954029e-01, 4.02177591e-03, 3.64276371e-03,
           3.81396472e-04],
          [9.96816576e-01, 1.82910007e-03, 1.19603309e-03,
           1.58304480e-04],
          [9.97274578e-01, 1.26234652e-03, 1.37240055e-03,
           9.07372596e-05],
          ...,
          [9.80878115e-01, 1.18959574e-02, 7.05386745e-03,
           1.72031287e-04],
          [9.84599531e-01, 8.05631280e-03, 7.25846924e-03,
           8.57298510e-05],
          [9.65641856e-01, 1.49798337e-02, 1.87559612e-02,
           6.22333202e-04]],

         [[9.86004651e-01, 7.66551169e-03, 5.42353000e-03,
           9.06280591e-04],
          [9.92352307e-01, 3.03810672e-03, 4.11254028e-03,
           4.97006753e-04],
          [9.94638145e-01, 2.71502393e-03, 2.41743634e-03,
           2.29440455e-04],
          ...,
          [9.88713384e-01, 6.48948178e-03, 4.46203630e-03,
           3.35188030e-04],
          [9.87415969e-01, 5.09567698e-03, 7.24183396e-03,
           2.46629817e-04],
          [9.68962312e-01, 1.19851753e-02, 1.82618108e-02,
           7.90745544e-04]]],


        [[[9.97684479e-01, 1.23465166e-03, 7.95992091e-04,
           2.84852547e-04],
          [9.99319553e-01, 4.13673493e-04, 1.40528966e-04,
           1.26156898e-04],
          [9.99568999e-01, 2.91875011e-04, 7.48895254e-05,
           6.42827799e-05],
          ...,
          [9.99570787e-01, 3.25437111e-04, 5.87388713e-05,
           4.50664265e-05],
          [9.99311924e-01, 4.81764757e-04, 1.61689852e-04,
           4.46042759e-05],
          [9.97523963e-01, 1.60132337e-03, 6.33955293e-04,
           2.40730049e-04]],

         [[9.99561846e-01, 2.22248986e-04, 1.36108240e-04,
           7.97796092e-05],
          [9.99827623e-01, 8.05804157e-05, 3.69864574e-05,
           5.47904201e-05],
          [9.99898314e-01, 4.73403488e-05, 2.76195424e-05,
           2.67392115e-05],
          ...,
          [9.99849796e-01, 1.01061349e-04, 2.40592017e-05,
           2.50993162e-05],
          [9.99714911e-01, 2.01202434e-04, 6.06417234e-05,
           2.32379807e-05],
          [9.99731243e-01, 1.24952698e-04, 1.18272590e-04,
           2.55551768e-05]],

         [[9.99676824e-01, 1.42700024e-04, 1.00985482e-04,
           7.95728192e-05],
          [9.99880910e-01, 4.37573617e-05, 2.39773508e-05,
           5.13539417e-05],
          [9.99916196e-01, 3.07002447e-05, 2.00943105e-05,
           3.29666291e-05],
          ...,
          [9.99856353e-01, 7.81410854e-05, 2.63809052e-05,
           3.91106732e-05],
          [9.99789059e-01, 1.20802797e-04, 5.40376896e-05,
           3.60235499e-05],
          [9.99854565e-01, 6.05469213e-05, 5.65198570e-05,
           2.83998907e-05]],

         ...,

         [[9.95044589e-01, 2.79108807e-03, 1.85081339e-03,
           3.13461816e-04],
          [9.98873532e-01, 6.70133042e-04, 3.67738452e-04,
           8.85020345e-05],
          [9.98935163e-01, 5.07904741e-04, 4.70923987e-04,
           8.60546425e-05],
          ...,
          [9.93232489e-01, 4.22809087e-03, 2.27710628e-03,
           2.62370304e-04],
          [9.85339046e-01, 5.86561766e-03, 8.68670829e-03,
           1.08645072e-04],
          [9.64635134e-01, 1.40020158e-02, 2.03354079e-02,
           1.02738990e-03]],

         [[9.84070539e-01, 7.88356643e-03, 7.09816441e-03,
           9.47730616e-04],
          [9.98518646e-01, 7.32919434e-04, 6.04359899e-04,
           1.44176214e-04],
          [9.97803032e-01, 1.06662977e-03, 9.56067757e-04,
           1.74343339e-04],
          ...,
          [9.78772163e-01, 9.38029308e-03, 1.13591915e-02,
           4.88348713e-04],
          [9.62676585e-01, 1.99132599e-02, 1.69552155e-02,
           4.54891502e-04],
          [9.54478145e-01, 1.72766261e-02, 2.72716545e-02,
           9.73484130e-04]],

         [[9.82780993e-01, 7.53620965e-03, 8.30189604e-03,
           1.38092064e-03],
          [9.92929518e-01, 2.08720658e-03, 4.31233412e-03,
           6.71005342e-04],
          [9.92770016e-01, 2.24607065e-03, 4.34644241e-03,
           6.37371209e-04],
          ...,
          [9.74440813e-01, 1.09303165e-02, 1.32030444e-02,
           1.42591773e-03],
          [9.71790910e-01, 1.14718089e-02, 1.58943143e-02,
           8.42907000e-04],
          [9.54998672e-01, 1.84329040e-02, 2.45243702e-02,
           2.04404327e-03]]],


        [[[9.90227222e-01, 5.99350641e-03, 2.79796403e-03,
           9.81348101e-04],
          [9.98001873e-01, 8.74505204e-04, 8.79175146e-04,
           2.44407769e-04],
          [9.98234034e-01, 9.05682275e-04, 6.66914042e-04,
           1.93304091e-04],
          ...,
          [9.98337030e-01, 9.13614931e-04, 6.14485587e-04,
           1.34759743e-04],
          [9.97943580e-01, 9.98269534e-04, 9.26586159e-04,
           1.31608991e-04],
          [9.93036687e-01, 3.39898467e-03, 2.81368149e-03,
           7.50655658e-04]],

         [[9.96065319e-01, 2.38064420e-03, 1.13545207e-03,
           4.18586336e-04],
          [9.98890936e-01, 5.43533883e-04, 3.68855981e-04,
           1.96685098e-04],
          [9.99638677e-01, 1.83787692e-04, 1.20057797e-04,
           5.75109370e-05],
          ...,
          [9.99479830e-01, 3.13966681e-04, 1.52893190e-04,
           5.33228704e-05],
          [9.98781264e-01, 6.73314673e-04, 4.70363302e-04,
           7.50955951e-05],
          [9.98247027e-01, 7.10915192e-04, 9.06177855e-04,
           1.35934519e-04]],

         [[9.98287857e-01, 8.56191386e-04, 5.57535561e-04,
           2.98404251e-04],
          [9.99682069e-01, 1.14638584e-04, 9.82245110e-05,
           1.05096602e-04],
          [9.99838591e-01, 6.50481379e-05, 4.92745712e-05,
           4.70456616e-05],
          ...,
          [9.99719441e-01, 1.36930990e-04, 8.10614147e-05,
           6.25283283e-05],
          [9.99456584e-01, 2.83029600e-04, 1.83246011e-04,
           7.70844053e-05],
          [9.98415947e-01, 6.81679405e-04, 7.00085424e-04,
           2.02312192e-04]],

         ...,

         [[9.89113331e-01, 5.47944801e-03, 4.69202315e-03,
           7.15198810e-04],
          [9.97554958e-01, 6.98310614e-04, 1.59555429e-03,
           1.51202272e-04],
          [9.96634781e-01, 9.90980770e-04, 2.20770552e-03,
           1.66532525e-04],
          ...,
          [9.81841445e-01, 6.16683951e-03, 1.13430135e-02,
           6.48626185e-04],
          [9.73056734e-01, 7.38061685e-03, 1.90185644e-02,
           5.44123526e-04],
          [9.65777695e-01, 1.18641537e-02, 2.03434415e-02,
           2.01478251e-03]],

         [[9.82167840e-01, 9.57159977e-03, 7.12918490e-03,
           1.13145018e-03],
          [9.95319426e-01, 1.93514896e-03, 2.36308877e-03,
           3.82256374e-04],
          [9.95950937e-01, 1.42072828e-03, 2.37082574e-03,
           2.57508713e-04],
          ...,
          [9.72458065e-01, 8.26925505e-03, 1.83334686e-02,
           9.39239690e-04],
          [9.50311422e-01, 1.52129736e-02, 3.34487781e-02,
           1.02689385e-03],
          [9.57001567e-01, 1.37144690e-02, 2.78225262e-02,
           1.46139564e-03]],

         [[9.86690044e-01, 5.29590435e-03, 7.17763091e-03,
           8.36305553e-04],
          [9.91934299e-01, 2.30977079e-03, 5.08053880e-03,
           6.75425399e-04],
          [9.91462290e-01, 2.71540834e-03, 5.27004478e-03,
           5.52225043e-04],
          ...,
          [9.58498895e-01, 1.27189169e-02, 2.68267095e-02,
           1.95538322e-03],
          [9.68751729e-01, 9.19515174e-03, 2.11049374e-02,
           9.48155182e-04],
          [9.39124465e-01, 2.62798090e-02, 3.21452469e-02,
           2.45047384e-03]]]]], dtype=float32)>}2021-07-14 12:41:19.579593: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.91193950e-01, 3.74337262e-03, 4.33740951e-03,
           7.25287362e-04],
          [9.95526731e-01, 2.27012951e-03, 1.73905655e-03,
           4.64095909e-04],
          [9.96700943e-01, 1.47930929e-03, 1.42561761e-03,
           3.94196250e-04],
          ...,
          [9.97891366e-01, 1.24564103e-03, 5.77871280e-04,
           2.85161455e-04],
          [9.96779978e-01, 1.87284756e-03, 1.04656874e-03,
           3.00721149e-04],
          [9.89740729e-01, 5.61613264e-03, 3.89847113e-03,
           7.44697172e-04]],

         [[9.98357236e-01, 7.94027583e-04, 6.58454665e-04,
           1.90237028e-04],
          [9.99173343e-01, 3.29496630e-04, 2.90674390e-04,
           2.06505822e-04],
          [9.99546468e-01, 1.49878353e-04, 1.81750700e-04,
           1.21861965e-04],
          ...,
          [9.99285638e-01, 3.49228096e-04, 2.28535078e-04,
           1.36578703e-04],
          [9.99273956e-01, 2.78794032e-04, 3.35675257e-04,
           1.11632049e-04],
          [9.97724712e-01, 6.97223877e-04, 1.38101354e-03,
           1.97077345e-04]],

         [[9.99008238e-01, 5.19729627e-04, 3.10528820e-04,
           1.61495729e-04],
          [9.99585330e-01, 1.94897570e-04, 1.20751807e-04,
           9.89495529e-05],
          [9.99772608e-01, 1.01506150e-04, 7.00815071e-05,
           5.57388776e-05],
          ...,
          [9.99637127e-01, 2.27649260e-04, 8.02056747e-05,
           5.50541517e-05],
          [9.99574959e-01, 2.04530836e-04, 1.56338414e-04,
           6.41803053e-05],
          [9.99008596e-01, 3.88314656e-04, 4.91176208e-04,
           1.11851426e-04]],

         ...,

         [[9.99111593e-01, 5.03975316e-04, 2.33317245e-04,
           1.51202272e-04],
          [9.99464214e-01, 2.77230720e-04, 1.37917741e-04,
           1.20656601e-04],
          [9.99676824e-01, 1.63362391e-04, 8.96654092e-05,
           7.01824756e-05],
          ...,
          [9.99605954e-01, 2.56659172e-04, 8.60012151e-05,
           5.14317508e-05],
          [9.99351203e-01, 3.60603677e-04, 2.11453298e-04,
           7.67492820e-05],
          [9.98745322e-01, 5.06720215e-04, 6.21473591e-04,
           1.26482075e-04]],

         [[9.97096777e-01, 1.63447764e-03, 9.07161972e-04,
           3.61543847e-04],
          [9.98685300e-01, 6.47679903e-04, 4.40349046e-04,
           2.26715492e-04],
          [9.99355853e-01, 3.35574732e-04, 2.10243757e-04,
           9.82868951e-05],
          ...,
          [9.99473035e-01, 3.12846998e-04, 1.51656190e-04,
           6.24036184e-05],
          [9.99012113e-01, 4.96131193e-04, 3.87089793e-04,
           1.04647654e-04],
          [9.97328401e-01, 9.42580693e-04, 1.55436783e-03,
           1.74655055e-04]],

         [[9.88947988e-01, 6.14765426e-03, 3.49200610e-03,
           1.41232705e-03],
          [9.91160870e-01, 5.05638588e-03, 2.82973703e-03,
           9.53044102e-04],
          [9.96250808e-01, 2.20165239e-03, 1.15368993e-03,
           3.93957744e-04],
          ...,
          [9.97459471e-01, 1.59500528e-03, 7.14235881e-04,
           2.31349637e-04],
          [9.96504188e-01, 2.13853014e-03, 1.06933853e-03,
           2.87959992e-04],
          [9.90298569e-01, 3.63640883e-03, 5.51400986e-03,
           5.51097386e-04]]],


        [[[9.98172402e-01, 8.14764120e-04, 7.10419554e-04,
           3.02397151e-04],
          [9.99216795e-01, 3.90727771e-04, 1.97126399e-04,
           1.95349086e-04],
          [9.99425173e-01, 2.94051744e-04, 1.48545252e-04,
           1.32226545e-04],
          ...,
          [9.99753058e-01, 1.46673294e-04, 4.21445729e-05,
           5.81102213e-05],
          [9.99642730e-01, 1.87460886e-04, 1.02331731e-04,
           6.75132105e-05],
          [9.97635841e-01, 1.34854089e-03, 6.42123574e-04,
           3.73463030e-04]],

         [[9.99623537e-01, 1.77954702e-04, 1.21081735e-04,
           7.74696964e-05],
          [9.99847531e-01, 6.94191549e-05, 3.45459594e-05,
           4.84813318e-05],
          [9.99864340e-01, 4.72161919e-05, 3.05017275e-05,
           5.79255648e-05],
          ...,
          [9.99837041e-01, 7.81498602e-05, 3.77382567e-05,
           4.70190789e-05],
          [9.99810398e-01, 7.73981374e-05, 5.92046017e-05,
           5.31273799e-05],
          [9.99679685e-01, 1.03663537e-04, 1.45133818e-04,
           7.15334609e-05]],

         [[9.99834657e-01, 7.56771697e-05, 4.72710162e-05,
           4.23208876e-05],
          [9.99902368e-01, 3.25607944e-05, 2.24952601e-05,
           4.26056104e-05],
          [9.99920249e-01, 2.45091451e-05, 1.91176732e-05,
           3.60434642e-05],
          ...,
          [9.99907732e-01, 4.11985056e-05, 1.83568682e-05,
           3.27160706e-05],
          [9.99877930e-01, 5.07524928e-05, 3.74178308e-05,
           3.38452264e-05],
          [9.99833941e-01, 5.23664457e-05, 6.23157539e-05,
           5.13762170e-05]],

         ...,

         [[9.99832988e-01, 7.00756427e-05, 4.92436156e-05,
           4.76820060e-05],
          [9.99856949e-01, 5.68300129e-05, 3.69301633e-05,
           4.92958752e-05],
          [9.99900103e-01, 3.93030059e-05, 2.50064895e-05,
           3.55699012e-05],
          ...,
          [9.99895215e-01, 5.47799609e-05, 2.32419279e-05,
           2.67135892e-05],
          [9.99753416e-01, 1.19396049e-04, 7.68181853e-05,
           5.03900810e-05],
          [9.99761045e-01, 9.02589600e-05, 8.25007010e-05,
           6.62717648e-05]],

         [[9.99624729e-01, 1.65027755e-04, 1.10661655e-04,
           9.95905939e-05],
          [9.99779165e-01, 7.98682158e-05, 7.62942655e-05,
           6.46835688e-05],
          [9.99839544e-01, 6.01599240e-05, 4.59916300e-05,
           5.42498092e-05],
          ...,
          [9.99870062e-01, 7.11419125e-05, 2.62641352e-05,
           3.25195870e-05],
          [9.99683380e-01, 1.65018850e-04, 9.33457050e-05,
           5.82873217e-05],
          [9.99655962e-01, 1.22008008e-04, 1.55718502e-04,
           6.62618913e-05]],

         [[9.98149157e-01, 7.89302750e-04, 7.62654934e-04,
           2.98992556e-04],
          [9.99033689e-01, 3.40688595e-04, 4.13757691e-04,
           2.11812105e-04],
          [9.99431789e-01, 2.22180257e-04, 2.15715292e-04,
           1.30246844e-04],
          ...,
          [9.99565661e-01, 2.09762948e-04, 1.36569826e-04,
           8.80785374e-05],
          [9.99270141e-01, 3.48660775e-04, 2.56350642e-04,
           1.24868151e-04],
          [9.97667313e-01, 5.96570317e-04, 1.43643189e-03,
           2.99779087e-04]]],


        [[[9.98662233e-01, 5.66142262e-04, 5.87436254e-04,
           1.84070843e-04],
          [9.99665976e-01, 1.42531862e-04, 1.06593761e-04,
           8.49278076e-05],
          [9.99698758e-01, 1.25520717e-04, 9.50324320e-05,
           8.07523247e-05],
          ...,
          [9.99862909e-01, 6.69052606e-05, 3.32808777e-05,
           3.69688605e-05],
          [9.99798357e-01, 8.44352471e-05, 7.16700524e-05,
           4.56672715e-05],
          [9.98584747e-01, 6.97628246e-04, 4.30180051e-04,
           2.87468836e-04]],

         [[9.99802411e-01, 9.68412423e-05, 6.82216923e-05,
           3.25001456e-05],
          [9.99918103e-01, 2.40369936e-05, 2.52824193e-05,
           3.25200344e-05],
          [9.99835849e-01, 4.41335724e-05, 6.09276794e-05,
           5.90734599e-05],
          ...,
          [9.99876142e-01, 4.32749257e-05, 3.24287939e-05,
           4.81669376e-05],
          [9.99842405e-01, 5.80903688e-05, 5.70980446e-05,
           4.24747777e-05],
          [9.99839187e-01, 4.17306037e-05, 7.38683448e-05,
           4.52083732e-05]],

         [[9.99842763e-01, 6.21037907e-05, 5.09844358e-05,
           4.41691554e-05],
          [9.99900937e-01, 2.15039217e-05, 2.55261930e-05,
           5.20825670e-05],
          [9.99843121e-01, 2.96247781e-05, 4.66389538e-05,
           8.05566087e-05],
          ...,
          [9.99899983e-01, 3.22346023e-05, 2.33420669e-05,
           4.44809084e-05],
          [9.99845147e-01, 3.81306090e-05, 5.39559624e-05,
           6.26984474e-05],
          [9.99829412e-01, 3.67996981e-05, 6.53653042e-05,
           6.83807884e-05]],

         ...,

         [[9.99818504e-01, 7.17196381e-05, 6.47269699e-05,
           4.49987347e-05],
          [9.99868870e-01, 3.27812595e-05, 4.11100518e-05,
           5.71771998e-05],
          [9.99838233e-01, 3.85205858e-05, 5.55889055e-05,
           6.76285636e-05],
          ...,
          [9.99897838e-01, 3.40577208e-05, 3.07117771e-05,
           3.73487710e-05],
          [9.99780118e-01, 6.88324508e-05, 7.85294760e-05,
           7.24991769e-05],
          [9.99738514e-01, 6.46408516e-05, 9.10880044e-05,
           1.05746200e-04]],

         [[9.99757588e-01, 9.06872956e-05, 8.43815797e-05,
           6.72985989e-05],
          [9.99838114e-01, 4.27695741e-05, 5.00006499e-05,
           6.90241941e-05],
          [9.99827623e-01, 4.88385194e-05, 5.39515204e-05,
           6.95274866e-05],
          ...,
          [9.99867678e-01, 4.98927147e-05, 3.29009563e-05,
           4.94028100e-05],
          [9.99734581e-01, 1.04270774e-04, 9.37382138e-05,
           6.73572795e-05],
          [9.99699593e-01, 9.18261576e-05, 1.23090678e-04,
           8.54036916e-05]],

         [[9.99322891e-01, 2.75557919e-04, 2.56983214e-04,
           1.44646561e-04],
          [9.99556124e-01, 1.39537427e-04, 1.63508361e-04,
           1.40792326e-04],
          [9.99667048e-01, 1.17380252e-04, 1.28942323e-04,
           8.66161645e-05],
          ...,
          [9.99730766e-01, 1.01619880e-04, 9.54502902e-05,
           7.20826501e-05],
          [9.99523878e-01, 2.06398472e-04, 1.58838753e-04,
           1.10890498e-04],
          [9.98035848e-01, 4.95961925e-04, 1.15980103e-03,
           3.08371527e-04]]],


        ...,


        [[[9.99005020e-01, 3.21594212e-04, 5.45479474e-04,
           1.27987238e-04],
          [9.99798954e-01, 7.51941261e-05, 9.22368417e-05,
           3.36111625e-05],
          [9.99823391e-01, 7.80628325e-05, 6.76605196e-05,
           3.08587696e-05],
          ...,
          [9.99871135e-01, 5.02549083e-05, 4.80727576e-05,
           3.04343212e-05],
          [9.99826372e-01, 6.09240742e-05, 8.04609735e-05,
           3.22408996e-05],
          [9.99355972e-01, 2.77671148e-04, 2.68261734e-04,
           9.80562254e-05]],

         [[9.99773681e-01, 6.89277149e-05, 1.27007166e-04,
           3.04362875e-05],
          [9.99897838e-01, 3.80940910e-05, 4.26368351e-05,
           2.13278654e-05],
          [9.99915957e-01, 3.35352051e-05, 2.98695286e-05,
           2.06805671e-05],
          ...,
          [9.99935627e-01, 1.99048482e-05, 2.15430136e-05,
           2.28915796e-05],
          [9.99896646e-01, 2.73871865e-05, 4.52273161e-05,
           3.07501869e-05],
          [9.99879718e-01, 3.70775961e-05, 5.62950154e-05,
           2.68437507e-05]],

         [[9.99860287e-01, 5.46669435e-05, 6.22255247e-05,
           2.27081073e-05],
          [9.99865174e-01, 5.87213290e-05, 4.50683110e-05,
           3.09761454e-05],
          [9.99882698e-01, 4.75519555e-05, 4.31340850e-05,
           2.65357467e-05],
          ...,
          [9.99913931e-01, 3.21949592e-05, 2.47259868e-05,
           2.91269171e-05],
          [9.99856591e-01, 5.04798409e-05, 4.94640226e-05,
           4.34392641e-05],
          [9.99922514e-01, 2.85391252e-05, 3.28933784e-05,
           1.60595537e-05]],

         ...,

         [[9.99812782e-01, 7.42310658e-05, 5.81041604e-05,
           5.48434509e-05],
          [9.99891281e-01, 2.48412871e-05, 2.68261992e-05,
           5.70409611e-05],
          [9.99865651e-01, 3.08805684e-05, 3.44158725e-05,
           6.89912122e-05],
          ...,
          [9.99890327e-01, 3.64596635e-05, 3.03570723e-05,
           4.27808227e-05],
          [9.99816120e-01, 5.42729103e-05, 6.25437387e-05,
           6.71710877e-05],
          [9.99723136e-01, 5.88782314e-05, 1.10874324e-04,
           1.07080785e-04]],

         [[9.99733865e-01, 1.10841895e-04, 7.58289025e-05,
           7.94622465e-05],
          [9.99807656e-01, 5.42164271e-05, 4.42958408e-05,
           9.38668163e-05],
          [9.99879003e-01, 3.34407778e-05, 3.21542575e-05,
           5.53758146e-05],
          ...,
          [9.99884725e-01, 4.24459213e-05, 2.82176243e-05,
           4.45587320e-05],
          [9.99822438e-01, 6.94557457e-05, 6.04658671e-05,
           4.76605856e-05],
          [9.99688148e-01, 7.72207350e-05, 1.49399362e-04,
           8.52976373e-05]],

         [[9.99438345e-01, 2.55746651e-04, 1.76761532e-04,
           1.29060427e-04],
          [9.99702394e-01, 1.01114791e-04, 9.22384061e-05,
           1.04297767e-04],
          [9.99804199e-01, 6.69888686e-05, 6.88844157e-05,
           5.98990882e-05],
          ...,
          [9.99747217e-01, 9.79254401e-05, 8.77752755e-05,
           6.70933441e-05],
          [9.99602377e-01, 1.40562974e-04, 1.56761482e-04,
           1.00284298e-04],
          [9.97475922e-01, 6.64638006e-04, 1.51175517e-03,
           3.47725902e-04]]],


        [[[9.99087334e-01, 2.98124185e-04, 4.89740516e-04,
           1.24803992e-04],
          [9.99747932e-01, 9.94657967e-05, 1.16124065e-04,
           3.63885083e-05],
          [9.99813378e-01, 8.88523209e-05, 6.83773396e-05,
           2.94385845e-05],
          ...,
          [9.99830842e-01, 6.17709666e-05, 7.21055476e-05,
           3.52840907e-05],
          [9.99729335e-01, 9.71977788e-05, 1.33940805e-04,
           3.94233866e-05],
          [9.99135554e-01, 3.74153577e-04, 3.71332892e-04,
           1.19049124e-04]],

         [[9.99686122e-01, 9.48791785e-05, 1.85198718e-04,
           3.38002865e-05],
          [9.99890447e-01, 4.11391775e-05, 4.84605334e-05,
           2.00006270e-05],
          [9.99908566e-01, 3.67210632e-05, 3.45981171e-05,
           2.00701033e-05],
          ...,
          [9.99914169e-01, 3.35039804e-05, 2.90444295e-05,
           2.33370993e-05],
          [9.99861360e-01, 5.01567920e-05, 5.68645846e-05,
           3.16260703e-05],
          [9.99780595e-01, 7.67957317e-05, 1.06330306e-04,
           3.62754618e-05]],

         [[9.99816120e-01, 6.88654618e-05, 9.22483669e-05,
           2.27863256e-05],
          [9.99921441e-01, 3.58426732e-05, 2.55005580e-05,
           1.71189768e-05],
          [9.99908209e-01, 3.84484811e-05, 3.21581065e-05,
           2.11451224e-05],
          ...,
          [9.99906182e-01, 3.99318487e-05, 2.80156728e-05,
           2.58939090e-05],
          [9.99858856e-01, 5.18982124e-05, 5.41833797e-05,
           3.51255330e-05],
          [9.99836206e-01, 5.87702161e-05, 8.13326187e-05,
           2.37151926e-05]],

         ...,

         [[9.99685287e-01, 1.18252152e-04, 1.14841176e-04,
           8.17232940e-05],
          [9.99884009e-01, 3.50511909e-05, 3.10570103e-05,
           4.98385998e-05],
          [9.99887705e-01, 2.91914748e-05, 4.02247242e-05,
           4.28598105e-05],
          ...,
          [9.99901056e-01, 3.60961603e-05, 3.32499476e-05,
           2.95306436e-05],
          [9.99851584e-01, 7.25258069e-05, 4.89467493e-05,
           2.70290566e-05],
          [9.99707878e-01, 1.07211577e-04, 1.26430459e-04,
           5.84605550e-05]],

         [[9.99521136e-01, 2.15923923e-04, 1.57223942e-04,
           1.05756677e-04],
          [9.99866486e-01, 5.59269138e-05, 3.04693185e-05,
           4.70771774e-05],
          [9.99929190e-01, 2.89051004e-05, 1.90212941e-05,
           2.29664329e-05],
          ...,
          [9.99937773e-01, 2.63476268e-05, 1.86086309e-05,
           1.72545751e-05],
          [9.99849558e-01, 7.10716195e-05, 5.54994840e-05,
           2.38563280e-05],
          [9.99110639e-01, 3.33865901e-04, 4.36706003e-04,
           1.18822260e-04]],

         [[9.98686254e-01, 5.77285420e-04, 5.20404079e-04,
           2.16071770e-04],
          [9.99351680e-01, 1.87992729e-04, 2.50180135e-04,
           2.10198996e-04],
          [9.99619246e-01, 1.15179078e-04, 1.64164463e-04,
           1.01328696e-04],
          ...,
          [9.99555528e-01, 1.43236510e-04, 1.84283112e-04,
           1.16936120e-04],
          [9.99004543e-01, 3.17934988e-04, 5.12609724e-04,
           1.64844067e-04],
          [9.94376779e-01, 1.56678306e-03, 3.40435049e-03,
           6.52221148e-04]]],


        [[[9.96080816e-01, 1.42406079e-03, 2.01851246e-03,
           4.76614572e-04],
          [9.98827994e-01, 3.45283479e-04, 7.28073996e-04,
           9.86043233e-05],
          [9.98982966e-01, 3.97459837e-04, 5.19471127e-04,
           1.00055600e-04],
          ...,
          [9.98951674e-01, 3.61161481e-04, 5.68397867e-04,
           1.18746939e-04],
          [9.98547018e-01, 4.45419428e-04, 8.63972993e-04,
           1.43575075e-04],
          [9.95993733e-01, 1.76217698e-03, 1.68179360e-03,
           5.62183093e-04]],

         [[9.98046279e-01, 6.89474633e-04, 1.05365145e-03,
           2.10620870e-04],
          [9.99589026e-01, 1.34918184e-04, 2.13583276e-04,
           6.25179673e-05],
          [9.99818265e-01, 8.23645387e-05, 6.72949900e-05,
           3.20564068e-05],
          ...,
          [9.99759018e-01, 6.40260114e-05, 1.17661730e-04,
           5.93534605e-05],
          [9.99722779e-01, 8.96402053e-05, 1.41173747e-04,
           4.63830984e-05],
          [9.99052465e-01, 2.70995457e-04, 5.15719177e-04,
           1.60841024e-04]],

         [[9.98441637e-01, 6.36485813e-04, 7.42036442e-04,
           1.79844981e-04],
          [9.99799907e-01, 8.30923236e-05, 7.76556553e-05,
           3.94201561e-05],
          [9.99902010e-01, 4.26351471e-05, 3.27656853e-05,
           2.25231579e-05],
          ...,
          [9.99857783e-01, 5.11376675e-05, 5.21645743e-05,
           3.89561683e-05],
          [9.99776304e-01, 8.55739563e-05, 8.97233476e-05,
           4.83716613e-05],
          [9.99430239e-01, 1.95363435e-04, 2.65555165e-04,
           1.08736022e-04]],

         ...,

         [[9.98626590e-01, 5.76499093e-04, 5.50797500e-04,
           2.46044860e-04],
          [9.99695182e-01, 9.21273240e-05, 1.21536759e-04,
           9.11919124e-05],
          [9.99803483e-01, 5.42558191e-05, 8.40724970e-05,
           5.82860448e-05],
          ...,
          [9.99733865e-01, 8.59585925e-05, 1.16302414e-04,
           6.39069112e-05],
          [9.99383092e-01, 2.09987615e-04, 3.01977532e-04,
           1.04914376e-04],
          [9.97909963e-01, 7.30891130e-04, 1.03837042e-03,
           3.20693507e-04]],

         [[9.97921884e-01, 9.87528125e-04, 7.52579770e-04,
           3.38092272e-04],
          [9.99559939e-01, 1.46526421e-04, 1.48752573e-04,
           1.44706399e-04],
          [9.99788225e-01, 7.16921641e-05, 7.27342558e-05,
           6.73386021e-05],
          ...,
          [9.99701917e-01, 1.05666215e-04, 1.12096124e-04,
           8.02660434e-05],
          [9.98622775e-01, 5.53502759e-04, 6.18001272e-04,
           2.05678763e-04],
          [9.96991992e-01, 9.66484484e-04, 1.72089797e-03,
           3.20619816e-04]],

         [[9.96229708e-01, 1.52962364e-03, 1.75545982e-03,
           4.85192839e-04],
          [9.98152673e-01, 5.45692863e-04, 9.46546730e-04,
           3.55075928e-04],
          [9.98951197e-01, 2.77294632e-04, 5.70397766e-04,
           2.01048737e-04],
          ...,
          [9.97583270e-01, 6.50166941e-04, 1.38990954e-03,
           3.76682176e-04],
          [9.96197343e-01, 1.14053907e-03, 2.12174631e-03,
           5.40418259e-04],
          [9.89017367e-01, 4.23489278e-03, 5.63854072e-03,
           1.10923627e-03]]]]], dtype=float32)>}2021-07-14 12:41:19.876523: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.91192281e-01, 3.99840903e-03, 4.09933459e-03,
           7.09953369e-04],
          [9.95914280e-01, 2.28783977e-03, 1.37314387e-03,
           4.24630474e-04],
          [9.97102201e-01, 1.46650989e-03, 1.09000679e-03,
           3.41200008e-04],
          ...,
          [9.97934580e-01, 1.26870407e-03, 5.31993981e-04,
           2.64742353e-04],
          [9.96811092e-01, 1.90212694e-03, 9.97671275e-04,
           2.89155665e-04],
          [9.89967585e-01, 5.57807600e-03, 3.74067761e-03,
           7.13792862e-04]],

         [[9.98415947e-01, 8.39106389e-04, 5.69909462e-04,
           1.75084118e-04],
          [9.99231815e-01, 3.63234285e-04, 2.28652905e-04,
           1.76377667e-04],
          [9.99638915e-01, 1.49439176e-04, 1.21259829e-04,
           9.04146218e-05],
          ...,
          [9.99256432e-01, 3.86323984e-04, 2.23316529e-04,
           1.33962370e-04],
          [9.99275982e-01, 2.93631805e-04, 3.18355189e-04,
           1.11984897e-04],
          [9.97673213e-01, 7.45059806e-04, 1.38331356e-03,
           1.98410038e-04]],

         [[9.98965502e-01, 5.82977838e-04, 2.96026585e-04,
           1.55603091e-04],
          [9.99597132e-01, 2.21271286e-04, 9.60839170e-05,
           8.55520120e-05],
          [9.99803245e-01, 1.04853440e-04, 4.96544453e-05,
           4.21839613e-05],
          ...,
          [9.99637127e-01, 2.33130515e-04, 7.56647423e-05,
           5.41386726e-05],
          [9.99568045e-01, 2.10433864e-04, 1.57061673e-04,
           6.44327738e-05],
          [9.98985946e-01, 3.94931209e-04, 5.04844589e-04,
           1.14238661e-04]],

         ...,

         [[9.99109805e-01, 5.04628522e-04, 2.34071238e-04,
           1.51490662e-04],
          [9.99463856e-01, 2.77095853e-04, 1.38260613e-04,
           1.20815006e-04],
          [9.99676466e-01, 1.63126795e-04, 9.00433588e-05,
           7.03608384e-05],
          ...,
          [9.99606311e-01, 2.56073487e-04, 8.61902590e-05,
           5.14306885e-05],
          [9.99350727e-01, 3.60481936e-04, 2.11968058e-04,
           7.68149985e-05],
          [9.98745084e-01, 5.06324985e-04, 6.22080697e-04,
           1.26392217e-04]],

         [[9.97090936e-01, 1.63664541e-03, 9.10186209e-04,
           3.62205581e-04],
          [9.98683751e-01, 6.47396024e-04, 4.41921729e-04,
           2.26883189e-04],
          [9.99355376e-01, 3.35140561e-04, 2.11035134e-04,
           9.84902726e-05],
          ...,
          [9.99473631e-01, 3.11915646e-04, 1.52082095e-04,
           6.24334207e-05],
          [9.99011278e-01, 4.95669898e-04, 3.88309243e-04,
           1.04744715e-04],
          [9.97328401e-01, 9.41261591e-04, 1.55579241e-03,
           1.74556131e-04]],

         [[9.88935292e-01, 6.15180098e-03, 3.49908671e-03,
           1.41383428e-03],
          [9.91148949e-01, 5.05862525e-03, 2.83771288e-03,
           9.54693707e-04],
          [9.96244967e-01, 2.20214855e-03, 1.15794525e-03,
           3.94823321e-04],
          ...,
          [9.97456968e-01, 1.59516558e-03, 7.16201204e-04,
           2.31672486e-04],
          [9.96501446e-01, 2.13856529e-03, 1.07161363e-03,
           2.88272713e-04],
          [9.90296423e-01, 3.63488938e-03, 5.51775144e-03,
           5.50983474e-04]]],


        [[[9.98195112e-01, 8.93165707e-04, 6.27531845e-04,
           2.84180336e-04],
          [9.99262512e-01, 4.20393364e-04, 1.49577638e-04,
           1.67578924e-04],
          [9.99472320e-01, 3.11983633e-04, 1.09657645e-04,
           1.06155087e-04],
          ...,
          [9.99762475e-01, 1.49905580e-04, 3.73397961e-05,
           5.02514122e-05],
          [9.99663472e-01, 1.87930345e-04, 8.92135940e-05,
           5.93739460e-05],
          [9.97642457e-01, 1.38394325e-03, 6.20198844e-04,
           3.53290729e-04]],

         [[9.99600708e-01, 2.16622590e-04, 1.10691719e-04,
           7.19987365e-05],
          [9.99850512e-01, 8.43438029e-05, 2.66536154e-05,
           3.83839870e-05],
          [9.99882221e-01, 5.15651336e-05, 2.23311199e-05,
           4.37806266e-05],
          ...,
          [9.99845862e-01, 8.10592901e-05, 3.16367732e-05,
           4.14279712e-05],
          [9.99826014e-01, 7.48021339e-05, 5.27969241e-05,
           4.63548495e-05],
          [9.99696255e-01, 1.06216343e-04, 1.33763402e-04,
           6.38484053e-05]],

         [[9.99814093e-01, 9.73229835e-05, 4.66092752e-05,
           4.19791832e-05],
          [9.99911666e-01, 3.58532961e-05, 1.77019629e-05,
           3.47093010e-05],
          [9.99936104e-01, 2.55091290e-05, 1.29015580e-05,
           2.54219922e-05],
          ...,
          [9.99913335e-01, 3.79166086e-05, 1.72795790e-05,
           3.14643221e-05],
          [9.99886870e-01, 4.63428223e-05, 3.45662011e-05,
           3.21991247e-05],
          [9.99838233e-01, 4.97113870e-05, 6.16319739e-05,
           5.03555384e-05]],

         ...,

         [[9.99832869e-01, 7.00294040e-05, 4.93298139e-05,
           4.76964196e-05],
          [9.99856949e-01, 5.66760864e-05, 3.70238922e-05,
           4.93119078e-05],
          [9.99900222e-01, 3.91420144e-05, 2.50946214e-05,
           3.56230703e-05],
          ...,
          [9.99895334e-01, 5.45377334e-05, 2.33051869e-05,
           2.67416817e-05],
          [9.99753535e-01, 1.19117190e-04, 7.70111801e-05,
           5.04122909e-05],
          [9.99760926e-01, 9.01119638e-05, 8.26444739e-05,
           6.62723251e-05]],

         [[9.99623775e-01, 1.65297417e-04, 1.11140340e-04,
           9.97711177e-05],
          [9.99779046e-01, 7.96306849e-05, 7.65640143e-05,
           6.47345441e-05],
          [9.99839425e-01, 5.99537816e-05, 4.62048847e-05,
           5.43669084e-05],
          ...,
          [9.99870181e-01, 7.08642256e-05, 2.63445891e-05,
           3.25633482e-05],
          [9.99683380e-01, 1.64652432e-04, 9.36044962e-05,
           5.83222391e-05],
          [9.99655724e-01, 1.21853322e-04, 1.56097914e-04,
           6.63109895e-05]],

         [[9.98144627e-01, 7.90315680e-04, 7.65601406e-04,
           2.99512612e-04],
          [9.99032140e-01, 3.40413157e-04, 4.15384566e-04,
           2.12077983e-04],
          [9.99430835e-01, 2.21916183e-04, 2.16609129e-04,
           1.30613407e-04],
          ...,
          [9.99565184e-01, 2.09518344e-04, 1.37054740e-04,
           8.82395834e-05],
          [9.99269545e-01, 3.48432572e-04, 2.56940606e-04,
           1.25048726e-04],
          [9.97665048e-01, 5.96374157e-04, 1.43863854e-03,
           3.00015789e-04]]],


        [[[9.98624682e-01, 6.59584592e-04, 5.42626716e-04,
           1.73080160e-04],
          [9.99710739e-01, 1.47102459e-04, 7.22799450e-05,
           6.99169614e-05],
          [9.99740303e-01, 1.31252542e-04, 6.43964522e-05,
           6.40225480e-05],
          ...,
          [9.99868393e-01, 6.60895967e-05, 2.94029724e-05,
           3.61715793e-05],
          [9.99821842e-01, 7.94789303e-05, 5.92629040e-05,
           3.93751798e-05],
          [9.98558819e-01, 7.46061560e-04, 4.16143303e-04,
           2.79046042e-04]],

         [[9.99804795e-01, 1.09320150e-04, 5.78124018e-05,
           2.81268167e-05],
          [9.99920607e-01, 2.94353958e-05, 2.10473663e-05,
           2.88603114e-05],
          [9.99837279e-01, 5.42656271e-05, 5.42825001e-05,
           5.42103844e-05],
          ...,
          [9.99870062e-01, 4.62099597e-05, 3.19257779e-05,
           5.17482076e-05],
          [9.99845624e-01, 6.08707160e-05, 5.20710419e-05,
           4.14277638e-05],
          [9.99849916e-01, 4.20044380e-05, 6.75208939e-05,
           4.05851024e-05]],

         [[9.99844432e-01, 6.96522329e-05, 4.47518105e-05,
           4.12359914e-05],
          [9.99907255e-01, 2.32890470e-05, 2.29715824e-05,
           4.65315861e-05],
          [9.99846458e-01, 3.45835324e-05, 4.08537999e-05,
           7.81017152e-05],
          ...,
          [9.99897480e-01, 2.81742596e-05, 2.25857129e-05,
           5.17916378e-05],
          [9.99857306e-01, 3.25728361e-05, 4.82475007e-05,
           6.18559570e-05],
          [9.99826610e-01, 3.58068173e-05, 6.67196437e-05,
           7.09643282e-05]],

         ...,

         [[9.99818265e-01, 7.17245493e-05, 6.49366775e-05,
           4.50629232e-05],
          [9.99868989e-01, 3.26738627e-05, 4.12304325e-05,
           5.71470628e-05],
          [9.99838114e-01, 3.83623192e-05, 5.58165812e-05,
           6.76863638e-05],
          ...,
          [9.99897957e-01, 3.38589452e-05, 3.08441849e-05,
           3.73714356e-05],
          [9.99779761e-01, 6.86245185e-05, 7.89663100e-05,
           7.26810104e-05],
          [9.99738634e-01, 6.44197498e-05, 9.11941461e-05,
           1.05746214e-04]],

         [[9.99757230e-01, 9.07497306e-05, 8.46610856e-05,
           6.74339972e-05],
          [9.99837995e-01, 4.26441657e-05, 5.01860013e-05,
           6.90735687e-05],
          [9.99827385e-01, 4.86785466e-05, 5.42110356e-05,
           6.96987481e-05],
          ...,
          [9.99867916e-01, 4.96351204e-05, 3.30428411e-05,
           4.94807646e-05],
          [9.99734461e-01, 1.03963954e-04, 9.41626204e-05,
           6.74535695e-05],
          [9.99699712e-01, 9.15839191e-05, 1.23398291e-04,
           8.54447644e-05]],

         [[9.99321342e-01, 2.75934057e-04, 2.57845706e-04,
           1.44895414e-04],
          [9.99555290e-01, 1.39389420e-04, 1.64223005e-04,
           1.41082128e-04],
          [9.99666452e-01, 1.17214397e-04, 1.29510983e-04,
           8.68155839e-05],
          ...,
          [9.99730766e-01, 1.01344536e-04, 9.57236771e-05,
           7.22197146e-05],
          [9.99523640e-01, 2.06115350e-04, 1.59239440e-04,
           1.11053771e-04],
          [9.98034298e-01, 4.95425600e-04, 1.16187171e-03,
           3.08433402e-04]]],


        ...,


        [[[9.92347121e-01, 1.32074859e-03, 4.72816313e-03,
           1.60389405e-03],
          [9.86363828e-01, 1.12408248e-03, 1.11092776e-02,
           1.40275212e-03],
          [9.77115631e-01, 1.11220253e-03, 1.88207403e-02,
           2.95144110e-03],
          ...,
          [9.66552556e-01, 1.05625391e-03, 1.51526164e-02,
           1.72385983e-02],
          [9.74880517e-01, 1.38063880e-03, 1.38718309e-02,
           9.86700319e-03],
          [9.56094742e-01, 9.05030593e-03, 2.09137313e-02,
           1.39411846e-02]],

         [[9.39400077e-01, 7.29465950e-03, 4.63389680e-02,
           6.96632406e-03],
          [7.55598962e-01, 1.20323300e-02, 2.16030210e-01,
           1.63385030e-02],
          [5.37853718e-01, 4.96907486e-03, 4.14183259e-01,
           4.29939441e-02],
          ...,
          [4.01839077e-01, 2.60236789e-03, 2.43711233e-01,
           3.51847291e-01],
          [4.95651603e-01, 6.50035311e-03, 2.68810928e-01,
           2.29037195e-01],
          [8.17103088e-01, 1.24158142e-02, 8.71036351e-02,
           8.33774954e-02]],

         [[8.33873093e-01, 2.06860658e-02, 1.00661010e-01,
           4.47797999e-02],
          [7.43135154e-01, 1.09925810e-02, 2.04606920e-01,
           4.12652344e-02],
          [2.40188003e-01, 1.09461909e-02, 5.95278859e-01,
           1.53586954e-01],
          ...,
          [2.64847279e-02, 1.31804764e-03, 2.26678416e-01,
           7.45518804e-01],
          [1.07201517e-01, 5.78721194e-03, 3.11961263e-01,
           5.75050056e-01],
          [6.29953742e-01, 1.88636538e-02, 1.19413346e-01,
           2.31769159e-01]],

         ...,

         [[9.99817669e-01, 7.28449013e-05, 5.64499460e-05,
           5.31209807e-05],
          [9.99894142e-01, 2.42910064e-05, 2.59471399e-05,
           5.55845400e-05],
          [9.99870896e-01, 2.94977781e-05, 3.28787282e-05,
           6.67490822e-05],
          ...,
          [9.99895573e-01, 3.64335719e-05, 2.70728106e-05,
           4.08575215e-05],
          [9.99828219e-01, 5.24801289e-05, 5.60652734e-05,
           6.32225128e-05],
          [9.99731243e-01, 5.91718672e-05, 1.04093982e-04,
           1.05453277e-04]],

         [[9.99735773e-01, 1.10932422e-04, 7.51478656e-05,
           7.80806367e-05],
          [9.99812067e-01, 5.30413090e-05, 4.36219343e-05,
           9.12479882e-05],
          [9.99880910e-01, 3.28003880e-05, 3.19955579e-05,
           5.42753914e-05],
          ...,
          [9.99890089e-01, 4.23271849e-05, 2.58380896e-05,
           4.17495685e-05],
          [9.99828219e-01, 6.99337106e-05, 5.63086505e-05,
           4.55184527e-05],
          [9.99706328e-01, 7.53639833e-05, 1.38645177e-04,
           7.96636305e-05]],

         [[9.99445140e-01, 2.51369987e-04, 1.76275717e-04,
           1.27214749e-04],
          [9.99705851e-01, 9.96330637e-05, 9.23248008e-05,
           1.02201448e-04],
          [9.99806225e-01, 6.57114215e-05, 6.90331071e-05,
           5.90619056e-05],
          ...,
          [9.99765575e-01, 9.55435098e-05, 7.79631591e-05,
           6.08239461e-05],
          [9.99634266e-01, 1.34030022e-04, 1.41059776e-04,
           9.05931374e-05],
          [9.97578323e-01, 6.52693445e-04, 1.43550814e-03,
           3.33581527e-04]]],


        [[[9.93596792e-01, 1.16534159e-03, 3.52059770e-03,
           1.71725266e-03],
          [9.92364287e-01, 7.81407289e-04, 5.37512219e-03,
           1.47927692e-03],
          [9.86698508e-01, 1.26521371e-03, 8.39941110e-03,
           3.63691570e-03],
          ...,
          [9.66262758e-01, 1.56737119e-03, 9.58128087e-03,
           2.25886609e-02],
          [9.71686780e-01, 2.54100934e-03, 1.34757468e-02,
           1.22964634e-02],
          [9.59894478e-01, 8.99818633e-03, 1.74338110e-02,
           1.36735588e-02]],

         [[9.82725859e-01, 3.26953386e-03, 1.02784391e-02,
           3.72615596e-03],
          [9.82784033e-01, 2.14686664e-03, 1.25294263e-02,
           2.53962469e-03],
          [9.29730415e-01, 2.18062405e-03, 5.80901988e-02,
           9.99869406e-03],
          ...,
          [6.40933573e-01, 2.96598347e-03, 7.00108036e-02,
           2.86089659e-01],
          [8.00710082e-01, 6.21455768e-03, 8.47926736e-02,
           1.08282618e-01],
          [8.30380976e-01, 1.38852969e-02, 8.92278776e-02,
           6.65058121e-02]],

         [[9.48774517e-01, 9.28826816e-03, 2.91788336e-02,
           1.27583798e-02],
          [9.35536444e-01, 9.17631388e-03, 4.46422063e-02,
           1.06449937e-02],
          [7.58688211e-01, 7.03315251e-03, 2.07469627e-01,
           2.68089417e-02],
          ...,
          [2.42067978e-01, 2.61341315e-03, 1.20017499e-01,
           6.35301113e-01],
          [3.45149666e-01, 1.79169662e-02, 1.71051756e-01,
           4.65881646e-01],
          [7.47308195e-01, 2.31844541e-02, 8.40804279e-02,
           1.45426840e-01]],

         ...,

         [[9.99691129e-01, 1.15989737e-04, 1.11628287e-04,
           8.12853832e-05],
          [9.99884009e-01, 3.46534071e-05, 3.06302682e-05,
           5.06793804e-05],
          [9.99889016e-01, 2.82447218e-05, 3.87941836e-05,
           4.39722753e-05],
          ...,
          [9.99905109e-01, 3.62102946e-05, 2.97395654e-05,
           2.88736010e-05],
          [9.99856353e-01, 7.25343125e-05, 4.48439459e-05,
           2.62478734e-05],
          [9.99725163e-01, 1.04887949e-04, 1.14256924e-04,
           5.56557643e-05]],

         [[9.99542594e-01, 2.04110751e-04, 1.49737185e-04,
           1.03625986e-04],
          [9.99866724e-01, 5.47307754e-05, 3.08882554e-05,
           4.77029425e-05],
          [9.99929905e-01, 2.77893523e-05, 1.88450103e-05,
           2.35078332e-05],
          ...,
          [9.99943733e-01, 2.53753878e-05, 1.54856207e-05,
           1.53504789e-05],
          [9.99868393e-01, 6.50334550e-05, 4.49625040e-05,
           2.15009859e-05],
          [9.99235392e-01, 3.01798456e-04, 3.56576056e-04,
           1.06208186e-04]],

         [[9.98713732e-01, 5.59049367e-04, 5.13017003e-04,
           2.14208587e-04],
          [9.99383926e-01, 1.79035065e-04, 2.36930835e-04,
           2.00010894e-04],
          [9.99647379e-01, 1.06293126e-04, 1.50965556e-04,
           9.53613562e-05],
          ...,
          [9.99593914e-01, 1.37728624e-04, 1.61894888e-04,
           1.06449748e-04],
          [9.99099970e-01, 2.99355306e-04, 4.51097731e-04,
           1.49702697e-04],
          [9.94751751e-01, 1.49695855e-03, 3.13596940e-03,
           6.15332101e-04]]],


        [[[9.94618893e-01, 1.42196880e-03, 2.57563638e-03,
           1.38345989e-03],
          [9.94344473e-01, 6.16381411e-04, 4.08494147e-03,
           9.54263844e-04],
          [9.88763928e-01, 1.32109551e-03, 6.34562038e-03,
           3.56937922e-03],
          ...,
          [9.71693099e-01, 2.65664980e-03, 1.00492621e-02,
           1.56010184e-02],
          [9.65453923e-01, 3.94433131e-03, 1.63390655e-02,
           1.42627629e-02],
          [9.54356790e-01, 1.26268091e-02, 1.80226229e-02,
           1.49937784e-02]],

         [[9.93522882e-01, 1.43556437e-03, 3.07545345e-03,
           1.96610438e-03],
          [9.87816632e-01, 1.18509005e-03, 8.39954428e-03,
           2.59868987e-03],
          [9.87233400e-01, 7.25260295e-04, 7.56281381e-03,
           4.47852118e-03],
          ...,
          [8.61921430e-01, 1.91201537e-03, 1.91933680e-02,
           1.16973117e-01],
          [8.69040847e-01, 5.18586813e-03, 3.22223231e-02,
           9.35509205e-02],
          [9.04077888e-01, 9.55273118e-03, 3.64472531e-02,
           4.99221161e-02]],

         [[9.84287143e-01, 4.36820183e-03, 5.81121631e-03,
           5.53339580e-03],
          [9.91966903e-01, 1.20722118e-03, 4.34104027e-03,
           2.48476071e-03],
          [9.86431539e-01, 5.98063343e-04, 7.02284649e-03,
           5.94756193e-03],
          ...,
          [7.67202914e-01, 1.49720116e-03, 2.08022613e-02,
           2.10497692e-01],
          [7.40972459e-01, 6.35732245e-03, 5.42321876e-02,
           1.98438004e-01],
          [8.82265985e-01, 1.21106394e-02, 3.30981202e-02,
           7.25253001e-02]],

         ...,

         [[9.98679221e-01, 5.59191161e-04, 5.24996489e-04,
           2.36523207e-04],
          [9.99707997e-01, 8.97937498e-05, 1.14505310e-04,
           8.76909253e-05],
          [9.99811351e-01, 5.25033211e-05, 8.00785419e-05,
           5.60297449e-05],
          ...,
          [9.99748528e-01, 8.56815022e-05, 1.06709667e-04,
           5.90920790e-05],
          [9.99423742e-01, 2.04622993e-04, 2.70948833e-04,
           1.00792036e-04],
          [9.98078823e-01, 6.91007182e-04, 9.31440445e-04,
           2.98646366e-04]],

         [[9.98021364e-01, 9.32714320e-04, 7.19345291e-04,
           3.26567009e-04],
          [9.99576390e-01, 1.40923468e-04, 1.41450335e-04,
           1.41227516e-04],
          [9.99794900e-01, 6.90487941e-05, 7.01900863e-05,
           6.59270445e-05],
          ...,
          [9.99726832e-01, 1.00581266e-04, 1.00065001e-04,
           7.25290665e-05],
          [9.98791397e-01, 5.04843832e-04, 5.21140522e-04,
           1.82619508e-04],
          [9.97286916e-01, 9.02570959e-04, 1.51718687e-03,
           2.93300924e-04]],

         [[9.96426284e-01, 1.43619336e-03, 1.66886777e-03,
           4.68656770e-04],
          [9.98250902e-01, 5.14674291e-04, 8.91541247e-04,
           3.42794374e-04],
          [9.99029160e-01, 2.52389087e-04, 5.25929150e-04,
           1.92537773e-04],
          ...,
          [9.97691870e-01, 6.39426056e-04, 1.30934420e-03,
           3.59474157e-04],
          [9.96563494e-01, 1.05558382e-03, 1.88431481e-03,
           4.96716239e-04],
          [9.89402771e-01, 4.10932070e-03, 5.42634726e-03,
           1.06145535e-03]]]]], dtype=float32)>}2021-07-14 12:41:20.171396: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.91175532e-01, 3.80578148e-03, 4.30179061e-03,
           7.16932933e-04],
          [9.95523572e-01, 2.36437027e-03, 1.66869524e-03,
           4.43355617e-04],
          [9.96554971e-01, 1.64303568e-03, 1.41528214e-03,
           3.86821601e-04],
          ...,
          [9.97982979e-01, 1.21591147e-03, 5.27612283e-04,
           2.73547601e-04],
          [9.96995449e-01, 1.77706452e-03, 9.41548788e-04,
           2.85983988e-04],
          [9.90393698e-01, 5.35660936e-03, 3.54327750e-03,
           7.06404448e-04]],

         [[9.98415828e-01, 7.72445404e-04, 6.30047347e-04,
           1.81711206e-04],
          [9.99185622e-01, 3.50805814e-04, 2.67328083e-04,
           1.96242254e-04],
          [9.99595940e-01, 1.45066864e-04, 1.55295391e-04,
           1.03770566e-04],
          ...,
          [9.99292612e-01, 3.54692398e-04, 2.17541135e-04,
           1.35157592e-04],
          [9.99333203e-01, 2.63024936e-04, 2.96892249e-04,
           1.06844927e-04],
          [9.97977197e-01, 6.32802024e-04, 1.20592804e-03,
           1.84102348e-04]],

         [[9.99024391e-01, 5.22956776e-04, 2.98391853e-04,
           1.54336944e-04],
          [9.99615669e-01, 1.92056279e-04, 1.03997809e-04,
           8.82425229e-05],
          [9.99794304e-01, 1.00042467e-04, 5.96967948e-05,
           4.59748990e-05],
          ...,
          [9.99639153e-01, 2.28794786e-04, 7.69879844e-05,
           5.50330042e-05],
          [9.99589860e-01, 1.99354108e-04, 1.48013220e-04,
           6.27382906e-05],
          [9.99098897e-01, 3.57480661e-04, 4.37768322e-04,
           1.05949082e-04]],

         ...,

         [[9.98444498e-01, 7.46559701e-04, 6.06473710e-04,
           2.02507537e-04],
          [9.99023318e-01, 4.01731668e-04, 3.72747745e-04,
           2.02190233e-04],
          [9.99365985e-01, 2.20004687e-04, 2.69478012e-04,
           1.44529258e-04],
          ...,
          [9.98751044e-01, 7.74798158e-04, 3.92519782e-04,
           8.15438179e-05],
          [9.98465896e-01, 6.53190073e-04, 8.08737648e-04,
           7.22313198e-05],
          [9.90571737e-01, 2.79540406e-03, 6.37570675e-03,
           2.57160747e-04]],

         [[9.94523048e-01, 2.69256276e-03, 2.33318959e-03,
           4.51197062e-04],
          [9.96953011e-01, 1.26029842e-03, 1.43359276e-03,
           3.53176903e-04],
          [9.98724520e-01, 4.90996696e-04, 5.97137609e-04,
           1.87380167e-04],
          ...,
          [9.97418761e-01, 1.19807583e-03, 1.28649070e-03,
           9.67148080e-05],
          [9.95976627e-01, 1.43815484e-03, 2.44833739e-03,
           1.36880713e-04],
          [9.82031941e-01, 4.83173924e-03, 1.27547393e-02,
           3.81597201e-04]],

         [[9.81455147e-01, 9.58021451e-03, 7.31261726e-03,
           1.65210152e-03],
          [9.82508421e-01, 9.25019383e-03, 6.81483978e-03,
           1.42649957e-03],
          [9.92411256e-01, 3.93776596e-03, 2.96074618e-03,
           6.90276560e-04],
          ...,
          [9.90375102e-01, 5.64573472e-03, 3.56169674e-03,
           4.17490461e-04],
          [9.85846817e-01, 6.36412762e-03, 7.13814795e-03,
           6.50821778e-04],
          [9.59052742e-01, 1.49575435e-02, 2.49265116e-02,
           1.06323359e-03]]],


        [[[9.98129427e-01, 8.61909299e-04, 7.11061293e-04,
           2.97534862e-04],
          [9.99166965e-01, 4.42425371e-04, 1.96859386e-04,
           1.93822518e-04],
          [9.99342859e-01, 3.67954053e-04, 1.57529212e-04,
           1.31640292e-04],
          ...,
          [9.99753416e-01, 1.51982546e-04, 3.93136579e-05,
           5.53094324e-05],
          [9.99650002e-01, 1.89521190e-04, 9.62737395e-05,
           6.42094310e-05],
          [9.97666121e-01, 1.34977442e-03, 6.22648455e-04,
           3.61525279e-04]],

         [[9.99625564e-01, 1.83068769e-04, 1.18066724e-04,
           7.33057241e-05],
          [9.99835968e-01, 8.27204713e-05, 3.42144122e-05,
           4.70542836e-05],
          [9.99864697e-01, 5.46052288e-05, 2.73943569e-05,
           5.32523700e-05],
          ...,
          [9.99841094e-01, 7.95732994e-05, 3.43092142e-05,
           4.49068502e-05],
          [9.99816954e-01, 7.67659367e-05, 5.55763763e-05,
           5.06832330e-05],
          [9.99715626e-01, 9.51584589e-05, 1.24831990e-04,
           6.44376851e-05]],

         [[9.99834180e-01, 7.88252437e-05, 4.63446704e-05,
           4.06689214e-05],
          [9.99900937e-01, 3.80784804e-05, 2.09142327e-05,
           4.01570323e-05],
          [9.99937654e-01, 2.29363995e-05, 1.36794106e-05,
           2.57734355e-05],
          ...,
          [9.99911666e-01, 3.96305732e-05, 1.69238047e-05,
           3.18187122e-05],
          [9.99882698e-01, 4.88125734e-05, 3.50190712e-05,
           3.33542703e-05],
          [9.99845862e-01, 4.88184123e-05, 5.66754607e-05,
           4.85375058e-05]],

         ...,

         [[9.99776065e-01, 8.26968972e-05, 7.78403555e-05,
           6.33565869e-05],
          [9.99878526e-01, 3.51741946e-05, 4.39731157e-05,
           4.23802558e-05],
          [9.99824941e-01, 4.14658753e-05, 7.07286890e-05,
           6.28305352e-05],
          ...,
          [9.99882698e-01, 6.93834663e-05, 3.58982434e-05,
           1.20032082e-05],
          [9.99822557e-01, 8.40962239e-05, 8.06802709e-05,
           1.26621453e-05],
          [9.98689592e-01, 5.55399281e-04, 6.05535402e-04,
           1.49521526e-04]],

         [[9.99017000e-01, 3.60020116e-04, 4.41926968e-04,
           1.80994190e-04],
          [9.99694943e-01, 8.07982433e-05, 1.51453540e-04,
           7.28213054e-05],
          [9.99737799e-01, 5.76550374e-05, 1.35203358e-04,
           6.93014663e-05],
          ...,
          [9.99700189e-01, 1.56278387e-04, 1.19864511e-04,
           2.37609493e-05],
          [9.99294162e-01, 3.07850627e-04, 3.70658003e-04,
           2.73640817e-05],
          [9.97516632e-01, 7.60472729e-04, 1.54873449e-03,
           1.74203888e-04]],

         [[9.95851159e-01, 1.81561813e-03, 1.79178070e-03,
           5.41461166e-04],
          [9.98253167e-01, 6.07498630e-04, 8.41411820e-04,
           2.97860242e-04],
          [9.99022126e-01, 2.77915853e-04, 5.18627756e-04,
           1.81293639e-04],
          ...,
          [9.98609304e-01, 5.58810832e-04, 7.11846398e-04,
           1.20064629e-04],
          [9.96246040e-01, 1.07135600e-03, 2.51049036e-03,
           1.72155065e-04],
          [9.89736080e-01, 2.69032340e-03, 7.00785918e-03,
           5.65777125e-04]]],


        [[[9.98562276e-01, 6.24246022e-04, 6.26286841e-04,
           1.87228448e-04],
          [9.99644637e-01, 1.63201257e-04, 1.07710017e-04,
           8.43892703e-05],
          [9.99635696e-01, 1.70821470e-04, 1.06911728e-04,
           8.66645059e-05],
          ...,
          [9.99858141e-01, 7.26136204e-05, 3.24541979e-05,
           3.67707253e-05],
          [9.99795496e-01, 8.88714130e-05, 7.03271508e-05,
           4.52735731e-05],
          [9.98561919e-01, 7.26839236e-04, 4.27748048e-04,
           2.83512054e-04]],

         [[9.99798834e-01, 1.03628045e-04, 6.71197267e-05,
           3.04754521e-05],
          [9.99927402e-01, 2.44577659e-05, 2.08471029e-05,
           2.72888246e-05],
          [9.99845505e-01, 4.89139748e-05, 5.34628780e-05,
           5.21875700e-05],
          ...,
          [9.99870300e-01, 4.78199036e-05, 3.17373633e-05,
           5.01604009e-05],
          [9.99836445e-01, 6.35160832e-05, 5.62876921e-05,
           4.37530762e-05],
          [9.99849796e-01, 4.05172214e-05, 6.73879840e-05,
           4.23203128e-05]],

         [[9.99837637e-01, 6.66537380e-05, 5.16638356e-05,
           4.40025251e-05],
          [9.99906421e-01, 2.31538288e-05, 2.33250812e-05,
           4.71100502e-05],
          [9.99835491e-01, 3.70440794e-05, 4.74049593e-05,
           8.00362759e-05],
          ...,
          [9.99899268e-01, 3.28832357e-05, 2.21351584e-05,
           4.56508060e-05],
          [9.99846339e-01, 3.87896434e-05, 5.11074904e-05,
           6.38123311e-05],
          [9.99831915e-01, 3.63559047e-05, 6.26108595e-05,
           6.91150562e-05]],

         ...,

         [[9.99830842e-01, 5.55863226e-05, 6.98183430e-05,
           4.37635535e-05],
          [9.99853373e-01, 2.44455787e-05, 6.78525321e-05,
           5.42866364e-05],
          [9.99838948e-01, 2.21093924e-05, 8.02762734e-05,
           5.87442628e-05],
          ...,
          [9.99869108e-01, 4.73663349e-05, 6.24390086e-05,
           2.10912094e-05],
          [9.99833584e-01, 6.78462020e-05, 7.77076930e-05,
           2.08679794e-05],
          [9.99636054e-01, 1.16285046e-04, 1.82509713e-04,
           6.50868969e-05]],

         [[9.99672174e-01, 1.05955995e-04, 1.44105506e-04,
           7.78301837e-05],
          [9.99785125e-01, 3.81093050e-05, 1.09830667e-04,
           6.69269211e-05],
          [9.99788105e-01, 3.19136670e-05, 1.13914968e-04,
           6.60529040e-05],
          ...,
          [9.99808013e-01, 6.55687472e-05, 1.00096986e-04,
           2.63645379e-05],
          [9.99781311e-01, 8.70122312e-05, 1.08578846e-04,
           2.31094818e-05],
          [9.98959780e-01, 2.55157036e-04, 6.83432096e-04,
           1.01581216e-04]],

         [[9.98323619e-01, 6.05629059e-04, 7.97824818e-04,
           2.72941397e-04],
          [9.99145746e-01, 2.09997204e-04, 4.18948533e-04,
           2.25245356e-04],
          [9.99485135e-01, 1.10050569e-04, 2.83490197e-04,
           1.21311612e-04],
          ...,
          [9.99221087e-01, 2.35761967e-04, 4.26308659e-04,
           1.16897892e-04],
          [9.98631775e-01, 3.36468831e-04, 9.12452990e-04,
           1.19314202e-04],
          [9.93110418e-01, 1.65277848e-03, 4.82897228e-03,
           4.07814863e-04]]],


        ...,


        [[[9.99234676e-01, 3.84391489e-04, 2.59877736e-04,
           1.21099867e-04],
          [9.99809921e-01, 9.01015956e-05, 4.29491120e-05,
           5.71021228e-05],
          [9.99822557e-01, 8.71122174e-05, 4.09934364e-05,
           4.93506632e-05],
          ...,
          [9.99812424e-01, 1.12281195e-04, 2.90724256e-05,
           4.62508506e-05],
          [9.99779642e-01, 1.25403443e-04, 5.19752284e-05,
           4.29666979e-05],
          [9.98124540e-01, 1.01375417e-03, 5.41520771e-04,
           3.20165593e-04]],

         [[9.99776065e-01, 1.13866350e-04, 6.11200885e-05,
           4.89529011e-05],
          [9.99867201e-01, 4.84679549e-05, 3.15231810e-05,
           5.26947224e-05],
          [9.99895453e-01, 3.31806732e-05, 2.61913374e-05,
           4.51489177e-05],
          ...,
          [9.99832392e-01, 8.51874283e-05, 3.04392379e-05,
           5.19357563e-05],
          [9.99851227e-01, 7.70612387e-05, 4.01470716e-05,
           3.14982208e-05],
          [9.99861717e-01, 4.51934866e-05, 6.19422426e-05,
           3.11173317e-05]],

         [[9.99818504e-01, 8.34723323e-05, 4.93132029e-05,
           4.87804500e-05],
          [9.99879718e-01, 2.99695384e-05, 2.41080179e-05,
           6.62526509e-05],
          [9.99905109e-01, 2.36732576e-05, 1.87547557e-05,
           5.23671224e-05],
          ...,
          [9.99881625e-01, 4.97656729e-05, 2.17170164e-05,
           4.68753533e-05],
          [9.99845982e-01, 6.29192800e-05, 3.96307296e-05,
           5.13814412e-05],
          [9.99850392e-01, 3.51884046e-05, 6.13542725e-05,
           5.31116784e-05]],

         ...,

         [[9.99841452e-01, 5.81602144e-05, 5.28132514e-05,
           4.75314555e-05],
          [9.99898314e-01, 2.08130641e-05, 2.73070873e-05,
           5.34717146e-05],
          [9.99900460e-01, 1.91644813e-05, 2.71975478e-05,
           5.31993974e-05],
          ...,
          [9.99902964e-01, 2.49861314e-05, 2.59822100e-05,
           4.59722651e-05],
          [9.99825776e-01, 4.00161625e-05, 6.05808709e-05,
           7.35958602e-05],
          [9.99757111e-01, 4.99980270e-05, 8.34912425e-05,
           1.09398577e-04]],

         [[9.99755681e-01, 8.47056072e-05, 8.24310409e-05,
           7.70930565e-05],
          [9.99825656e-01, 3.66661225e-05, 4.86132376e-05,
           8.90872616e-05],
          [9.99888420e-01, 2.31111426e-05, 3.33296884e-05,
           5.50740842e-05],
          ...,
          [9.99899745e-01, 2.82001838e-05, 2.74682261e-05,
           4.44778452e-05],
          [9.99790132e-01, 6.84278057e-05, 6.74652983e-05,
           7.39825191e-05],
          [9.99760091e-01, 6.25916728e-05, 9.99483527e-05,
           7.74420914e-05]],

         [[9.99459445e-01, 2.18907415e-04, 1.90856139e-04,
           1.30784654e-04],
          [9.99710023e-01, 8.18780754e-05, 1.04923980e-04,
           1.03169790e-04],
          [9.99811351e-01, 5.05636999e-05, 7.71915948e-05,
           6.09149101e-05],
          ...,
          [9.99828458e-01, 6.16306643e-05, 5.78497347e-05,
           5.20453759e-05],
          [9.99734223e-01, 9.82797719e-05, 9.26266512e-05,
           7.48072489e-05],
          [9.98253047e-01, 4.38185351e-04, 1.00310089e-03,
           3.05667898e-04]]],


        [[[9.97770905e-01, 1.17733865e-03, 7.73090927e-04,
           2.78712047e-04],
          [9.99356687e-01, 3.87474516e-04, 1.33602109e-04,
           1.22236408e-04],
          [9.99600589e-01, 2.60813220e-04, 7.45643556e-05,
           6.40158032e-05],
          ...,
          [9.99577940e-01, 3.17951257e-04, 5.83650544e-05,
           4.58254981e-05],
          [9.99297738e-01, 4.84974822e-04, 1.69991923e-04,
           4.73195832e-05],
          [9.97459710e-01, 1.63704308e-03, 6.53361902e-04,
           2.49944278e-04]],

         [[9.99570429e-01, 2.15223219e-04, 1.34546921e-04,
           7.98069304e-05],
          [9.99829412e-01, 7.58870083e-05, 3.90291789e-05,
           5.55719816e-05],
          [9.99894261e-01, 4.47304446e-05, 3.10992364e-05,
           2.99340409e-05],
          ...,
          [9.99845624e-01, 1.02050057e-04, 2.56687563e-05,
           2.66474599e-05],
          [9.99715984e-01, 1.97632340e-04, 6.19809580e-05,
           2.44486309e-05],
          [9.99715745e-01, 1.31031469e-04, 1.25199105e-04,
           2.80373570e-05]],

         [[9.99681830e-01, 1.39839933e-04, 9.91346969e-05,
           7.92941428e-05],
          [9.99879479e-01, 4.33062341e-05, 2.52324953e-05,
           5.19605965e-05],
          [9.99912739e-01, 2.98931700e-05, 2.19531466e-05,
           3.53409341e-05],
          ...,
          [9.99864697e-01, 7.40760879e-05, 2.47475818e-05,
           3.65531450e-05],
          [9.99800980e-01, 1.14077120e-04, 5.09509046e-05,
           3.39784456e-05],
          [9.99854803e-01, 6.05707319e-05, 5.67184652e-05,
           2.79649867e-05]],

         ...,

         [[9.99732435e-01, 9.04627668e-05, 1.00835197e-04,
           7.62444470e-05],
          [9.99902606e-01, 2.27116234e-05, 2.97487386e-05,
           4.48237406e-05],
          [9.99910116e-01, 1.73079898e-05, 3.04317928e-05,
           4.21716177e-05],
          ...,
          [9.99908924e-01, 2.33101964e-05, 3.32781274e-05,
           3.43847823e-05],
          [9.99872446e-01, 4.62643038e-05, 4.42875171e-05,
           3.69533518e-05],
          [9.99766767e-01, 6.90230809e-05, 9.34975687e-05,
           7.07940781e-05]],

         [[9.99592841e-01, 1.58365379e-04, 1.40080956e-04,
           1.08756300e-04],
          [9.99867678e-01, 4.21490040e-05, 3.56379824e-05,
           5.45014991e-05],
          [9.99922156e-01, 2.23349925e-05, 2.37587046e-05,
           3.18402344e-05],
          ...,
          [9.99927759e-01, 2.81267876e-05, 2.01100520e-05,
           2.39532656e-05],
          [9.99880791e-01, 5.49287870e-05, 3.83908191e-05,
           2.58986111e-05],
          [9.99606907e-01, 1.38105926e-04, 1.78677859e-04,
           7.62755153e-05]],

         [[9.98774469e-01, 4.75190755e-04, 5.26508375e-04,
           2.23877592e-04],
          [9.99437392e-01, 1.45104321e-04, 2.21564682e-04,
           1.95918401e-04],
          [9.99716818e-01, 7.32862100e-05, 1.21039004e-04,
           8.88593422e-05],
          ...,
          [9.99749243e-01, 7.14456401e-05, 1.02247410e-04,
           7.70594852e-05],
          [9.99438703e-01, 1.78854592e-04, 2.74873542e-04,
           1.07559528e-04],
          [9.95987475e-01, 1.00643409e-03, 2.48308224e-03,
           5.22901246e-04]]],


        [[[9.90675032e-01, 5.69531880e-03, 2.67272885e-03,
           9.56857170e-04],
          [9.98006642e-01, 8.76932230e-04, 8.67964642e-04,
           2.48454628e-04],
          [9.98361528e-01, 8.16556858e-04, 6.35772070e-04,
           1.86146368e-04],
          ...,
          [9.98359621e-01, 8.98155617e-04, 6.05747919e-04,
           1.36480390e-04],
          [9.97922003e-01, 9.98043688e-04, 9.47066001e-04,
           1.32906018e-04],
          [9.92988646e-01, 3.37375957e-03, 2.87716137e-03,
           7.60440365e-04]],

         [[9.96187389e-01, 2.28976156e-03, 1.11031497e-03,
           4.12571768e-04],
          [9.98932302e-01, 5.08740486e-04, 3.65760643e-04,
           1.93226544e-04],
          [9.99660850e-01, 1.64247875e-04, 1.17269868e-04,
           5.76662642e-05],
          ...,
          [9.99472678e-01, 3.17854428e-04, 1.54153124e-04,
           5.53629179e-05],
          [9.98808026e-01, 6.59144425e-04, 4.58169816e-04,
           7.46961159e-05],
          [9.98236299e-01, 7.20811309e-04, 9.05842462e-04,
           1.37050432e-04]],

         [[9.98348832e-01, 8.15201201e-04, 5.46555850e-04,
           2.89419491e-04],
          [9.99690652e-01, 1.07227606e-04, 9.84411454e-05,
           1.03669416e-04],
          [9.99836087e-01, 6.22471125e-05, 5.16785367e-05,
           4.99499329e-05],
          ...,
          [9.99719918e-01, 1.34723698e-04, 8.20859859e-05,
           6.33037489e-05],
          [9.99463499e-01, 2.78852240e-04, 1.81763331e-04,
           7.59071409e-05],
          [9.98462319e-01, 6.59619516e-04, 6.80226425e-04,
           1.97781133e-04]],

         ...,

         [[9.98890102e-01, 4.16877883e-04, 4.62626165e-04,
           2.30355377e-04],
          [9.99735415e-01, 6.85154155e-05, 1.02966776e-04,
           9.30252208e-05],
          [9.99850988e-01, 3.66267268e-05, 6.18595805e-05,
           5.05152893e-05],
          ...,
          [9.99782264e-01, 6.27905902e-05, 8.99237275e-05,
           6.49643116e-05],
          [9.99699712e-01, 1.01766062e-04, 1.24510421e-04,
           7.39816824e-05],
          [9.98673320e-01, 4.17109899e-04, 5.97818638e-04,
           3.11764248e-04]],

         [[9.98312116e-01, 7.01444689e-04, 6.72250462e-04,
           3.14150355e-04],
          [9.99581873e-01, 1.18250871e-04, 1.47456652e-04,
           1.52520239e-04],
          [9.99804318e-01, 5.38902932e-05, 7.38316812e-05,
           6.79404984e-05],
          ...,
          [9.99774754e-01, 6.52284070e-05, 8.82643944e-05,
           7.17729417e-05],
          [9.99348700e-01, 2.53446109e-04, 2.78289692e-04,
           1.19622448e-04],
          [9.98210907e-01, 5.81301108e-04, 9.45884560e-04,
           2.61956448e-04]],

         [[9.96715546e-01, 1.20822294e-03, 1.61146233e-03,
           4.64756682e-04],
          [9.98337626e-01, 4.31553985e-04, 8.60281463e-04,
           3.70537746e-04],
          [9.99201119e-01, 1.83781347e-04, 4.21190343e-04,
           1.93955071e-04],
          ...,
          [9.98363793e-01, 4.14894952e-04, 8.84248584e-04,
           3.37066653e-04],
          [9.97287750e-01, 8.00846959e-04, 1.47859438e-03,
           4.32819186e-04],
          [9.90762293e-01, 3.22441477e-03, 4.96354140e-03,
           1.04972743e-03]]]]], dtype=float32)>}2021-07-14 12:41:20.469315: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.97132301e-01, 9.82569996e-04, 1.45952636e-03,
           4.25562554e-04],
          [9.98865366e-01, 4.98074631e-04, 4.58100636e-04,
           1.78441667e-04],
          [9.99319673e-01, 2.62036920e-04, 2.94845377e-04,
           1.23365229e-04],
          ...,
          [9.99505520e-01, 1.67658203e-04, 2.28515826e-04,
           9.83594800e-05],
          [9.98613834e-01, 5.53756487e-04, 6.55274605e-04,
           1.77031208e-04],
          [9.96390283e-01, 1.65189337e-03, 1.67631393e-03,
           2.81478366e-04]],

         [[9.99575675e-01, 1.26787898e-04, 2.18456087e-04,
           7.90744452e-05],
          [9.99827206e-01, 6.44415486e-05, 6.67902204e-05,
           4.15557552e-05],
          [9.99908686e-01, 3.22153683e-05, 4.05471328e-05,
           1.85469125e-05],
          ...,
          [9.99934316e-01, 2.27127985e-05, 2.75641469e-05,
           1.52954635e-05],
          [9.99822795e-01, 5.54495891e-05, 9.43518899e-05,
           2.75067687e-05],
          [9.99214172e-01, 2.87444098e-04, 4.41514538e-04,
           5.68190517e-05]],

         [[9.99777019e-01, 6.14279852e-05, 1.10195724e-04,
           5.14409439e-05],
          [9.99836445e-01, 4.70650812e-05, 6.19575076e-05,
           5.44554787e-05],
          [9.99918461e-01, 2.73702099e-05, 3.16699516e-05,
           2.24565229e-05],
          ...,
          [9.99941111e-01, 1.90286337e-05, 2.17563902e-05,
           1.80704264e-05],
          [9.99877691e-01, 4.12564405e-05, 5.10240097e-05,
           3.00569773e-05],
          [9.99201357e-01, 3.07859300e-04, 4.28988424e-04,
           6.18032936e-05]],

         ...,

         [[9.99183238e-01, 4.65926452e-04, 2.10415645e-04,
           1.40322198e-04],
          [9.99525785e-01, 2.50349054e-04, 1.17399708e-04,
           1.06517335e-04],
          [9.99722898e-01, 1.46312625e-04, 7.64490396e-05,
           5.42379457e-05],
          ...,
          [9.99604523e-01, 2.59405264e-04, 8.47348128e-05,
           5.13637387e-05],
          [9.99360144e-01, 3.53760290e-04, 2.09088539e-04,
           7.70272163e-05],
          [9.98818338e-01, 4.76090296e-04, 5.81633474e-04,
           1.23911508e-04]],

         [[9.97280836e-01, 1.54114026e-03, 8.37530766e-04,
           3.40542669e-04],
          [9.98799682e-01, 5.92449855e-04, 4.06381820e-04,
           2.01496179e-04],
          [9.99421358e-01, 3.09169438e-04, 1.89369268e-04,
           8.01223869e-05],
          ...,
          [9.99499321e-01, 2.96219543e-04, 1.43159225e-04,
           6.12898075e-05],
          [9.99099255e-01, 4.48303501e-04, 3.50160175e-04,
           1.02316575e-04],
          [9.97562170e-01, 8.65129172e-04, 1.40392059e-03,
           1.68738916e-04]],

         [[9.89409328e-01, 5.89353079e-03, 3.33353714e-03,
           1.36352459e-03],
          [9.91611838e-01, 4.81360639e-03, 2.66590435e-03,
           9.08648595e-04],
          [9.96329367e-01, 2.17112596e-03, 1.13520282e-03,
           3.64254462e-04],
          ...,
          [9.97528136e-01, 1.54918956e-03, 6.91657769e-04,
           2.31017402e-04],
          [9.96658683e-01, 2.04944168e-03, 1.00600405e-03,
           2.85876740e-04],
          [9.90799069e-01, 3.45694227e-03, 5.20149805e-03,
           5.42537251e-04]]],


        [[[9.99034643e-01, 2.72759935e-04, 4.81420982e-04,
           2.11260165e-04],
          [9.99806702e-01, 5.56867963e-05, 7.64984725e-05,
           6.12136573e-05],
          [9.99848962e-01, 4.61051859e-05, 4.91958235e-05,
           5.56771520e-05],
          ...,
          [9.99837399e-01, 4.49757790e-05, 5.55153238e-05,
           6.20964638e-05],
          [9.99824107e-01, 4.16849471e-05, 7.54259891e-05,
           5.87257455e-05],
          [9.99376476e-01, 2.85321235e-04, 2.23486946e-04,
           1.14716720e-04]],

         [[9.99795020e-01, 5.27214797e-05, 1.00701000e-04,
           5.16738510e-05],
          [9.99907494e-01, 3.23737586e-05, 2.92950717e-05,
           3.08025337e-05],
          [9.99931931e-01, 2.76866667e-05, 1.70700023e-05,
           2.33072642e-05],
          ...,
          [9.99932051e-01, 2.17964607e-05, 1.75519544e-05,
           2.85385831e-05],
          [9.99928713e-01, 1.86747220e-05, 2.62373360e-05,
           2.63694328e-05],
          [9.99855399e-01, 6.57953642e-05, 4.96881621e-05,
           2.90789158e-05]],

         [[9.99869704e-01, 3.19618630e-05, 4.91672436e-05,
           4.92039253e-05],
          [9.99887586e-01, 3.61158527e-05, 2.89733598e-05,
           4.72529682e-05],
          [9.99920249e-01, 2.91857141e-05, 1.75152618e-05,
           3.30729454e-05],
          ...,
          [9.99950409e-01, 1.57923860e-05, 9.66658081e-06,
           2.41810594e-05],
          [9.99932408e-01, 2.05315973e-05, 2.13792919e-05,
           2.57138126e-05],
          [9.99921799e-01, 3.49940346e-05, 2.37173117e-05,
           1.94652457e-05]],

         ...,

         [[9.99841332e-01, 6.72839014e-05, 4.63878023e-05,
           4.49557156e-05],
          [9.99877334e-01, 5.10284226e-05, 3.10249779e-05,
           4.05660139e-05],
          [9.99921799e-01, 3.32600212e-05, 1.84310120e-05,
           2.64762930e-05],
          ...,
          [9.99895692e-01, 5.45718867e-05, 2.28149511e-05,
           2.68760705e-05],
          [9.99756277e-01, 1.15980154e-04, 7.55704896e-05,
           5.21945549e-05],
          [9.99768674e-01, 8.71683587e-05, 7.86228557e-05,
           6.56253542e-05]],

         [[9.99657631e-01, 1.50681881e-04, 9.88328757e-05,
           9.28851878e-05],
          [9.99811232e-01, 6.98095755e-05, 6.56893753e-05,
           5.32191079e-05],
          [9.99861360e-01, 5.64193178e-05, 3.73575604e-05,
           4.49207000e-05],
          ...,
          [9.99873281e-01, 6.90755478e-05, 2.49412988e-05,
           3.25721121e-05],
          [9.99690890e-01, 1.60340802e-04, 8.93341276e-05,
           5.94722551e-05],
          [9.99680519e-01, 1.12228918e-04, 1.43234880e-04,
           6.39842328e-05]],

         [[9.98285711e-01, 7.27911363e-04, 7.04177131e-04,
           2.82095600e-04],
          [9.99095440e-01, 3.18300416e-04, 3.91058507e-04,
           1.95169690e-04],
          [9.99450862e-01, 2.21560927e-04, 2.03588701e-04,
           1.23979102e-04],
          ...,
          [9.99588430e-01, 1.98397931e-04, 1.27525753e-04,
           8.56931147e-05],
          [9.99329209e-01, 3.21997853e-04, 2.28265781e-04,
           1.20593839e-04],
          [9.97767091e-01, 5.70161093e-04, 1.36191153e-03,
           3.00788786e-04]]],


        [[[9.99287188e-01, 2.66208837e-04, 3.46111134e-04,
           1.00528596e-04],
          [9.99860287e-01, 5.52107340e-05, 5.85290472e-05,
           2.59243971e-05],
          [9.99892831e-01, 4.50540429e-05, 3.58315992e-05,
           2.63058173e-05],
          ...,
          [9.99884129e-01, 3.44036780e-05, 4.65776138e-05,
           3.48105750e-05],
          [9.99864101e-01, 3.52807219e-05, 6.65741245e-05,
           3.40645674e-05],
          [9.99515772e-01, 2.13934560e-04, 1.73107284e-04,
           9.72677881e-05]],

         [[9.99839425e-01, 4.97812798e-05, 8.07994511e-05,
           2.99158455e-05],
          [9.99910712e-01, 3.28265232e-05, 3.43331703e-05,
           2.21696355e-05],
          [9.99929905e-01, 2.51251804e-05, 2.49971254e-05,
           1.99968581e-05],
          ...,
          [9.99951243e-01, 1.39569611e-05, 1.44249907e-05,
           2.03737181e-05],
          [9.99925733e-01, 1.81043542e-05, 2.77030285e-05,
           2.84670477e-05],
          [9.99915242e-01, 3.05431022e-05, 3.16418336e-05,
           2.26316715e-05]],

         [[9.99922991e-01, 2.81753546e-05, 2.81043449e-05,
           2.07223693e-05],
          [9.99894857e-01, 3.79539670e-05, 3.21236257e-05,
           3.50878254e-05],
          [9.99910593e-01, 2.94432739e-05, 2.91037159e-05,
           3.08231938e-05],
          ...,
          [9.99940515e-01, 1.53645633e-05, 1.81476480e-05,
           2.59084354e-05],
          [9.99923587e-01, 2.07720841e-05, 2.62808499e-05,
           2.93472185e-05],
          [9.99930382e-01, 2.26740140e-05, 2.57094707e-05,
           2.12371797e-05]],

         ...,

         [[9.99824703e-01, 6.90325396e-05, 6.29078568e-05,
           4.33599016e-05],
          [9.99875307e-01, 3.18411767e-05, 3.82444050e-05,
           5.45846706e-05],
          [9.99844313e-01, 3.89831475e-05, 5.25518444e-05,
           6.41540901e-05],
          ...,
          [9.99898911e-01, 3.35073964e-05, 2.95840528e-05,
           3.79733101e-05],
          [9.99770105e-01, 7.10289823e-05, 8.02793220e-05,
           7.85967204e-05],
          [9.99741137e-01, 6.20497012e-05, 8.83384782e-05,
           1.08427957e-04]],

         [[9.99763787e-01, 8.80170555e-05, 8.23086957e-05,
           6.58052668e-05],
          [9.99850154e-01, 4.06552645e-05, 4.54708570e-05,
           6.36550321e-05],
          [9.99837637e-01, 4.80927047e-05, 4.94521919e-05,
           6.48324349e-05],
          ...,
          [9.99874115e-01, 4.77265094e-05, 2.99597123e-05,
           4.82053038e-05],
          [9.99734819e-01, 1.03805680e-04, 9.25242930e-05,
           6.88097862e-05],
          [9.99723375e-01, 8.40401044e-05, 1.11300134e-04,
           8.12995640e-05]],

         [[9.99368250e-01, 2.54080020e-04, 2.40778929e-04,
           1.36875969e-04],
          [9.99579847e-01, 1.32292669e-04, 1.54157751e-04,
           1.33677444e-04],
          [9.99679446e-01, 1.16444913e-04, 1.22264915e-04,
           8.19251654e-05],
          ...,
          [9.99738872e-01, 9.93365466e-05, 9.07504000e-05,
           7.09411906e-05],
          [9.99533415e-01, 2.04989628e-04, 1.50734428e-04,
           1.10886700e-04],
          [9.98075366e-01, 4.90157050e-04, 1.12852885e-03,
           3.05870111e-04]]],


        ...,


        [[[9.99300838e-01, 3.53688229e-04, 2.31463709e-04,
           1.13970484e-04],
          [9.99841452e-01, 7.32106710e-05, 3.61740240e-05,
           4.91912724e-05],
          [9.99837875e-01, 7.91086932e-05, 3.87675682e-05,
           4.42474447e-05],
          ...,
          [9.99840975e-01, 9.05060733e-05, 2.66215302e-05,
           4.18870914e-05],
          [9.99832749e-01, 9.33061674e-05, 3.83434963e-05,
           3.55391312e-05],
          [9.98301268e-01, 9.10201459e-04, 4.86310018e-04,
           3.02184199e-04]],

         [[9.99829412e-01, 8.62253655e-05, 4.66271995e-05,
           3.77669130e-05],
          [9.99906540e-01, 3.30389812e-05, 2.21030241e-05,
           3.83437655e-05],
          [9.99914885e-01, 2.62688936e-05, 2.20190304e-05,
           3.68471628e-05],
          ...,
          [9.99848366e-01, 7.17426519e-05, 2.66443567e-05,
           5.32037302e-05],
          [9.99885201e-01, 5.66347881e-05, 3.20303770e-05,
           2.61597161e-05],
          [9.99881983e-01, 3.81687641e-05, 5.30539219e-05,
           2.68128260e-05]],

         [[9.99837995e-01, 7.13955160e-05, 4.58150462e-05,
           4.47471684e-05],
          [9.99896526e-01, 2.31496469e-05, 2.08999063e-05,
           5.94021185e-05],
          [9.99913812e-01, 2.00098530e-05, 1.71976826e-05,
           4.89461054e-05],
          ...,
          [9.99878049e-01, 4.70436571e-05, 2.25250878e-05,
           5.23338058e-05],
          [9.99867320e-01, 4.87465077e-05, 3.34203323e-05,
           5.04919408e-05],
          [9.99844432e-01, 3.38349564e-05, 6.14866949e-05,
           6.02443288e-05]],

         ...,

         [[9.99814093e-01, 7.32867629e-05, 5.81076165e-05,
           5.45800285e-05],
          [9.99890685e-01, 2.43747181e-05, 2.73118021e-05,
           5.76348248e-05],
          [9.99864817e-01, 2.94512756e-05, 3.47339665e-05,
           7.10336099e-05],
          ...,
          [9.99895453e-01, 3.54942749e-05, 2.66876250e-05,
           4.22926714e-05],
          [9.99832273e-01, 5.06948418e-05, 5.41831323e-05,
           6.28399212e-05],
          [9.99739945e-01, 5.82654466e-05, 1.00074998e-04,
           1.01653568e-04]],

         [[9.99734581e-01, 1.09307992e-04, 7.69725666e-05,
           7.91177954e-05],
          [9.99807894e-01, 5.25463656e-05, 4.54054098e-05,
           9.41985418e-05],
          [9.99875307e-01, 3.26805566e-05, 3.39153194e-05,
           5.81150489e-05],
          ...,
          [9.99891996e-01, 4.05584469e-05, 2.50091725e-05,
           4.24266800e-05],
          [9.99838233e-01, 6.50608272e-05, 5.21704678e-05,
           4.44664583e-05],
          [9.99719322e-01, 7.22965560e-05, 1.32307221e-04,
           7.59960458e-05]],

         [[9.99437749e-01, 2.52708851e-04, 1.80511619e-04,
           1.29038453e-04],
          [9.99701083e-01, 1.00051082e-04, 9.42581319e-05,
           1.04497041e-04],
          [9.99803007e-01, 6.51406081e-05, 7.05487473e-05,
           6.12785007e-05],
          ...,
          [9.99779165e-01, 8.98154613e-05, 7.14843845e-05,
           5.95225029e-05],
          [9.99652743e-01, 1.26449901e-04, 1.33414112e-04,
           8.74455727e-05],
          [9.97683525e-01, 6.36129640e-04, 1.35742594e-03,
           3.22880020e-04]]],


        [[[9.97767925e-01, 1.16152002e-03, 7.91913772e-04,
           2.78662308e-04],
          [9.99434650e-01, 3.34421638e-04, 1.21378507e-04,
           1.09486224e-04],
          [9.99605000e-01, 2.65664421e-04, 6.96707575e-05,
           5.97263752e-05],
          ...,
          [9.99626279e-01, 2.79499160e-04, 5.34182363e-05,
           4.08691558e-05],
          [9.99407291e-01, 4.04188264e-04, 1.45405807e-04,
           4.30248947e-05],
          [9.97677267e-01, 1.52264105e-03, 5.68373944e-04,
           2.31713726e-04]],

         [[9.99678612e-01, 1.71684791e-04, 9.06558344e-05,
           5.89816518e-05],
          [9.99871850e-01, 5.95784550e-05, 2.64775463e-05,
           4.20740362e-05],
          [9.99920130e-01, 3.58462130e-05, 2.19872527e-05,
           2.20380098e-05],
          ...,
          [9.99873877e-01, 8.17347391e-05, 2.02339306e-05,
           2.41425478e-05],
          [9.99800026e-01, 1.37828494e-04, 4.43887038e-05,
           1.78797363e-05],
          [9.99736488e-01, 1.19120385e-04, 1.15709183e-04,
           2.85570932e-05]],

         [[9.99728024e-01, 1.16634292e-04, 8.48192649e-05,
           7.04606355e-05],
          [9.99904156e-01, 3.28702918e-05, 2.01162911e-05,
           4.28489111e-05],
          [9.99932766e-01, 2.14083520e-05, 1.72521522e-05,
           2.85388742e-05],
          ...,
          [9.99876857e-01, 6.14961391e-05, 2.26866414e-05,
           3.88907283e-05],
          [9.99818504e-01, 9.87977983e-05, 4.62423959e-05,
           3.65136875e-05],
          [9.99873281e-01, 5.00819697e-05, 4.92847357e-05,
           2.73384012e-05]],

         ...,

         [[9.99697208e-01, 1.13263130e-04, 1.09677509e-04,
           7.99260524e-05],
          [9.99883175e-01, 3.42631793e-05, 3.17601771e-05,
           5.08462617e-05],
          [9.99886155e-01, 2.77171530e-05, 4.05314167e-05,
           4.55654808e-05],
          ...,
          [9.99906898e-01, 3.46774104e-05, 2.91811211e-05,
           2.92467048e-05],
          [9.99869704e-01, 6.41607985e-05, 4.16209841e-05,
           2.45682349e-05],
          [9.99696016e-01, 1.12213325e-04, 1.30385422e-04,
           6.13769880e-05]],

         [[9.99533772e-01, 2.07517238e-04, 1.53956702e-04,
           1.04758023e-04],
          [9.99861836e-01, 5.58350439e-05, 3.25201909e-05,
           4.98091758e-05],
          [9.99925971e-01, 2.82355850e-05, 2.04127009e-05,
           2.53386643e-05],
          ...,
          [9.99943495e-01, 2.50464309e-05, 1.55984708e-05,
           1.58857183e-05],
          [9.99872684e-01, 6.18611593e-05, 4.38820716e-05,
           2.15630134e-05],
          [9.99200642e-01, 3.20670049e-04, 3.67075292e-04,
           1.11609392e-04]],

         [[9.98680532e-01, 5.71000681e-04, 5.29114972e-04,
           2.19326699e-04],
          [9.99350965e-01, 1.86502570e-04, 2.49719451e-04,
           2.12800966e-04],
          [9.99625683e-01, 1.10223606e-04, 1.60946365e-04,
           1.03144463e-04],
          ...,
          [9.99592483e-01, 1.36978895e-04, 1.60994881e-04,
           1.09473025e-04],
          [9.99115288e-01, 2.98381725e-04, 4.36187751e-04,
           1.50137217e-04],
          [9.94751513e-01, 1.51614146e-03, 3.10643343e-03,
           6.25931134e-04]]],


        [[[9.91433382e-01, 5.17423777e-03, 2.48136232e-03,
           9.11031093e-04],
          [9.98268723e-01, 7.27709383e-04, 7.76922097e-04,
           2.26578122e-04],
          [9.98396933e-01, 7.91977101e-04, 6.34353142e-04,
           1.76724599e-04],
          ...,
          [9.98502254e-01, 7.70003360e-04, 5.98329876e-04,
           1.29417793e-04],
          [9.98060524e-01, 9.22355917e-04, 8.86410475e-04,
           1.30787565e-04],
          [9.93600368e-01, 3.09241796e-03, 2.57918355e-03,
           7.28085928e-04]],

         [[9.96487617e-01, 2.10357015e-03, 1.02771795e-03,
           3.81136051e-04],
          [9.99201477e-01, 3.81480408e-04, 2.60241097e-04,
           1.56802358e-04],
          [9.99717772e-01, 1.38822463e-04, 9.94525617e-05,
           4.39486066e-05],
          ...,
          [9.99590695e-01, 2.34880179e-04, 1.28817905e-04,
           4.55876507e-05],
          [9.98912811e-01, 5.83605201e-04, 4.28976055e-04,
           7.46496080e-05],
          [9.98374224e-01, 6.31318078e-04, 8.64961476e-04,
           1.29375767e-04]],

         [[9.98730242e-01, 6.08528731e-04, 4.36306873e-04,
           2.24905525e-04],
          [9.99737561e-01, 8.51281802e-05, 8.65133770e-05,
           9.08474321e-05],
          [9.99869704e-01, 4.95506465e-05, 4.07503903e-05,
           4.00033059e-05],
          ...,
          [9.99755919e-01, 1.11347392e-04, 7.22336554e-05,
           6.05375972e-05],
          [9.99538422e-01, 2.34634615e-04, 1.50953274e-04,
           7.60594994e-05],
          [9.98594820e-01, 5.96523343e-04, 6.11035910e-04,
           1.97605084e-04]],

         ...,

         [[9.98673201e-01, 5.54873142e-04, 5.32043050e-04,
           2.39829125e-04],
          [9.99701321e-01, 8.83858593e-05, 1.18826196e-04,
           9.13985641e-05],
          [9.99806464e-01, 5.23661984e-05, 8.23695300e-05,
           5.88755574e-05],
          ...,
          [9.99748886e-01, 8.32106016e-05, 1.06156105e-04,
           6.17819314e-05],
          [9.99437153e-01, 1.98566267e-04, 2.62376561e-04,
           1.01828839e-04],
          [9.98232186e-01, 6.29680057e-04, 8.61209992e-04,
           2.77000683e-04]],

         [[9.97966647e-01, 9.58837511e-04, 7.40323740e-04,
           3.34204087e-04],
          [9.99568880e-01, 1.40249904e-04, 1.47786704e-04,
           1.43077734e-04],
          [9.99783218e-01, 7.07720901e-05, 7.58220776e-05,
           7.01576791e-05],
          ...,
          [9.99731004e-01, 9.74382274e-05, 9.71277987e-05,
           7.43855053e-05],
          [9.98906136e-01, 4.60910640e-04, 4.58714785e-04,
           1.74162968e-04],
          [9.97364938e-01, 8.86870374e-04, 1.45709887e-03,
           2.91127828e-04]],

         [[9.96303082e-01, 1.49184221e-03, 1.72772270e-03,
           4.77360794e-04],
          [9.98234510e-01, 5.18245564e-04, 9.03294247e-04,
           3.43950902e-04],
          [9.99000490e-01, 2.59864115e-04, 5.43159316e-04,
           1.96555338e-04],
          ...,
          [9.97787595e-01, 6.19489525e-04, 1.24705012e-03,
           3.45870154e-04],
          [9.96787071e-01, 9.89585067e-04, 1.76459237e-03,
           4.58762137e-04],
          [9.89817798e-01, 3.97269567e-03, 5.20610856e-03,
           1.00340834e-03]]]]], dtype=float32)>}2021-07-14 12:41:20.766734: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.96535301e-01, 1.15471683e-03, 1.75829907e-03,
           5.51657693e-04],
          [9.99121606e-01, 3.80217243e-04, 3.22484673e-04,
           1.75670823e-04],
          [9.98965502e-01, 4.03016369e-04, 4.39114898e-04,
           1.92421809e-04],
          ...,
          [9.99451220e-01, 1.99518923e-04, 2.39998350e-04,
           1.09258988e-04],
          [9.99155402e-01, 3.52647738e-04, 3.38489539e-04,
           1.53437679e-04],
          [9.95758712e-01, 1.82133878e-03, 2.02390179e-03,
           3.95952287e-04]],

         [[9.99434173e-01, 1.70903702e-04, 2.74082850e-04,
           1.20917466e-04],
          [9.99791443e-01, 6.06388494e-05, 9.28476657e-05,
           5.50380246e-05],
          [9.99852180e-01, 4.36863847e-05, 6.93953116e-05,
           3.46156703e-05],
          ...,
          [9.99898911e-01, 3.51859817e-05, 4.25907965e-05,
           2.33117826e-05],
          [9.99810398e-01, 5.97592152e-05, 9.37606892e-05,
           3.61839775e-05],
          [9.98379946e-01, 7.76279776e-04, 6.53572206e-04,
           1.90256236e-04]],

         [[9.98537421e-01, 3.26925423e-04, 8.36983672e-04,
           2.98693834e-04],
          [9.99725282e-01, 6.86715211e-05, 7.72627900e-05,
           1.28823958e-04],
          [9.99567091e-01, 9.93826689e-05, 1.92845124e-04,
           1.40646647e-04],
          ...,
          [9.99502897e-01, 1.18902128e-04, 1.86452686e-04,
           1.91695173e-04],
          [9.99385715e-01, 2.25139433e-04, 1.69335224e-04,
           2.19709415e-04],
          [9.94405389e-01, 2.22264067e-03, 2.51534651e-03,
           8.56554718e-04]],

         ...,

         [[9.99185503e-01, 4.61881835e-04, 2.12134415e-04,
           1.40406046e-04],
          [9.99511480e-01, 2.56234081e-04, 1.23097110e-04,
           1.09300177e-04],
          [9.99705851e-01, 1.52917128e-04, 8.14699815e-05,
           5.97781072e-05],
          ...,
          [9.99611080e-01, 2.54460203e-04, 8.39165441e-05,
           5.06318829e-05],
          [9.99358118e-01, 3.54874152e-04, 2.10183716e-04,
           7.68429745e-05],
          [9.98793125e-01, 4.84713557e-04, 5.97472244e-04,
           1.24685292e-04]],

         [[9.97319877e-01, 1.50619447e-03, 8.31299578e-04,
           3.42653686e-04],
          [9.98822272e-01, 5.80646505e-04, 3.90852219e-04,
           2.06214856e-04],
          [9.99412060e-01, 3.05878668e-04, 1.93622283e-04,
           8.85077025e-05],
          ...,
          [9.99491811e-01, 2.99672422e-04, 1.46840976e-04,
           6.16512261e-05],
          [9.99046981e-01, 4.74376429e-04, 3.73784656e-04,
           1.04913204e-04],
          [9.97422934e-01, 9.10066417e-04, 1.49400346e-03,
           1.73029563e-04]],

         [[9.89447474e-01, 5.89451147e-03, 3.29605769e-03,
           1.36201177e-03],
          [9.91848350e-01, 4.63110581e-03, 2.61548348e-03,
           9.05079767e-04],
          [9.96485829e-01, 2.08436977e-03, 1.06033427e-03,
           3.69450863e-04],
          ...,
          [9.97572482e-01, 1.51578523e-03, 6.82384300e-04,
           2.29384881e-04],
          [9.96641159e-01, 2.05844711e-03, 1.01302215e-03,
           2.87315372e-04],
          [9.90786374e-01, 3.44315334e-03, 5.23122447e-03,
           5.39221393e-04]]],


        [[[9.98821914e-01, 3.77746008e-04, 4.77207039e-04,
           3.23055807e-04],
          [9.99818027e-01, 5.27671582e-05, 6.69275905e-05,
           6.23074448e-05],
          [9.99804676e-01, 6.28450143e-05, 6.90001616e-05,
           6.35182369e-05],
          ...,
          [9.99716818e-01, 1.00901634e-04, 1.03457409e-04,
           7.88168109e-05],
          [9.99792635e-01, 6.77414719e-05, 6.30568393e-05,
           7.66305820e-05],
          [9.98122036e-01, 9.57662181e-04, 5.69891126e-04,
           3.50307790e-04]],

         [[9.98892367e-01, 2.63183581e-04, 5.66347269e-04,
           2.78152816e-04],
          [9.99807537e-01, 5.64260736e-05, 6.82748287e-05,
           6.77952848e-05],
          [9.99754369e-01, 8.45900649e-05, 7.44641147e-05,
           8.65127731e-05],
          ...,
          [9.99647260e-01, 1.21544501e-04, 1.13378512e-04,
           1.17836542e-04],
          [9.99736607e-01, 9.20341045e-05, 6.42224113e-05,
           1.07177337e-04],
          [9.98003185e-01, 1.09208375e-03, 4.40598378e-04,
           4.64181183e-04]],

         [[9.96898770e-01, 8.82856722e-04, 1.48246577e-03,
           7.35883776e-04],
          [9.99172986e-01, 3.00038868e-04, 2.97416205e-04,
           2.29571771e-04],
          [9.98934090e-01, 4.34071117e-04, 4.04750055e-04,
           2.27124750e-04],
          ...,
          [9.97525871e-01, 1.40281371e-03, 7.36909395e-04,
           3.34358600e-04],
          [9.98838127e-01, 5.89745876e-04, 2.16799468e-04,
           3.55374621e-04],
          [9.94555831e-01, 2.71254871e-03, 1.32012612e-03,
           1.41149375e-03]],

         ...,

         [[9.99838948e-01, 6.71279195e-05, 4.80550334e-05,
           4.58450704e-05],
          [9.99873400e-01, 5.16945620e-05, 3.28714123e-05,
           4.20318684e-05],
          [9.99909759e-01, 3.80187630e-05, 2.14168431e-05,
           3.08330491e-05],
          ...,
          [9.99894619e-01, 5.59951513e-05, 2.28005483e-05,
           2.65125127e-05],
          [9.99756396e-01, 1.17016629e-04, 7.57564485e-05,
           5.08363701e-05],
          [9.99762118e-01, 8.98404032e-05, 8.15649764e-05,
           6.64074760e-05]],

         [[9.99655485e-01, 1.49751373e-04, 1.00980826e-04,
           9.37952573e-05],
          [9.99801219e-01, 7.27441511e-05, 6.79909135e-05,
           5.80534143e-05],
          [9.99855280e-01, 5.57260028e-05, 3.98142220e-05,
           4.90828133e-05],
          ...,
          [9.99872565e-01, 6.89725421e-05, 2.54815914e-05,
           3.29424984e-05],
          [9.99683022e-01, 1.64024998e-04, 9.34411655e-05,
           5.96340469e-05],
          [9.99659657e-01, 1.20488272e-04, 1.53395114e-04,
           6.64469189e-05]],

         [[9.98311758e-01, 7.14554044e-04, 6.95054536e-04,
           2.78686610e-04],
          [9.99088883e-01, 3.21804400e-04, 3.87174194e-04,
           2.02152805e-04],
          [9.99453604e-01, 2.17236156e-04, 2.05656223e-04,
           1.23584206e-04],
          ...,
          [9.99581754e-01, 2.00459006e-04, 1.30296190e-04,
           8.75110200e-05],
          [9.99282897e-01, 3.40501021e-04, 2.50822253e-04,
           1.25838546e-04],
          [9.97662067e-01, 6.00778963e-04, 1.42970565e-03,
           3.07343435e-04]]],


        [[[9.98383045e-01, 5.48314245e-04, 8.01994931e-04,
           2.66675052e-04],
          [9.99707401e-01, 7.10437671e-05, 1.58880808e-04,
           6.26080728e-05],
          [9.99683499e-01, 9.79920587e-05, 1.49873871e-04,
           6.87390202e-05],
          ...,
          [9.99795854e-01, 4.68467915e-05, 1.07016582e-04,
           5.02699149e-05],
          [9.99820173e-01, 4.78835354e-05, 7.95895394e-05,
           5.23713097e-05],
          [9.98824060e-01, 4.61991993e-04, 4.21890785e-04,
           2.92003970e-04]],

         [[9.97598112e-01, 6.26822584e-04, 1.46751781e-03,
           3.07498180e-04],
          [9.99571979e-01, 1.40055869e-04, 1.99563394e-04,
           8.84824476e-05],
          [9.99504924e-01, 1.52942535e-04, 2.42555965e-04,
           9.95817900e-05],
          ...,
          [9.99236822e-01, 2.80542648e-04, 3.56909964e-04,
           1.25779465e-04],
          [9.99612510e-01, 1.55075977e-04, 1.28499247e-04,
           1.03978731e-04],
          [9.97761130e-01, 1.01604243e-03, 7.38915231e-04,
           4.83888638e-04]],

         [[9.90350783e-01, 3.12636513e-03, 5.63530345e-03,
           8.87594419e-04],
          [9.96789634e-01, 9.64714331e-04, 1.85821659e-03,
           3.87348147e-04],
          [9.95693386e-01, 1.06172543e-03, 2.96181696e-03,
           2.83066678e-04],
          ...,
          [9.96382594e-01, 1.48768467e-03, 1.83567940e-03,
           2.94005469e-04],
          [9.94888842e-01, 3.02446587e-03, 1.62931287e-03,
           4.57400107e-04],
          [9.90293503e-01, 4.93391603e-03, 3.21346428e-03,
           1.55913713e-03]],

         ...,

         [[9.99823391e-01, 6.97753567e-05, 6.33378295e-05,
           4.35153124e-05],
          [9.99874949e-01, 3.24806933e-05, 3.89203342e-05,
           5.35170402e-05],
          [9.99839306e-01, 4.13243179e-05, 5.58769934e-05,
           6.33861564e-05],
          ...,
          [9.99899149e-01, 3.58929756e-05, 2.93491339e-05,
           3.56585479e-05],
          [9.99774396e-01, 7.45145444e-05, 7.91242564e-05,
           7.19582458e-05],
          [9.99734461e-01, 6.70939626e-05, 9.18794758e-05,
           1.06599131e-04]],

         [[9.99762237e-01, 8.81469532e-05, 8.36097606e-05,
           6.59577854e-05],
          [9.99843597e-01, 4.23653182e-05, 4.79676637e-05,
           6.60842925e-05],
          [9.99838114e-01, 4.84663615e-05, 4.99280795e-05,
           6.34449898e-05],
          ...,
          [9.99869466e-01, 5.11366561e-05, 3.15562793e-05,
           4.78312213e-05],
          [9.99732792e-01, 1.08426648e-04, 9.29408270e-05,
           6.58503122e-05],
          [9.99698281e-01, 9.36735887e-05, 1.23275895e-04,
           8.47646734e-05]],

         [[9.99357164e-01, 2.60358356e-04, 2.45073170e-04,
           1.37482522e-04],
          [9.99566138e-01, 1.35042661e-04, 1.61634161e-04,
           1.37207870e-04],
          [9.99673247e-01, 1.20249526e-04, 1.25448700e-04,
           8.10265919e-05],
          ...,
          [9.99729812e-01, 1.03278748e-04, 9.56685617e-05,
           7.11235189e-05],
          [9.99501944e-01, 2.20149857e-04, 1.64953206e-04,
           1.12879476e-04],
          [9.97976363e-01, 5.17670938e-04, 1.19609677e-03,
           3.09930416e-04]]],


        ...,


        [[[9.99398947e-01, 2.95461301e-04, 2.03133837e-04,
           1.02508347e-04],
          [9.99864817e-01, 6.04824454e-05, 3.16361657e-05,
           4.30620057e-05],
          [9.99871492e-01, 5.79375228e-05, 3.23766981e-05,
           3.81278696e-05],
          ...,
          [9.99849558e-01, 8.12234866e-05, 2.71575718e-05,
           4.21123223e-05],
          [9.99819100e-01, 9.09353694e-05, 4.81857787e-05,
           4.18101845e-05],
          [9.98536944e-01, 7.47493468e-04, 4.24103200e-04,
           2.91379605e-04]],

         [[9.99817073e-01, 9.13407348e-05, 5.07664445e-05,
           4.08517808e-05],
          [9.99894381e-01, 3.68395886e-05, 2.57461797e-05,
           4.30022919e-05],
          [9.99918342e-01, 2.35939624e-05, 2.04627922e-05,
           3.76139105e-05],
          ...,
          [9.99851704e-01, 6.46948611e-05, 3.01317614e-05,
           5.34783030e-05],
          [9.99842763e-01, 7.72210406e-05, 4.10407411e-05,
           3.88815024e-05],
          [9.99866486e-01, 3.90144342e-05, 6.02379005e-05,
           3.42610729e-05]],

         [[9.99854088e-01, 6.78007636e-05, 3.95266507e-05,
           3.85642052e-05],
          [9.99909043e-01, 2.09277932e-05, 1.84403762e-05,
           5.14996718e-05],
          [9.99928832e-01, 1.74387096e-05, 1.46025532e-05,
           3.92141628e-05],
          ...,
          [9.99884248e-01, 4.62885910e-05, 2.21375067e-05,
           4.73132350e-05],
          [9.99849558e-01, 5.53743957e-05, 3.91036556e-05,
           5.58985048e-05],
          [9.99835730e-01, 3.61574675e-05, 6.38649217e-05,
           6.42711748e-05]],

         ...,

         [[9.99815166e-01, 7.27883962e-05, 5.75344748e-05,
           5.44904215e-05],
          [9.99890566e-01, 2.42842962e-05, 2.69425018e-05,
           5.81534732e-05],
          [9.99866486e-01, 2.87408675e-05, 3.37464699e-05,
           7.10409076e-05],
          ...,
          [9.99895930e-01, 3.51708150e-05, 2.65062299e-05,
           4.23423298e-05],
          [9.99829888e-01, 5.19278510e-05, 5.48454300e-05,
           6.32374577e-05],
          [9.99739945e-01, 5.88951116e-05, 1.00041609e-04,
           1.01103455e-04]],

         [[9.99735653e-01, 1.08629189e-04, 7.67218662e-05,
           7.90273843e-05],
          [9.99808729e-01, 5.19265013e-05, 4.49007748e-05,
           9.43943960e-05],
          [9.99876022e-01, 3.21577791e-05, 3.35902623e-05,
           5.82451539e-05],
          ...,
          [9.99891758e-01, 4.05100400e-05, 2.51294714e-05,
           4.25413309e-05],
          [9.99834895e-01, 6.66988271e-05, 5.31914993e-05,
           4.51750384e-05],
          [9.99720514e-01, 7.26385988e-05, 1.31508685e-04,
           7.52683627e-05]],

         [[9.99440849e-01, 2.51368183e-04, 1.78977134e-04,
           1.28783140e-04],
          [9.99701023e-01, 9.97729367e-05, 9.41474354e-05,
           1.05108011e-04],
          [9.99803722e-01, 6.46686240e-05, 7.01014651e-05,
           6.14956880e-05],
          ...,
          [9.99777973e-01, 8.97629579e-05, 7.22936893e-05,
           5.99416926e-05],
          [9.99651551e-01, 1.27310675e-04, 1.33861817e-04,
           8.73441168e-05],
          [9.97679055e-01, 6.34065946e-04, 1.36434566e-03,
           3.22542182e-04]]],


        [[[9.98157918e-01, 9.60195961e-04, 6.37751189e-04,
           2.44086768e-04],
          [9.99568880e-01, 2.55557185e-04, 8.34930543e-05,
           9.20487728e-05],
          [9.99709070e-01, 1.77265087e-04, 5.99408777e-05,
           5.37456217e-05],
          ...,
          [9.99654412e-01, 2.50315643e-04, 5.31884943e-05,
           4.19853277e-05],
          [9.99386907e-01, 4.11299319e-04, 1.53566783e-04,
           4.81991374e-05],
          [9.97560501e-01, 1.47215812e-03, 7.05761428e-04,
           2.61470646e-04]],

         [[9.99709547e-01, 1.45595084e-04, 8.45665927e-05,
           6.02548134e-05],
          [9.99859452e-01, 5.74891419e-05, 3.38267237e-05,
           4.92871586e-05],
          [9.99904156e-01, 3.62070095e-05, 2.89978070e-05,
           3.05929352e-05],
          ...,
          [9.99818861e-01, 1.07119318e-04, 3.53705545e-05,
           3.86330794e-05],
          [9.99749720e-01, 1.61554432e-04, 6.05301830e-05,
           2.81413650e-05],
          [9.99788702e-01, 9.48033485e-05, 9.10914459e-05,
           2.54732331e-05]],

         [[9.99745190e-01, 1.09832145e-04, 7.75654044e-05,
           6.73171526e-05],
          [9.99903560e-01, 3.37075144e-05, 1.94667300e-05,
           4.31749868e-05],
          [9.99927878e-01, 2.11626466e-05, 1.90283990e-05,
           3.18747188e-05],
          ...,
          [9.99877810e-01, 6.04909583e-05, 2.36043034e-05,
           3.81291647e-05],
          [9.99808371e-01, 1.01758109e-04, 4.97528163e-05,
           4.01631951e-05],
          [9.99870658e-01, 4.81512870e-05, 5.09665588e-05,
           3.02468652e-05]],

         ...,

         [[9.99699354e-01, 1.12469752e-04, 1.08585467e-04,
           7.95740125e-05],
          [9.99883413e-01, 3.42180901e-05, 3.14608333e-05,
           5.09595775e-05],
          [9.99886274e-01, 2.76674000e-05, 3.99479686e-05,
           4.61631353e-05],
          ...,
          [9.99907017e-01, 3.45431035e-05, 2.93480480e-05,
           2.90139906e-05],
          [9.99868155e-01, 6.52853560e-05, 4.19569988e-05,
           2.45186948e-05],
          [9.99701917e-01, 1.11553411e-04, 1.27115592e-04,
           5.94102166e-05]],

         [[9.99537826e-01, 2.05343502e-04, 1.52262248e-04,
           1.04645507e-04],
          [9.99861836e-01, 5.57838430e-05, 3.23016247e-05,
           5.00377610e-05],
          [9.99925733e-01, 2.82136134e-05, 2.02827032e-05,
           2.56986878e-05],
          ...,
          [9.99942541e-01, 2.53616163e-05, 1.59366737e-05,
           1.61248845e-05],
          [9.99869466e-01, 6.36622135e-05, 4.50709122e-05,
           2.18353125e-05],
          [9.99203026e-01, 3.18378996e-04, 3.68340494e-04,
           1.10215457e-04]],

         [[9.98685777e-01, 5.68447926e-04, 5.26687363e-04,
           2.19114168e-04],
          [9.99354422e-01, 1.85661003e-04, 2.47255521e-04,
           2.12764367e-04],
          [9.99630928e-01, 1.08900771e-04, 1.57411341e-04,
           1.02692822e-04],
          ...,
          [9.99591649e-01, 1.35457318e-04, 1.63319972e-04,
           1.09600587e-04],
          [9.99102592e-01, 2.99690000e-04, 4.46728664e-04,
           1.51092361e-04],
          [9.94699836e-01, 1.52640964e-03, 3.14524025e-03,
           6.28465787e-04]]],


        [[[9.92285967e-01, 4.70544444e-03, 2.16562743e-03,
           8.42962065e-04],
          [9.98303652e-01, 7.65089761e-04, 7.00610457e-04,
           2.30608857e-04],
          [9.98686969e-01, 6.32447656e-04, 5.12607105e-04,
           1.68016573e-04],
          ...,
          [9.98473346e-01, 8.29237397e-04, 5.53439138e-04,
           1.43943966e-04],
          [9.97990727e-01, 9.18093137e-04, 9.52070463e-04,
           1.39070529e-04],
          [9.92342055e-01, 3.46997660e-03, 3.34824272e-03,
           8.39719549e-04]],

         [[9.97101367e-01, 1.69071485e-03, 8.65752401e-04,
           3.42150219e-04],
          [9.99237895e-01, 3.45962035e-04, 2.62824557e-04,
           1.53319721e-04],
          [9.99750912e-01, 1.16312156e-04, 8.22612637e-05,
           5.04629061e-05],
          ...,
          [9.99536633e-01, 2.74239312e-04, 1.29085063e-04,
           6.00446110e-05],
          [9.98999059e-01, 5.70042524e-04, 3.53914220e-04,
           7.69598118e-05],
          [9.98350739e-01, 6.91436348e-04, 8.15564301e-04,
           1.42199846e-04]],

         [[9.98878896e-01, 5.30333840e-04, 3.81503487e-04,
           2.09238744e-04],
          [9.99755800e-01, 8.25740135e-05, 7.35524736e-05,
           8.80966327e-05],
          [9.99859691e-01, 5.10490354e-05, 4.25657781e-05,
           4.66633101e-05],
          ...,
          [9.99753177e-01, 1.09724242e-04, 7.36917937e-05,
           6.34033713e-05],
          [9.99617100e-01, 1.90528692e-04, 1.25821098e-04,
           6.65183907e-05],
          [9.98580933e-01, 5.72233461e-04, 6.21494895e-04,
           2.25409094e-04]],

         ...,

         [[9.98692095e-01, 5.46450261e-04, 5.23244962e-04,
           2.38265886e-04],
          [9.99702871e-01, 8.81444939e-05, 1.16989395e-04,
           9.18798105e-05],
          [9.99807894e-01, 5.22231385e-05, 8.08628029e-05,
           5.90793024e-05],
          ...,
          [9.99746859e-01, 8.40604407e-05, 1.06900370e-04,
           6.22204825e-05],
          [9.99439061e-01, 1.99559305e-04, 2.61400273e-04,
           9.99394106e-05],
          [9.98217523e-01, 6.40420418e-04, 8.65682669e-04,
           2.76364706e-04]],

         [[9.97990966e-01, 9.46060405e-04, 7.31435430e-04,
           3.31570569e-04],
          [9.99571860e-01, 1.39673561e-04, 1.45721715e-04,
           1.42782374e-04],
          [9.99786198e-01, 6.95892159e-05, 7.46752048e-05,
           6.95163835e-05],
          ...,
          [9.99728382e-01, 9.75002404e-05, 9.89859909e-05,
           7.51335538e-05],
          [9.98886526e-01, 4.67363221e-04, 4.70889121e-04,
           1.75232140e-04],
          [9.97356534e-01, 8.88465904e-04, 1.46433315e-03,
           2.90670112e-04]],

         [[9.96338964e-01, 1.47791894e-03, 1.70931593e-03,
           4.73825901e-04],
          [9.98255908e-01, 5.13309031e-04, 8.89183080e-04,
           3.41679668e-04],
          [9.99017596e-01, 2.56106781e-04, 5.31427213e-04,
           1.94886117e-04],
          ...,
          [9.97773945e-01, 6.17289916e-04, 1.25973497e-03,
           3.48935660e-04],
          [9.96746898e-01, 9.96820512e-04, 1.79378840e-03,
           4.62480297e-04],
          [9.89697278e-01, 4.00586985e-03, 5.28118992e-03,
           1.01574895e-03]]]]], dtype=float32)>}2021-07-14 12:41:21.061603: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.91295576e-01, 3.72336851e-03, 4.27023135e-03,
           7.10786786e-04],
          [9.95626211e-01, 2.29099416e-03, 1.64562452e-03,
           4.37073992e-04],
          [9.96663392e-01, 1.57728139e-03, 1.38168945e-03,
           3.77702265e-04],
          ...,
          [9.98038948e-01, 1.18611124e-03, 5.09380770e-04,
           2.65640556e-04],
          [9.97091889e-01, 1.72872469e-03, 9.01574735e-04,
           2.77814339e-04],
          [9.90617454e-01, 5.25342301e-03, 3.43704340e-03,
           6.92172034e-04]],

         [[9.98448014e-01, 7.56703317e-04, 6.15660276e-04,
           1.79503259e-04],
          [9.99219060e-01, 3.30489798e-04, 2.61389854e-04,
           1.88984050e-04],
          [9.99605834e-01, 1.40259770e-04, 1.52387933e-04,
           1.01531521e-04],
          ...,
          [9.99303937e-01, 3.52733507e-04, 2.12929808e-04,
           1.30394343e-04],
          [9.99347150e-01, 2.59366177e-04, 2.90001655e-04,
           1.03492355e-04],
          [9.98038113e-01, 6.15090074e-04, 1.16688025e-03,
           1.79893017e-04]],

         [[9.99052942e-01, 5.06599667e-04, 2.88710260e-04,
           1.51689062e-04],
          [9.99622107e-01, 1.86609570e-04, 1.03706509e-04,
           8.75979749e-05],
          [9.99801934e-01, 9.50814938e-05, 5.78853978e-05,
           4.51464148e-05],
          ...,
          [9.99644041e-01, 2.25407101e-04, 7.67769016e-05,
           5.36814769e-05],
          [9.99592721e-01, 1.98900059e-04, 1.46646140e-04,
           6.17077458e-05],
          [9.99110043e-01, 3.55187221e-04, 4.30288404e-04,
           1.04493942e-04]],

         ...,

         [[9.95812714e-01, 2.43305066e-03, 1.38576468e-03,
           3.68468609e-04],
          [9.98860359e-01, 6.38163416e-04, 3.94230767e-04,
           1.07359076e-04],
          [9.99110520e-01, 4.69868653e-04, 3.18764214e-04,
           1.00895275e-04],
          ...,
          [9.97842550e-01, 1.55397865e-03, 5.50368219e-04,
           5.30953293e-05],
          [9.96985376e-01, 1.55740418e-03, 1.38423836e-03,
           7.30146348e-05],
          [9.88204837e-01, 4.11164388e-03, 7.42393313e-03,
           2.59576307e-04]],

         [[9.87988949e-01, 6.70969253e-03, 4.74169990e-03,
           5.59688662e-04],
          [9.94561732e-01, 2.79471837e-03, 2.37348047e-03,
           2.70064862e-04],
          [9.96503830e-01, 1.49964099e-03, 1.84088724e-03,
           1.55648318e-04],
          ...,
          [9.92404878e-01, 3.46258469e-03, 4.04783012e-03,
           8.46434195e-05],
          [9.84867871e-01, 5.58534218e-03, 9.37512890e-03,
           1.71689142e-04],
          [9.65264857e-01, 9.80189629e-03, 2.44579446e-02,
           4.75371489e-04]],

         [[9.64534760e-01, 1.93119589e-02, 1.38949826e-02,
           2.25833897e-03],
          [9.71031964e-01, 1.77671164e-02, 9.84425191e-03,
           1.35667273e-03],
          [9.85239863e-01, 8.96394160e-03, 5.17871976e-03,
           6.17372803e-04],
          ...,
          [9.79689717e-01, 1.29153943e-02, 6.95837848e-03,
           4.36568953e-04],
          [9.68917072e-01, 1.62903108e-02, 1.41245201e-02,
           6.68041524e-04],
          [9.29188311e-01, 2.78884117e-02, 4.15475108e-02,
           1.37576926e-03]]],


        [[[9.98132169e-01, 8.54575657e-04, 7.15632865e-04,
           2.97665945e-04],
          [9.99197900e-01, 4.19322314e-04, 1.92928375e-04,
           1.89877523e-04],
          [9.99367654e-01, 3.50110640e-04, 1.53768982e-04,
           1.28505388e-04],
          ...,
          [9.99760807e-01, 1.47559869e-04, 3.81985483e-05,
           5.34773681e-05],
          [9.99665976e-01, 1.80846648e-04, 9.19024387e-05,
           6.11972282e-05],
          [9.97739673e-01, 1.30778376e-03, 6.00617728e-04,
           3.51972471e-04]],

         [[9.99637604e-01, 1.75580106e-04, 1.15116949e-04,
           7.17807052e-05],
          [9.99844074e-01, 7.71354680e-05, 3.32798118e-05,
           4.55127083e-05],
          [9.99868751e-01, 5.13065133e-05, 2.72171037e-05,
           5.27126940e-05],
          ...,
          [9.99841213e-01, 7.88422549e-05, 3.50341215e-05,
           4.49501349e-05],
          [9.99813855e-01, 7.81200288e-05, 5.68737560e-05,
           5.11840626e-05],
          [9.99723494e-01, 9.20212187e-05, 1.21065794e-04,
           6.34145545e-05]],

         [[9.99836802e-01, 7.64743745e-05, 4.60548363e-05,
           4.06504951e-05],
          [9.99901533e-01, 3.65876585e-05, 2.11880579e-05,
           4.07048792e-05],
          [9.99935627e-01, 2.28154277e-05, 1.44623418e-05,
           2.70848959e-05],
          ...,
          [9.99912500e-01, 3.90454879e-05, 1.69749292e-05,
           3.13718338e-05],
          [9.99883294e-01, 4.84818665e-05, 3.52210191e-05,
           3.29858267e-05],
          [9.99847412e-01, 4.82278811e-05, 5.63393842e-05,
           4.79048031e-05]],

         ...,

         [[9.99099255e-01, 3.87756678e-04, 3.94707138e-04,
           1.18230972e-04],
          [9.99723971e-01, 1.17582778e-04, 8.87968636e-05,
           6.96282950e-05],
          [9.99763906e-01, 8.87953283e-05, 8.80436710e-05,
           5.92964425e-05],
          ...,
          [9.99431551e-01, 4.18819429e-04, 1.24122336e-04,
           2.55249888e-05],
          [9.99382019e-01, 3.33931093e-04, 2.65344890e-04,
           1.87321129e-05],
          [9.96191382e-01, 2.11551110e-03, 1.51367940e-03,
           1.79393464e-04]],

         [[9.96470451e-01, 1.41539972e-03, 1.82992255e-03,
           2.84300069e-04],
          [9.99128282e-01, 3.54876596e-04, 3.72721668e-04,
           1.44050180e-04],
          [9.99500990e-01, 1.40726712e-04, 2.89765390e-04,
           6.85581690e-05],
          ...,
          [9.98705268e-01, 6.40508253e-04, 6.14234363e-04,
           3.99403762e-05],
          [9.96441662e-01, 1.37029204e-03, 2.13275873e-03,
           5.52479542e-05],
          [9.93720174e-01, 2.51798448e-03, 3.52032483e-03,
           2.41561153e-04]],

         [[9.89373982e-01, 4.63695219e-03, 5.35762496e-03,
           6.31505507e-04],
          [9.95286405e-01, 1.85835734e-03, 2.38799443e-03,
           4.67195670e-04],
          [9.96478379e-01, 1.36932766e-03, 1.86070893e-03,
           2.91607837e-04],
          ...,
          [9.95731056e-01, 1.82288000e-03, 2.32196623e-03,
           1.24057755e-04],
          [9.90795195e-01, 2.94259004e-03, 6.05342165e-03,
           2.08742567e-04],
          [9.81083333e-01, 5.29756211e-03, 1.30142225e-02,
           6.04906236e-04]]],


        [[[9.98588026e-01, 6.06043090e-04, 6.20297855e-04,
           1.85665354e-04],
          [9.99667168e-01, 1.49567306e-04, 1.01767902e-04,
           8.15130625e-05],
          [9.99654531e-01, 1.57989576e-04, 1.03570019e-04,
           8.38329288e-05],
          ...,
          [9.99860883e-01, 7.02840116e-05, 3.25405708e-05,
           3.62658502e-05],
          [9.99798357e-01, 8.70853619e-05, 6.98323129e-05,
           4.46890990e-05],
          [9.98595536e-01, 7.07450032e-04, 4.17071831e-04,
           2.79956730e-04]],

         [[9.99804795e-01, 9.96505332e-05, 6.59479483e-05,
           2.95980008e-05],
          [9.99926567e-01, 2.39584897e-05, 2.15269411e-05,
           2.79399064e-05],
          [9.99842763e-01, 4.87721409e-05, 5.51081866e-05,
           5.33970015e-05],
          ...,
          [9.99868989e-01, 4.76418609e-05, 3.24806206e-05,
           5.08403027e-05],
          [9.99837399e-01, 6.32267111e-05, 5.61433699e-05,
           4.32844718e-05],
          [9.99849439e-01, 4.04441307e-05, 6.77167700e-05,
           4.24391219e-05]],

         [[9.99835730e-01, 6.66967244e-05, 5.26494623e-05,
           4.48226674e-05],
          [9.99904752e-01, 2.28208155e-05, 2.41216840e-05,
           4.83332369e-05],
          [9.99835968e-01, 3.55809898e-05, 4.73234941e-05,
           8.10503698e-05],
          ...,
          [9.99898791e-01, 3.27959715e-05, 2.24505602e-05,
           4.59196708e-05],
          [9.99844670e-01, 3.89585948e-05, 5.18623019e-05,
           6.45137043e-05],
          [9.99829054e-01, 3.66054228e-05, 6.38138517e-05,
           7.05437342e-05]],

         ...,

         [[9.99703467e-01, 1.09577413e-04, 1.18847754e-04,
           6.81440069e-05],
          [9.99943852e-01, 1.46344473e-05, 1.95054799e-05,
           2.19923022e-05],
          [9.99839783e-01, 3.77186407e-05, 6.36973564e-05,
           5.88489456e-05],
          ...,
          [9.99897599e-01, 4.91886385e-05, 3.95717798e-05,
           1.36482286e-05],
          [9.99871373e-01, 6.56530028e-05, 5.10910795e-05,
           1.18994121e-05],
          [9.99067605e-01, 3.71306029e-04, 4.86525038e-04,
           7.45881625e-05]],

         [[9.99001920e-01, 4.03594924e-04, 4.18446580e-04,
           1.75998532e-04],
          [9.99810994e-01, 5.59530963e-05, 8.82369568e-05,
           4.48726205e-05],
          [9.99847531e-01, 3.77165561e-05, 7.84777221e-05,
           3.63585168e-05],
          ...,
          [9.99819338e-01, 7.24789352e-05, 9.42334882e-05,
           1.40417997e-05],
          [9.99691248e-01, 1.33612426e-04, 1.60516342e-04,
           1.47019718e-05],
          [9.97103035e-01, 7.74932152e-04, 2.00120732e-03,
           1.20868965e-04]],

         [[9.96342957e-01, 1.43459637e-03, 1.78196479e-03,
           4.40567354e-04],
          [9.98480618e-01, 4.79831797e-04, 7.60616269e-04,
           2.79010885e-04],
          [9.99071598e-01, 2.43422022e-04, 5.36665262e-04,
           1.48214283e-04],
          ...,
          [9.98243809e-01, 6.11718278e-04, 1.03026582e-03,
           1.14272298e-04],
          [9.97333050e-01, 6.53368072e-04, 1.89438579e-03,
           1.19148688e-04],
          [9.88930881e-01, 3.13924951e-03, 7.46730436e-03,
           4.62561729e-04]]],


        ...,


        [[[9.99234080e-01, 3.85153806e-04, 2.59676395e-04,
           1.21175573e-04],
          [9.99809921e-01, 9.02376414e-05, 4.28334315e-05,
           5.70849115e-05],
          [9.99822795e-01, 8.69970027e-05, 4.08779670e-05,
           4.93128537e-05],
          ...,
          [9.99812186e-01, 1.12568719e-04, 2.90957450e-05,
           4.62240278e-05],
          [9.99777853e-01, 1.26499144e-04, 5.25191390e-05,
           4.31282861e-05],
          [9.98121083e-01, 1.01652578e-03, 5.42542955e-04,
           3.19881859e-04]],

         [[9.99775589e-01, 1.14334849e-04, 6.10606367e-05,
           4.90173952e-05],
          [9.99866962e-01, 4.86973295e-05, 3.14939389e-05,
           5.27740667e-05],
          [9.99895573e-01, 3.31831143e-05, 2.60994329e-05,
           4.51560300e-05],
          ...,
          [9.99831676e-01, 8.55542239e-05, 3.05920876e-05,
           5.20827307e-05],
          [9.99850392e-01, 7.78389367e-05, 4.02580336e-05,
           3.15424986e-05],
          [9.99861598e-01, 4.53991925e-05, 6.18818958e-05,
           3.10685209e-05]],

         [[9.99818385e-01, 8.37376647e-05, 4.91581086e-05,
           4.87177713e-05],
          [9.99879599e-01, 3.02003828e-05, 2.40164773e-05,
           6.62365928e-05],
          [9.99905229e-01, 2.38034554e-05, 1.86884645e-05,
           5.21997463e-05],
          ...,
          [9.99880672e-01, 5.03201773e-05, 2.18719451e-05,
           4.71262683e-05],
          [9.99844909e-01, 6.36545083e-05, 3.98916454e-05,
           5.15536158e-05],
          [9.99850154e-01, 3.53770265e-05, 6.14681121e-05,
           5.30123762e-05]],

         ...,

         [[9.99828458e-01, 6.37973208e-05, 5.39397843e-05,
           5.38209279e-05],
          [9.99897122e-01, 2.03481486e-05, 2.40904646e-05,
           5.84129266e-05],
          [9.99871373e-01, 2.51883412e-05, 3.22739761e-05,
           7.11473622e-05],
          ...,
          [9.99895573e-01, 3.39172002e-05, 2.57290303e-05,
           4.46936174e-05],
          [9.99836087e-01, 4.68281323e-05, 5.22980845e-05,
           6.47715788e-05],
          [9.99737799e-01, 5.64886832e-05, 9.73306960e-05,
           1.08342225e-04]],

         [[9.99759138e-01, 8.89450021e-05, 7.30896863e-05,
           7.88593970e-05],
          [9.99823153e-01, 4.14185342e-05, 4.06077816e-05,
           9.47370208e-05],
          [9.99882221e-01, 2.76503033e-05, 3.16908590e-05,
           5.84777190e-05],
          ...,
          [9.99900937e-01, 3.50063565e-05, 2.33627106e-05,
           4.05971223e-05],
          [9.99834061e-01, 6.46205372e-05, 5.31975929e-05,
           4.80766612e-05],
          [9.99764621e-01, 6.01128013e-05, 1.07574073e-04,
           6.77057906e-05]],

         [[9.99501228e-01, 2.10766637e-04, 1.62091848e-04,
           1.25932915e-04],
          [9.99725640e-01, 8.29319397e-05, 8.61233129e-05,
           1.05278137e-04],
          [9.99816597e-01, 5.74173137e-05, 6.56025950e-05,
           6.03244589e-05],
          ...,
          [9.99799550e-01, 8.11693972e-05, 6.36075056e-05,
           5.56826235e-05],
          [9.99694586e-01, 1.16339892e-04, 1.10589623e-04,
           7.85037410e-05],
          [9.98085618e-01, 5.14045591e-04, 1.11133012e-03,
           2.89122516e-04]]],


        [[[9.97768164e-01, 1.17986393e-03, 7.72958680e-04,
           2.78961787e-04],
          [9.99356687e-01, 3.87866399e-04, 1.33285852e-04,
           1.22184429e-04],
          [9.99600232e-01, 2.61179521e-04, 7.45913567e-05,
           6.40504659e-05],
          ...,
          [9.99576986e-01, 3.18774401e-04, 5.84199042e-05,
           4.58919785e-05],
          [9.99291897e-01, 4.89262806e-04, 1.71444815e-04,
           4.74427106e-05],
          [9.97453749e-01, 1.64055929e-03, 6.56183867e-04,
           2.49534118e-04]],

         [[9.99568880e-01, 2.16080909e-04, 1.34929112e-04,
           8.01127389e-05],
          [9.99829173e-01, 7.61287374e-05, 3.90244422e-05,
           5.56378836e-05],
          [9.99894381e-01, 4.47511484e-05, 3.09906427e-05,
           2.99319017e-05],
          ...,
          [9.99845147e-01, 1.02473066e-04, 2.57323190e-05,
           2.66186198e-05],
          [9.99712169e-01, 2.00504277e-04, 6.27173140e-05,
           2.46321597e-05],
          [9.99716461e-01, 1.30938613e-04, 1.24717859e-04,
           2.77963009e-05]],

         [[9.99681830e-01, 1.40196877e-04, 9.88962711e-05,
           7.91995190e-05],
          [9.99879479e-01, 4.35536676e-05, 2.51382226e-05,
           5.19152272e-05],
          [9.99913216e-01, 2.99406602e-05, 2.17446868e-05,
           3.51578055e-05],
          ...,
          [9.99863744e-01, 7.47195372e-05, 2.48652505e-05,
           3.66027125e-05],
          [9.99799788e-01, 1.15154944e-04, 5.11354301e-05,
           3.39669059e-05],
          [9.99854684e-01, 6.07380680e-05, 5.66891504e-05,
           2.78386160e-05]],

         ...,

         [[9.99717653e-01, 9.77770542e-05, 1.03737686e-04,
           8.09171324e-05],
          [9.99891400e-01, 2.72976813e-05, 2.86841077e-05,
           5.26064177e-05],
          [9.99890566e-01, 2.41106009e-05, 3.79035992e-05,
           4.74731241e-05],
          ...,
          [9.99909878e-01, 3.11078511e-05, 2.90444987e-05,
           2.99466428e-05],
          [9.99872446e-01, 6.01578868e-05, 4.15656868e-05,
           2.57897755e-05],
          [9.99751151e-01, 8.88715440e-05, 1.04981649e-04,
           5.49558790e-05]],

         [[9.99593079e-01, 1.68589089e-04, 1.31803914e-04,
           1.06498497e-04],
          [9.99877930e-01, 4.27952255e-05, 2.86445757e-05,
           5.05925382e-05],
          [9.99934554e-01, 2.29837788e-05, 1.82177846e-05,
           2.42258466e-05],
          ...,
          [9.99950290e-01, 2.14119318e-05, 1.36722028e-05,
           1.45471831e-05],
          [9.99891281e-01, 5.15556603e-05, 3.74009905e-05,
           1.97118334e-05],
          [9.99381423e-01, 2.45667674e-04, 2.80111883e-04,
           9.28383670e-05]],

         [[9.98887956e-01, 4.51842992e-04, 4.57330752e-04,
           2.02811687e-04],
          [9.99438703e-01, 1.45023441e-04, 2.14892993e-04,
           2.01426345e-04],
          [9.99678016e-01, 9.13089680e-05, 1.34627364e-04,
           9.60647594e-05],
          ...,
          [9.99639392e-01, 1.17471071e-04, 1.41612603e-04,
           1.01450045e-04],
          [9.99274671e-01, 2.44616793e-04, 3.48352449e-04,
           1.32391200e-04],
          [9.95445251e-01, 1.29970815e-03, 2.68325699e-03,
           5.71720244e-04]]],


        [[[9.90659118e-01, 5.70750469e-03, 2.67551932e-03,
           9.57909098e-04],
          [9.98000801e-01, 8.80822830e-04, 8.69405223e-04,
           2.48870056e-04],
          [9.98360455e-01, 8.17417691e-04, 6.35961071e-04,
           1.86202611e-04],
          ...,
          [9.98353958e-01, 9.02037777e-04, 6.07430178e-04,
           1.36627161e-04],
          [9.97913539e-01, 1.00232230e-03, 9.51108406e-04,
           1.33036781e-04],
          [9.92971838e-01, 3.38388514e-03, 2.88488553e-03,
           7.59406365e-04]],

         [[9.96177912e-01, 2.29696068e-03, 1.11174281e-03,
           4.13397531e-04],
          [9.98930395e-01, 5.10663434e-04, 3.65560467e-04,
           1.93433763e-04],
          [9.99661088e-01, 1.64366065e-04, 1.16912335e-04,
           5.77042920e-05],
          ...,
          [9.99468148e-01, 3.20952648e-04, 1.55256290e-04,
           5.56841915e-05],
          [9.98804569e-01, 6.61797298e-04, 4.59215022e-04,
           7.44204735e-05],
          [9.98231471e-01, 7.24218902e-04, 9.07457492e-04,
           1.36843140e-04]],

         [[9.98342633e-01, 8.19805718e-04, 5.47218777e-04,
           2.90335243e-04],
          [9.99690652e-01, 1.07714251e-04, 9.81816265e-05,
           1.03484890e-04],
          [9.99836683e-01, 6.23108135e-05, 5.12874540e-05,
           4.96983230e-05],
          ...,
          [9.99717772e-01, 1.36181028e-04, 8.25441894e-05,
           6.34553289e-05],
          [9.99462068e-01, 2.80682143e-04, 1.81589989e-04,
           7.56378577e-05],
          [9.98459816e-01, 6.62610109e-04, 6.80409954e-04,
           1.97205620e-04]],

         ...,

         [[9.98875678e-01, 4.41951503e-04, 4.52711742e-04,
           2.29585334e-04],
          [9.99726236e-01, 7.42090706e-05, 1.06797997e-04,
           9.27099609e-05],
          [9.99820769e-01, 4.43469326e-05, 7.71884152e-05,
           5.76788443e-05],
          ...,
          [9.99772727e-01, 7.13596746e-05, 9.63279017e-05,
           5.96006212e-05],
          [9.99505162e-01, 1.65548656e-04, 2.31244485e-04,
           9.81031408e-05],
          [9.98323977e-01, 5.82880573e-04, 8.06324824e-04,
           2.86755065e-04]],

         [[9.98374581e-01, 7.20420096e-04, 6.09755982e-04,
           2.95274484e-04],
          [9.99605358e-01, 1.20091805e-04, 1.32504501e-04,
           1.42024335e-04],
          [9.99813020e-01, 5.60522312e-05, 6.61282975e-05,
           6.48440036e-05],
          ...,
          [9.99768913e-01, 7.86941309e-05, 8.59515203e-05,
           6.64526597e-05],
          [9.99062240e-01, 3.78537807e-04, 4.04668797e-04,
           1.54577589e-04],
          [9.97664332e-01, 7.73820793e-04, 1.29107898e-03,
           2.70865479e-04]],

         [[9.96880651e-01, 1.20808824e-03, 1.47204043e-03,
           4.39263735e-04],
          [9.98426437e-01, 4.31225752e-04, 8.05248681e-04,
           3.37134115e-04],
          [9.99140143e-01, 2.13630148e-04, 4.64391429e-04,
           1.81802301e-04],
          ...,
          [9.97961283e-01, 5.59677894e-04, 1.14050333e-03,
           3.38445156e-04],
          [9.97079611e-01, 9.02321015e-04, 1.57230976e-03,
           4.45887505e-04],
          [9.90583658e-01, 3.62640293e-03, 4.81360033e-03,
           9.76340380e-04]]]]], dtype=float32)>}2021-07-14 12:41:21.359488: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.97263789e-01, 9.35724180e-04, 1.37847464e-03,
           4.22020239e-04],
          [9.98810053e-01, 5.26489748e-04, 4.69041086e-04,
           1.94353808e-04],
          [9.99273956e-01, 2.83643632e-04, 3.12219054e-04,
           1.30189248e-04],
          ...,
          [9.99458730e-01, 2.00829236e-04, 2.40262118e-04,
           1.00179466e-04],
          [9.98458862e-01, 6.47463254e-04, 7.24448822e-04,
           1.69145409e-04],
          [9.95906830e-01, 2.01481953e-03, 1.80553540e-03,
           2.72851263e-04]],

         [[9.99610722e-01, 1.15830851e-04, 1.97215588e-04,
           7.63164790e-05],
          [9.99813855e-01, 7.05752245e-05, 7.16975555e-05,
           4.38731731e-05],
          [9.99906421e-01, 3.35825061e-05, 4.19305215e-05,
           1.80507486e-05],
          ...,
          [9.99927878e-01, 2.57033007e-05, 3.17578088e-05,
           1.46251869e-05],
          [9.99816358e-01, 6.59427969e-05, 9.34269774e-05,
           2.42853421e-05],
          [9.99169707e-01, 3.23131011e-04, 4.55695146e-04,
           5.14744534e-05]],

         [[9.99782145e-01, 6.17392798e-05, 1.04488281e-04,
           5.16908331e-05],
          [9.99832153e-01, 5.08031480e-05, 6.22360531e-05,
           5.48319622e-05],
          [9.99912024e-01, 2.91996166e-05, 3.56173405e-05,
           2.31740814e-05],
          ...,
          [9.99931216e-01, 2.33129376e-05, 2.77149647e-05,
           1.77184393e-05],
          [9.99843597e-01, 5.92318174e-05, 6.87178472e-05,
           2.84113648e-05],
          [9.99133766e-01, 3.51391151e-04, 4.60630690e-04,
           5.43034112e-05]],

         ...,

         [[9.99198854e-01, 4.54627589e-04, 2.07131801e-04,
           1.39381955e-04],
          [9.99518871e-01, 2.52395257e-04, 1.19787241e-04,
           1.09011373e-04],
          [9.99716103e-01, 1.48589781e-04, 7.79906113e-05,
           5.72960780e-05],
          ...,
          [9.99607980e-01, 2.57895823e-04, 8.33894373e-05,
           5.08121957e-05],
          [9.99357402e-01, 3.57607234e-04, 2.07868405e-04,
           7.71174819e-05],
          [9.98798490e-01, 4.86216653e-04, 5.90645068e-04,
           1.24581347e-04]],

         [[9.97357905e-01, 1.49003451e-03, 8.13795836e-04,
           3.38348793e-04],
          [9.98846412e-01, 5.71442884e-04, 3.81499442e-04,
           2.00658164e-04],
          [9.99424934e-01, 3.04237707e-04, 1.86924153e-04,
           8.38384585e-05],
          ...,
          [9.99502182e-01, 2.96652317e-04, 1.40972814e-04,
           6.01338834e-05],
          [9.99064028e-01, 4.68506012e-04, 3.63402680e-04,
           1.04028863e-04],
          [9.97472346e-01, 8.95428413e-04, 1.46015431e-03,
           1.72055268e-04]],

         [[9.89534080e-01, 5.84412226e-03, 3.26780183e-03,
           1.35399168e-03],
          [9.91935968e-01, 4.61187260e-03, 2.55904859e-03,
           8.93127581e-04],
          [9.96520281e-01, 2.06760340e-03, 1.05406542e-03,
           3.58023186e-04],
          ...,
          [9.97621357e-01, 1.49500626e-03, 6.60490361e-04,
           2.23105322e-04],
          [9.96722400e-01, 2.01820396e-03, 9.80015844e-04,
           2.79378059e-04],
          [9.90910351e-01, 3.42051219e-03, 5.13360230e-03,
           5.35475730e-04]]],


        [[[9.99091148e-01, 2.47521326e-04, 4.43742028e-04,
           2.17601002e-04],
          [9.99788940e-01, 6.14903838e-05, 8.25513198e-05,
           6.70222144e-05],
          [9.99840975e-01, 4.85787168e-05, 5.22738046e-05,
           5.81264721e-05],
          ...,
          [9.99843478e-01, 4.75364432e-05, 5.61958877e-05,
           5.27256452e-05],
          [9.99802649e-01, 5.38326240e-05, 8.85873887e-05,
           5.49261131e-05],
          [9.99371111e-01, 3.13122204e-04, 2.18296642e-04,
           9.74852883e-05]],

         [[9.99820054e-01, 4.58758695e-05, 8.59790380e-05,
           4.81065799e-05],
          [9.99895096e-01, 3.60114645e-05, 3.49442744e-05,
           3.39760700e-05],
          [9.99920368e-01, 3.22411943e-05, 2.30558562e-05,
           2.43262093e-05],
          ...,
          [9.99923110e-01, 2.68944477e-05, 2.40838763e-05,
           2.58152959e-05],
          [9.99916673e-01, 2.48586002e-05, 3.39824437e-05,
           2.43773520e-05],
          [9.99861002e-01, 6.86593557e-05, 4.82137293e-05,
           2.20535712e-05]],

         [[9.99869108e-01, 3.18635794e-05, 4.95545391e-05,
           4.94698761e-05],
          [9.99883652e-01, 3.89863162e-05, 3.08845665e-05,
           4.64335426e-05],
          [9.99903917e-01, 3.67701286e-05, 2.41145553e-05,
           3.52820898e-05],
          ...,
          [9.99931574e-01, 2.35776533e-05, 1.74134620e-05,
           2.74314043e-05],
          [9.99907494e-01, 3.09910793e-05, 3.36052908e-05,
           2.78557527e-05],
          [9.99909282e-01, 4.58403811e-05, 2.89483869e-05,
           1.58415442e-05]],

         ...,

         [[9.99839067e-01, 6.73936229e-05, 4.76893001e-05,
           4.58539143e-05],
          [9.99874592e-01, 5.18418019e-05, 3.19217252e-05,
           4.16421135e-05],
          [9.99915481e-01, 3.59979495e-05, 1.99229235e-05,
           2.86460618e-05],
          ...,
          [9.99896646e-01, 5.52892452e-05, 2.22214585e-05,
           2.57994052e-05],
          [9.99760330e-01, 1.16808144e-04, 7.30504617e-05,
           4.97914843e-05],
          [9.99764621e-01, 8.94780023e-05, 7.97657412e-05,
           6.61331069e-05]],

         [[9.99655485e-01, 1.50003078e-04, 1.00164893e-04,
           9.43590567e-05],
          [9.99801934e-01, 7.30992178e-05, 6.77943244e-05,
           5.72846038e-05],
          [9.99854922e-01, 5.77542451e-05, 3.91271788e-05,
           4.81485549e-05],
          ...,
          [9.99869943e-01, 7.14794151e-05, 2.54266142e-05,
           3.30747534e-05],
          [9.99678254e-01, 1.68858969e-04, 9.20918537e-05,
           6.08305818e-05],
          [9.99665499e-01, 1.19594428e-04, 1.49026702e-04,
           6.58740828e-05]],

         [[9.98303413e-01, 7.18939875e-04, 6.95865077e-04,
           2.81801593e-04],
          [9.99094129e-01, 3.20129882e-04, 3.86463129e-04,
           1.99284317e-04],
          [9.99448240e-01, 2.22487943e-04, 2.04913129e-04,
           1.24405618e-04],
          ...,
          [9.99585807e-01, 2.00529976e-04, 1.27675448e-04,
           8.59464344e-05],
          [9.99294996e-01, 3.38560407e-04, 2.41936985e-04,
           1.24503218e-04],
          [9.97713804e-01, 5.88502095e-04, 1.39337173e-03,
           3.04309448e-04]]],


        [[[9.99326706e-01, 2.43465809e-04, 3.26094159e-04,
           1.03781604e-04],
          [9.99846101e-01, 6.25997418e-05, 6.30733266e-05,
           2.81885877e-05],
          [9.99881268e-01, 4.98504451e-05, 4.07755833e-05,
           2.81157718e-05],
          ...,
          [9.99865174e-01, 4.39246651e-05, 5.68324358e-05,
           3.40506995e-05],
          [9.99845147e-01, 4.39869582e-05, 7.79118345e-05,
           3.29883114e-05],
          [9.99460161e-01, 2.56270810e-04, 1.88618360e-04,
           9.49737878e-05]],

         [[9.99849200e-01, 4.78950205e-05, 7.30333486e-05,
           2.98184405e-05],
          [9.99889255e-01, 3.77400429e-05, 4.52536406e-05,
           2.77288200e-05],
          [9.99911070e-01, 2.95952486e-05, 3.60521044e-05,
           2.32983766e-05],
          ...,
          [9.99940395e-01, 1.75847399e-05, 2.26552620e-05,
           1.92911157e-05],
          [9.99904752e-01, 2.46812815e-05, 4.17150368e-05,
           2.88286865e-05],
          [9.99899507e-01, 4.02331825e-05, 3.84855302e-05,
           2.16702956e-05]],

         [[9.99914289e-01, 2.99665153e-05, 3.22936503e-05,
           2.34410436e-05],
          [9.99880314e-01, 4.44657853e-05, 3.68495821e-05,
           3.83101942e-05],
          [9.99895573e-01, 3.37646452e-05, 3.77047072e-05,
           3.30085095e-05],
          ...,
          [9.99921679e-01, 2.20027232e-05, 2.90948246e-05,
           2.71192566e-05],
          [9.99890208e-01, 3.22729829e-05, 4.40566509e-05,
           3.33744392e-05],
          [9.99903321e-01, 3.50571499e-05, 3.86614447e-05,
           2.29807829e-05]],

         ...,

         [[9.99822676e-01, 6.92270842e-05, 6.38540369e-05,
           4.42940545e-05],
          [9.99873877e-01, 3.18470193e-05, 3.87229993e-05,
           5.55459992e-05],
          [9.99841928e-01, 3.95308416e-05, 5.39706089e-05,
           6.44903994e-05],
          ...,
          [9.99897718e-01, 3.54270560e-05, 2.93509675e-05,
           3.75554591e-05],
          [9.99769151e-01, 7.43191267e-05, 8.00264606e-05,
           7.64187571e-05],
          [9.99738395e-01, 6.44248357e-05, 9.02077809e-05,
           1.06967796e-04]],

         [[9.99765933e-01, 8.67004419e-05, 8.18383924e-05,
           6.55369804e-05],
          [9.99846578e-01, 4.13745365e-05, 4.62483731e-05,
           6.57825440e-05],
          [9.99840379e-01, 4.73664622e-05, 4.86257304e-05,
           6.37072371e-05],
          ...,
          [9.99871731e-01, 4.98606678e-05, 3.01292639e-05,
           4.83269396e-05],
          [9.99733746e-01, 1.06925982e-04, 9.15121200e-05,
           6.78293363e-05],
          [9.99709547e-01, 8.92473254e-05, 1.17447387e-04,
           8.37529078e-05]],

         [[9.99364555e-01, 2.58032029e-04, 2.40254609e-04,
           1.37105395e-04],
          [9.99572217e-01, 1.34960821e-04, 1.56851107e-04,
           1.35870898e-04],
          [9.99679804e-01, 1.18272939e-04, 1.21869045e-04,
           8.01538772e-05],
          ...,
          [9.99737680e-01, 1.01333550e-04, 9.15430355e-05,
           6.94455593e-05],
          [9.99520659e-01, 2.11343591e-04, 1.56799186e-04,
           1.11178175e-04],
          [9.98038471e-01, 5.03389863e-04, 1.14937441e-03,
           3.08762828e-04]]],


        ...,


        [[[9.93595183e-01, 3.70010035e-03, 2.31054029e-03,
           3.94123694e-04],
          [9.98966217e-01, 5.82889887e-04, 3.72203009e-04,
           7.86614037e-05],
          [9.96823788e-01, 2.08050641e-03, 9.15309764e-04,
           1.80393719e-04],
          ...,
          [9.98415828e-01, 9.91059351e-04, 5.00515511e-04,
           9.25246204e-05],
          [9.96075213e-01, 2.84355856e-03, 8.56186729e-04,
           2.25104392e-04],
          [9.87228513e-01, 9.07020085e-03, 2.69294949e-03,
           1.00833364e-03]],

         [[9.96808231e-01, 1.81935739e-03, 1.15596864e-03,
           2.16395812e-04],
          [9.99590576e-01, 1.98022186e-04, 1.62382348e-04,
           4.90259918e-05],
          [9.99150157e-01, 4.51615633e-04, 3.01571650e-04,
           9.65575528e-05],
          ...,
          [9.99624848e-01, 1.82692442e-04, 1.59796400e-04,
           3.26561349e-05],
          [9.98022079e-01, 5.51241275e-04, 1.34119915e-03,
           8.55470789e-05],
          [9.93272007e-01, 2.68147769e-03, 3.61310854e-03,
           4.33506648e-04]],

         [[9.99583900e-01, 2.74382270e-04, 9.93492868e-05,
           4.23617894e-05],
          [9.99931097e-01, 4.23790843e-05, 1.13975220e-05,
           1.50334836e-05],
          [9.99921322e-01, 4.74831868e-05, 1.62306242e-05,
           1.50215992e-05],
          ...,
          [9.99925852e-01, 5.30391517e-05, 1.04747096e-05,
           1.06775769e-05],
          [9.99931812e-01, 3.97126023e-05, 2.10882063e-05,
           7.34371133e-06],
          [9.99187529e-01, 3.95549374e-04, 3.52120376e-04,
           6.47549386e-05]],

         ...,

         [[9.99815404e-01, 7.27774532e-05, 5.73677644e-05,
           5.44173163e-05],
          [9.99890685e-01, 2.43272279e-05, 2.68322456e-05,
           5.81775566e-05],
          [9.99866962e-01, 2.86745180e-05, 3.34638535e-05,
           7.08087318e-05],
          ...,
          [9.99896169e-01, 3.51459130e-05, 2.63345955e-05,
           4.23314377e-05],
          [9.99830604e-01, 5.17680310e-05, 5.45359762e-05,
           6.31224102e-05],
          [9.99740422e-01, 5.88726762e-05, 9.96256858e-05,
           1.01071397e-04]],

         [[9.99735773e-01, 1.08743428e-04, 7.66219891e-05,
           7.89594415e-05],
          [9.99808848e-01, 5.20168142e-05, 4.47839884e-05,
           9.43784762e-05],
          [9.99876261e-01, 3.21655752e-05, 3.34352335e-05,
           5.81402201e-05],
          ...,
          [9.99892473e-01, 4.03326303e-05, 2.49441800e-05,
           4.23323727e-05],
          [9.99835372e-01, 6.65872576e-05, 5.28651908e-05,
           4.50680018e-05],
          [9.99722660e-01, 7.22269833e-05, 1.30291446e-04,
           7.47514714e-05]],

         [[9.99441445e-01, 2.51256657e-04, 1.78652219e-04,
           1.28640080e-04],
          [9.99701083e-01, 9.98521355e-05, 9.39879465e-05,
           1.05075145e-04],
          [9.99804080e-01, 6.46307963e-05, 6.98714211e-05,
           6.14645105e-05],
          ...,
          [9.99779642e-01, 8.92712924e-05, 7.14818307e-05,
           5.95610290e-05],
          [9.99654412e-01, 1.26606014e-04, 1.32362344e-04,
           8.66195260e-05],
          [9.97697771e-01, 6.29954913e-04, 1.35181146e-03,
           3.20464227e-04]]],


        [[[9.84259784e-01, 7.65153766e-03, 7.26296660e-03,
           8.25773750e-04],
          [9.96862292e-01, 1.93364476e-03, 9.95645649e-04,
           2.08373676e-04],
          [9.90532398e-01, 6.23520371e-03, 2.88536656e-03,
           3.46923392e-04],
          ...,
          [9.93596196e-01, 4.68941173e-03, 1.55424885e-03,
           1.60084688e-04],
          [9.85561907e-01, 1.14544677e-02, 2.64904671e-03,
           3.34547658e-04],
          [9.85184431e-01, 1.15796160e-02, 2.68346560e-03,
           5.52483718e-04]],

         [[9.93983686e-01, 3.62306344e-03, 2.12438777e-03,
           2.68948992e-04],
          [9.99087453e-01, 4.30013053e-04, 4.20293858e-04,
           6.21554282e-05],
          [9.97354746e-01, 1.62556896e-03, 9.08634102e-04,
           1.11104106e-04],
          ...,
          [9.98857021e-01, 6.72643073e-04, 3.97979369e-04,
           7.23542253e-05],
          [9.95516121e-01, 2.86640553e-03, 1.49286620e-03,
           1.24657221e-04],
          [9.93933141e-01, 3.31327925e-03, 2.45124591e-03,
           3.02359404e-04]],

         [[9.98298824e-01, 9.79744014e-04, 5.62399742e-04,
           1.58975614e-04],
          [9.99670267e-01, 2.18697096e-04, 5.95195925e-05,
           5.15065767e-05],
          [9.99525666e-01, 3.59467842e-04, 8.26863543e-05,
           3.21369735e-05],
          ...,
          [9.99691010e-01, 2.36866268e-04, 4.87568286e-05,
           2.33521914e-05],
          [9.99306917e-01, 4.63505188e-04, 2.08177909e-04,
           2.14335905e-05],
          [9.97668803e-01, 1.46890164e-03, 7.80249888e-04,
           8.19960551e-05]],

         ...,

         [[9.99700069e-01, 1.12362730e-04, 1.08213389e-04,
           7.93881263e-05],
          [9.99883533e-01, 3.42567873e-05, 3.13561504e-05,
           5.09055681e-05],
          [9.99886513e-01, 2.76134215e-05, 3.96571013e-05,
           4.61457130e-05],
          ...,
          [9.99907374e-01, 3.44660511e-05, 2.92159984e-05,
           2.89972904e-05],
          [9.99868870e-01, 6.49085705e-05, 4.16799776e-05,
           2.44438834e-05],
          [9.99703705e-01, 1.10925052e-04, 1.26144383e-04,
           5.91859825e-05]],

         [[9.99538660e-01, 2.05120145e-04, 1.51807079e-04,
           1.04510560e-04],
          [9.99861717e-01, 5.58717911e-05, 3.22668056e-05,
           5.00884998e-05],
          [9.99925733e-01, 2.82810688e-05, 2.02261435e-05,
           2.57618703e-05],
          ...,
          [9.99942899e-01, 2.52778373e-05, 1.57635277e-05,
           1.60392610e-05],
          [9.99870658e-01, 6.31986768e-05, 4.44813923e-05,
           2.17164270e-05],
          [9.99211311e-01, 3.15854588e-04, 3.63375148e-04,
           1.09370980e-04]],

         [[9.98688400e-01, 5.67427545e-04, 5.25387935e-04,
           2.18756875e-04],
          [9.99355733e-01, 1.85583878e-04, 2.46212760e-04,
           2.12469808e-04],
          [9.99633074e-01, 1.08398257e-04, 1.56178969e-04,
           1.02304388e-04],
          ...,
          [9.99594629e-01, 1.34662623e-04, 1.61792981e-04,
           1.08987515e-04],
          [9.99110401e-01, 2.97572056e-04, 4.42091376e-04,
           1.49985208e-04],
          [9.94724691e-01, 1.52146420e-03, 3.12785874e-03,
           6.25960238e-04]]],


        [[[9.88114297e-01, 7.68820103e-03, 2.86675384e-03,
           1.33076753e-03],
          [9.96744752e-01, 2.24257633e-03, 6.47156674e-04,
           3.65424261e-04],
          [9.96990442e-01, 2.16675038e-03, 5.67572773e-04,
           2.75178376e-04],
          ...,
          [9.97599781e-01, 1.65926840e-03, 5.75268175e-04,
           1.65761943e-04],
          [9.94676828e-01, 3.63501371e-03, 1.32020866e-03,
           3.67993722e-04],
          [9.83548999e-01, 1.06802024e-02, 4.55873366e-03,
           1.21193891e-03]],

         [[9.84798849e-01, 9.21847764e-03, 5.16672991e-03,
           8.15909589e-04],
          [9.97754514e-01, 1.05420116e-03, 1.04266673e-03,
           1.48671490e-04],
          [9.95433629e-01, 2.56003463e-03, 1.80547452e-03,
           2.00810580e-04],
          ...,
          [9.96949017e-01, 1.80035597e-03, 1.11094769e-03,
           1.39665426e-04],
          [9.92786467e-01, 5.20643732e-03, 1.79716665e-03,
           2.09967315e-04],
          [9.88917351e-01, 7.18350196e-03, 3.38738714e-03,
           5.11789811e-04]],

         [[9.91059840e-01, 5.13546914e-03, 3.23131937e-03,
           5.73320838e-04],
          [9.98571634e-01, 3.94812028e-04, 9.05769994e-04,
           1.27686726e-04],
          [9.95836258e-01, 1.37294328e-03, 2.61966465e-03,
           1.71146618e-04],
          ...,
          [9.97593582e-01, 9.47954657e-04, 1.33733789e-03,
           1.21092191e-04],
          [9.92304623e-01, 1.89389696e-03, 5.67792961e-03,
           1.23554011e-04],
          [9.88157094e-01, 4.94015636e-03, 6.17768755e-03,
           7.25039397e-04]],

         ...,

         [[9.98694003e-01, 5.46212192e-04, 5.21819980e-04,
           2.38021734e-04],
          [9.99703109e-01, 8.83785979e-05, 1.16436015e-04,
           9.20010061e-05],
          [9.99808490e-01, 5.22087830e-05, 8.03144867e-05,
           5.90001182e-05],
          ...,
          [9.99748409e-01, 8.36180188e-05, 1.06036066e-04,
           6.19441416e-05],
          [9.99443948e-01, 1.98169786e-04, 2.58546672e-04,
           9.94096772e-05],
          [9.98231709e-01, 6.35778415e-04, 8.57542851e-04,
           2.74962396e-04]],

         [[9.97992873e-01, 9.45788866e-04, 7.30014523e-04,
           3.31347401e-04],
          [9.99572217e-01, 1.39777272e-04, 1.45242841e-04,
           1.42718025e-04],
          [9.99786794e-01, 6.94545961e-05, 7.43427736e-05,
           6.93467082e-05],
          ...,
          [9.99730647e-01, 9.66931984e-05, 9.80691402e-05,
           7.45699363e-05],
          [9.98899341e-01, 4.62897675e-04, 4.64139186e-04,
           1.73588880e-04],
          [9.97380197e-01, 8.82346940e-04, 1.44892128e-03,
           2.88478215e-04]],

         [[9.96345580e-01, 1.47559925e-03, 1.70543569e-03,
           4.73306485e-04],
          [9.98260319e-01, 5.12643019e-04, 8.85729271e-04,
           3.41307808e-04],
          [9.99022961e-01, 2.54799175e-04, 5.27717290e-04,
           1.94419728e-04],
          ...,
          [9.97788072e-01, 6.14147400e-04, 1.25017401e-03,
           3.47564957e-04],
          [9.96769428e-01, 9.90971457e-04, 1.77977758e-03,
           4.59876697e-04],
          [9.89742517e-01, 3.98786133e-03, 5.25847822e-03,
           1.01124088e-03]]]]], dtype=float32)>}2021-07-14 12:41:21.655010: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:628] TF-TRT Warning: Engine retrieval for input shapes: [[1,160,160,80,32], [1,160,160,80,32]] failed. Running native segment for PartitionedCall/TRTEngineOp_0_4

output shape:  (1, 160, 160, 80, 4)
processing a batch
{'conv3d_18': <tf.Tensor: shape=(1, 160, 160, 80, 4), dtype=float32, numpy=
array([[[[[9.67031419e-01, 2.06853617e-02, 1.07316496e-02,
           1.55157968e-03],
          [9.77257788e-01, 1.39066400e-02, 7.87219871e-03,
           9.63324681e-04],
          [9.75992978e-01, 1.82512570e-02, 5.05020469e-03,
           7.05524464e-04],
          ...,
          [9.49496090e-01, 4.19162288e-02, 7.57699832e-03,
           1.01064879e-03],
          [9.71914232e-01, 2.39220746e-02, 3.53403576e-03,
           6.29622838e-04],
          [9.41769540e-01, 4.59444933e-02, 1.01715522e-02,
           2.11429526e-03]],

         [[9.88402307e-01, 6.32934039e-03, 4.71422775e-03,
           5.54106489e-04],
          [9.83965397e-01, 8.61054007e-03, 6.78995252e-03,
           6.34054013e-04],
          [9.87386405e-01, 4.65472927e-03, 7.46176764e-03,
           4.97048313e-04],
          ...,
          [9.48153079e-01, 3.90307419e-02, 1.17233107e-02,
           1.09292392e-03],
          [9.58913743e-01, 2.52932049e-02, 1.44473584e-02,
           1.34572200e-03],
          [9.25068617e-01, 4.47340533e-02, 2.75863577e-02,
           2.61092582e-03]],

         [[9.89892662e-01, 4.51504858e-03, 5.11554722e-03,
           4.76662070e-04],
          [9.91643190e-01, 3.62741272e-03, 4.29120054e-03,
           4.38283489e-04],
          [9.95828688e-01, 1.38083380e-03, 2.54438189e-03,
           2.46021140e-04],
          ...,
          [9.80908632e-01, 8.49142857e-03, 9.95725859e-03,
           6.42696104e-04],
          [9.73352849e-01, 1.16688898e-02, 1.36962822e-02,
           1.28186448e-03],
          [9.43061531e-01, 2.27550101e-02, 3.26247811e-02,
           1.55861420e-03]],

         ...,

         [[9.99189198e-01, 4.58014751e-04, 2.11853563e-04,
           1.40982171e-04],
          [9.99518037e-01, 2.50427576e-04, 1.22408615e-04,
           1.09059001e-04],
          [9.99709547e-01, 1.50600332e-04, 8.07387332e-05,
           5.90755772e-05],
          ...,
          [9.99603570e-01, 2.58066633e-04, 8.60257060e-05,
           5.23028757e-05],
          [9.99343455e-01, 3.61818587e-04, 2.14433196e-04,
           8.03293660e-05],
          [9.98796821e-01, 4.83775977e-04, 5.93938224e-04,
           1.25429244e-04]],

         [[9.97340262e-01, 1.49702653e-03, 8.24277522e-04,
           3.38505779e-04],
          [9.98822749e-01, 5.79060521e-04, 3.95960466e-04,
           2.02260926e-04],
          [9.99420762e-01, 3.05218418e-04, 1.90497434e-04,
           8.35486935e-05],
          ...,
          [9.99502778e-01, 2.93884514e-04, 1.42454388e-04,
           6.07929978e-05],
          [9.99069631e-01, 4.63935488e-04, 3.62873805e-04,
           1.03654027e-04],
          [9.97556448e-01, 8.66134709e-04, 1.41006743e-03,
           1.67403734e-04]],

         [[9.89521861e-01, 5.83327562e-03, 3.29424045e-03,
           1.35066931e-03],
          [9.91748810e-01, 4.72551072e-03, 2.62698298e-03,
           8.98709230e-04],
          [9.96421695e-01, 2.11887155e-03, 1.09561754e-03,
           3.63859755e-04],
          ...,
          [9.97591972e-01, 1.51050347e-03, 6.71806512e-04,
           2.25754382e-04],
          [9.96680021e-01, 2.04106397e-03, 9.96334944e-04,
           2.82532827e-04],
          [9.90916193e-01, 3.41350655e-03, 5.13509149e-03,
           5.35160769e-04]]],


        [[[9.84082103e-01, 8.42000544e-03, 6.10708259e-03,
           1.39072526e-03],
          [9.89183664e-01, 6.26789453e-03, 3.91214946e-03,
           6.36198383e-04],
          [9.88964677e-01, 6.42022910e-03, 4.11705859e-03,
           4.98012756e-04],
          ...,
          [9.71486151e-01, 1.82252862e-02, 9.64347925e-03,
           6.45100023e-04],
          [9.76120055e-01, 1.89482961e-02, 4.28536860e-03,
           6.46335189e-04],
          [9.41097677e-01, 4.76252176e-02, 9.18942131e-03,
           2.08765035e-03]],

         [[9.81616735e-01, 9.69987176e-03, 7.87055213e-03,
           8.12822778e-04],
          [9.91904855e-01, 4.93147317e-03, 2.88356724e-03,
           2.80088891e-04],
          [9.96201813e-01, 1.89614354e-03, 1.73789973e-03,
           1.64133147e-04],
          ...,
          [9.86570895e-01, 9.09543596e-03, 4.13054368e-03,
           2.03102172e-04],
          [9.81712520e-01, 1.08670527e-02, 6.92028506e-03,
           5.00127149e-04],
          [9.79130089e-01, 1.28263468e-02, 7.19512068e-03,
           8.48348427e-04]],

         [[9.90946770e-01, 4.01759800e-03, 4.54644393e-03,
           4.89231315e-04],
          [9.99291539e-01, 3.46416782e-04, 2.86702474e-04,
           7.53429049e-05],
          [9.99566019e-01, 1.90224120e-04, 1.95531262e-04,
           4.82456780e-05],
          ...,
          [9.97877717e-01, 1.15821697e-03, 8.60396947e-04,
           1.03777493e-04],
          [9.91090775e-01, 5.15724393e-03, 3.30073014e-03,
           4.51278349e-04],
          [9.74501550e-01, 1.20374244e-02, 1.19546894e-02,
           1.50633859e-03]],

         ...,

         [[9.99841094e-01, 6.65069019e-05, 4.71494022e-05,
           4.52215681e-05],
          [9.99873161e-01, 5.18679844e-05, 3.25033507e-05,
           4.24598074e-05],
          [9.99914885e-01, 3.58525904e-05, 2.04671924e-05,
           2.87788207e-05],
          ...,
          [9.99896049e-01, 5.49317192e-05, 2.26368938e-05,
           2.63218881e-05],
          [9.99758780e-01, 1.15650982e-04, 7.45328580e-05,
           5.10281170e-05],
          [9.99765456e-01, 8.83168686e-05, 8.00802954e-05,
           6.61370068e-05]],

         [[9.99655128e-01, 1.49935950e-04, 1.00901758e-04,
           9.40344471e-05],
          [9.99805510e-01, 7.07216532e-05, 6.83388644e-05,
           5.54660328e-05],
          [9.99853730e-01, 5.72833669e-05, 4.05435931e-05,
           4.83400800e-05],
          ...,
          [9.99869347e-01, 7.09986416e-05, 2.59944463e-05,
           3.36287267e-05],
          [9.99679923e-01, 1.65589910e-04, 9.32444964e-05,
           6.12099830e-05],
          [9.99669433e-01, 1.16347161e-04, 1.49081592e-04,
           6.52205417e-05]],

         [[9.98289883e-01, 7.19446223e-04, 7.08023435e-04,
           2.82754510e-04],
          [9.99075770e-01, 3.22083273e-04, 3.99488286e-04,
           2.02709620e-04],
          [9.99437511e-01, 2.25086696e-04, 2.10231665e-04,
           1.27219842e-04],
          ...,
          [9.99578774e-01, 2.02487776e-04, 1.31245601e-04,
           8.75287078e-05],
          [9.99295831e-01, 3.35935300e-04, 2.42532740e-04,
           1.25709426e-04],
          [9.97726381e-01, 5.82817534e-04, 1.38616189e-03,
           3.04650690e-04]]],


        [[[9.91068363e-01, 3.94504424e-03, 4.38015396e-03,
           6.06325280e-04],
          [9.96668160e-01, 1.72837067e-03, 1.40329660e-03,
           2.00165407e-04],
          [9.94887412e-01, 2.19956739e-03, 2.62962165e-03,
           2.83378089e-04],
          ...,
          [9.92598295e-01, 3.91125213e-03, 3.27320094e-03,
           2.17163019e-04],
          [9.80853140e-01, 1.37204537e-02, 4.82775504e-03,
           5.98728890e-04],
          [9.53661084e-01, 3.74704674e-02, 6.37126295e-03,
           2.49721273e-03]],

         [[9.94826853e-01, 2.94357282e-03, 1.93216244e-03,
           2.97333696e-04],
          [9.99316931e-01, 3.81619058e-04, 2.26788135e-04,
           7.47022568e-05],
          [9.99482274e-01, 2.60776404e-04, 2.00145281e-04,
           5.67938769e-05],
          ...,
          [9.98068988e-01, 1.00421801e-03, 8.60914879e-04,
           6.59028083e-05],
          [9.90550995e-01, 5.62330987e-03, 3.60006443e-03,
           2.25627606e-04],
          [9.80501592e-01, 1.17022442e-02, 6.92124711e-03,
           8.74817080e-04]],

         [[9.98247385e-01, 9.11672076e-04, 6.82740530e-04,
           1.58253606e-04],
          [9.99848008e-01, 6.31702424e-05, 6.26166366e-05,
           2.62204358e-05],
          [9.99898314e-01, 3.66708555e-05, 4.37101553e-05,
           2.12401883e-05],
          ...,
          [9.99815524e-01, 9.09222144e-05, 7.27751685e-05,
           2.07578596e-05],
          [9.99387383e-01, 2.29283803e-04, 3.51779978e-04,
           3.14342542e-05],
          [9.86483753e-01, 6.83134189e-03, 5.80396876e-03,
           8.80846346e-04]],

         ...,

         [[9.99824345e-01, 6.80103185e-05, 6.41149527e-05,
           4.35185939e-05],
          [9.99875903e-01, 3.09061907e-05, 3.90299865e-05,
           5.42180605e-05],
          [9.99840617e-01, 3.94879462e-05, 5.51853263e-05,
           6.47128400e-05],
          ...,
          [9.99897599e-01, 3.46336565e-05, 3.01442687e-05,
           3.75267082e-05],
          [9.99766767e-01, 7.30737884e-05, 8.21543799e-05,
           7.80147238e-05],
          [9.99739707e-01, 6.28561029e-05, 9.00378946e-05,
           1.07411790e-04]],

         [[9.99764621e-01, 8.65339607e-05, 8.31120633e-05,
           6.57661731e-05],
          [9.99847651e-01, 4.02694859e-05, 4.69114530e-05,
           6.50726724e-05],
          [9.99834180e-01, 4.82922733e-05, 5.16164764e-05,
           6.58758436e-05],
          ...,
          [9.99871016e-01, 4.92259569e-05, 3.11463918e-05,
           4.86453100e-05],
          [9.99729216e-01, 1.06965686e-04, 9.50745816e-05,
           6.86841013e-05],
          [9.99707282e-01, 8.88923969e-05, 1.19217148e-04,
           8.46012554e-05]],

         [[9.99369323e-01, 2.53884587e-04, 2.40719484e-04,
           1.36050745e-04],
          [9.99575317e-01, 1.32062021e-04, 1.57581322e-04,
           1.35082286e-04],
          [9.99678373e-01, 1.16248608e-04, 1.24028375e-04,
           8.13798324e-05],
          ...,
          [9.99737799e-01, 1.00144673e-04, 9.20240273e-05,
           7.00317687e-05],
          [9.99523044e-01, 2.09950711e-04, 1.55791233e-04,
           1.11209498e-04],
          [9.98035371e-01, 4.98510140e-04, 1.15716667e-03,
           3.08918301e-04]]],


        ...,


        [[[9.99241948e-01, 3.76991607e-04, 2.60952977e-04,
           1.20149285e-04],
          [9.99810517e-01, 8.92934549e-05, 4.34380454e-05,
           5.68170253e-05],
          [9.99819219e-01, 9.21367318e-05, 4.06139734e-05,
           4.80277849e-05],
          ...,
          [9.99812543e-01, 1.11460569e-04, 2.95608806e-05,
           4.64359509e-05],
          [9.99780476e-01, 1.27188148e-04, 4.97611582e-05,
           4.26040278e-05],
          [9.98126447e-01, 1.00942689e-03, 5.42199297e-04,
           3.21900297e-04]],

         [[9.99787867e-01, 1.06443404e-04, 5.93496843e-05,
           4.63754550e-05],
          [9.99881029e-01, 4.42884921e-05, 2.74722697e-05,
           4.71664862e-05],
          [9.99899745e-01, 3.32742966e-05, 2.48923661e-05,
           4.20642973e-05],
          ...,
          [9.99826133e-01, 8.90780502e-05, 3.04290006e-05,
           5.43778442e-05],
          [9.99848843e-01, 7.82225106e-05, 4.07649677e-05,
           3.22178021e-05],
          [9.99863386e-01, 4.47032617e-05, 6.12864169e-05,
           3.05706308e-05]],

         [[9.99822915e-01, 7.98448236e-05, 4.90353741e-05,
           4.81882635e-05],
          [9.99888539e-01, 2.66457064e-05, 2.24804935e-05,
           6.22395673e-05],
          [9.99907136e-01, 2.29321777e-05, 1.86234356e-05,
           5.13664054e-05],
          ...,
          [9.99882817e-01, 4.91400424e-05, 2.14466781e-05,
           4.66324018e-05],
          [9.99848962e-01, 6.10047537e-05, 3.91984322e-05,
           5.07440054e-05],
          [9.99851823e-01, 3.38595819e-05, 6.06925569e-05,
           5.35853142e-05]],

         ...,

         [[9.99814689e-01, 7.31787004e-05, 5.76218663e-05,
           5.44957984e-05],
          [9.99890566e-01, 2.44441781e-05, 2.69613429e-05,
           5.80715059e-05],
          [9.99866605e-01, 2.89071213e-05, 3.36293087e-05,
           7.08025036e-05],
          ...,
          [9.99895573e-01, 3.52376155e-05, 2.67452851e-05,
           4.24417267e-05],
          [9.99828935e-01, 5.22103983e-05, 5.52909332e-05,
           6.34825919e-05],
          [9.99739468e-01, 5.89987467e-05, 1.00362064e-04,
           1.01186270e-04]],

         [[9.99734700e-01, 1.09512403e-04, 7.67148376e-05,
           7.89929545e-05],
          [9.99808371e-01, 5.24412644e-05, 4.49010149e-05,
           9.42943152e-05],
          [9.99875903e-01, 3.24138528e-05, 3.35040713e-05,
           5.81537279e-05],
          ...,
          [9.99891281e-01, 4.06958461e-05, 2.53250291e-05,
           4.27276136e-05],
          [9.99834061e-01, 6.69738729e-05, 5.35688305e-05,
           4.53095308e-05],
          [9.99718487e-01, 7.31143227e-05, 1.32644171e-04,
           7.57302478e-05]],

         [[9.99438703e-01, 2.53173464e-04, 1.79374561e-04,
           1.28763582e-04],
          [9.99700308e-01, 1.00533616e-04, 9.42090701e-05,
           1.04940271e-04],
          [9.99803483e-01, 6.50198635e-05, 7.00688979e-05,
           6.14187156e-05],
          ...,
          [9.99776781e-01, 9.01013627e-05, 7.29263775e-05,
           6.01959728e-05],
          [9.99649048e-01, 1.27976717e-04, 1.35095863e-04,
           8.78673163e-05],
          [9.97662306e-01, 6.37953868e-04, 1.37569953e-03,
           3.24109016e-04]]],


        [[[9.97759581e-01, 1.17073127e-03, 7.89838319e-04,
           2.79818138e-04],
          [9.99337494e-01, 3.95031384e-04, 1.42112811e-04,
           1.25368068e-04],
          [9.99579489e-01, 2.81458488e-04, 7.52195774e-05,
           6.38569618e-05],
          ...,
          [9.99573052e-01, 3.22924374e-04, 5.88688818e-05,
           4.51004526e-05],
          [9.99319673e-01, 4.70835075e-04, 1.64291589e-04,
           4.52669192e-05],
          [9.97539759e-01, 1.58203288e-03, 6.35663164e-04,
           2.42555339e-04]],

         [[9.99586046e-01, 2.07386445e-04, 1.30182976e-04,
           7.64560682e-05],
          [9.99835372e-01, 7.39255702e-05, 3.65812266e-05,
           5.41510635e-05],
          [9.99899507e-01, 4.52681379e-05, 2.86037830e-05,
           2.66358875e-05],
          ...,
          [9.99845266e-01, 1.02586993e-04, 2.53796916e-05,
           2.67497308e-05],
          [9.99714553e-01, 1.98526133e-04, 6.29044152e-05,
           2.39841775e-05],
          [9.99732673e-01, 1.22003170e-04, 1.19178105e-04,
           2.60692377e-05]],

         [[9.99686956e-01, 1.34070084e-04, 9.98585310e-05,
           7.91930506e-05],
          [9.99885440e-01, 3.97633958e-05, 2.41692505e-05,
           5.05743956e-05],
          [9.99917388e-01, 2.85161805e-05, 2.09286827e-05,
           3.31631491e-05],
          ...,
          [9.99861002e-01, 7.44694189e-05, 2.57254906e-05,
           3.87910986e-05],
          [9.99789894e-01, 1.18765674e-04, 5.44701870e-05,
           3.69105765e-05],
          [9.99858737e-01, 5.81256754e-05, 5.50186414e-05,
           2.80187796e-05]],

         ...,

         [[9.99698162e-01, 1.13382979e-04, 1.08920969e-04,
           7.96056338e-05],
          [9.99883056e-01, 3.45529188e-05, 3.14718964e-05,
           5.08649791e-05],
          [9.99886155e-01, 2.79254855e-05, 3.98572811e-05,
           4.60735828e-05],
          ...,
          [9.99906898e-01, 3.46096786e-05, 2.95366190e-05,
           2.90262178e-05],
          [9.99867439e-01, 6.56745324e-05, 4.22323210e-05,
           2.45759602e-05],
          [9.99700427e-01, 1.12148344e-04, 1.27897394e-04,
           5.95931851e-05]],

         [[9.99535561e-01, 2.06971323e-04, 1.52920533e-04,
           1.04582919e-04],
          [9.99861240e-01, 5.63664944e-05, 3.23255517e-05,
           4.99907437e-05],
          [9.99925494e-01, 2.84771158e-05, 2.02730680e-05,
           2.56946878e-05],
          ...,
          [9.99942183e-01, 2.55097711e-05, 1.61054977e-05,
           1.62177657e-05],
          [9.99868155e-01, 6.42884697e-05, 4.56444250e-05,
           2.19606063e-05],
          [9.99196708e-01, 3.20165796e-04, 3.72457609e-04,
           1.10718327e-04]],

         [[9.98680055e-01, 5.72550169e-04, 5.28019096e-04,
           2.19423047e-04],
          [9.99352872e-01, 1.87080994e-04, 2.47466523e-04,
           2.12583531e-04],
          [9.99630570e-01, 1.09480738e-04, 1.57413844e-04,
           1.02541882e-04],
          ...,
          [9.99589384e-01, 1.35969938e-04, 1.64636949e-04,
           1.10022273e-04],
          [9.99094725e-01, 3.01533903e-04, 4.51850559e-04,
           1.51897053e-04],
          [9.94673550e-01, 1.53220736e-03, 3.16416170e-03,
           6.30103692e-04]]],


        [[[9.90488529e-01, 5.78244822e-03, 2.75779446e-03,
           9.71313100e-04],
          [9.98085022e-01, 8.05308111e-04, 8.70799646e-04,
           2.38890760e-04],
          [9.98273611e-01, 8.67770519e-04, 6.67474349e-04,
           1.91141415e-04],
          ...,
          [9.98359501e-01, 8.88890412e-04, 6.15989498e-04,
           1.35584458e-04],
          [9.97966766e-01, 9.74288851e-04, 9.27205198e-04,
           1.31661014e-04],
          [9.93097365e-01, 3.31127620e-03, 2.83692079e-03,
           7.54466397e-04]],

         [[9.96248543e-01, 2.23698816e-03, 1.10566081e-03,
           4.08803171e-04],
          [9.98966694e-01, 4.87955112e-04, 3.56649165e-04,
           1.88710677e-04],
          [9.99649286e-01, 1.73599808e-04, 1.21802470e-04,
           5.52428428e-05],
          ...,
          [9.99495745e-01, 3.00223968e-04, 1.51574030e-04,
           5.24286661e-05],
          [9.98815417e-01, 6.41135906e-04, 4.67494858e-04,
           7.59636896e-05],
          [9.98257339e-01, 6.97889889e-04, 9.06036003e-04,
           1.38647025e-04]],

         [[9.98416781e-01, 7.67478603e-04, 5.33042185e-04,
           2.82757537e-04],
          [9.99697328e-01, 1.02239173e-04, 9.73751230e-05,
           1.03124505e-04],
          [9.99839664e-01, 6.09959898e-05, 5.15188913e-05,
           4.78054426e-05],
          ...,
          [9.99728739e-01, 1.29837761e-04, 7.97360335e-05,
           6.17233818e-05],
          [9.99473512e-01, 2.67173134e-04, 1.80959498e-04,
           7.84759759e-05],
          [9.98458624e-01, 6.52093906e-04, 6.84719707e-04,
           2.04504380e-04]],

         ...,

         [[9.98682201e-01, 5.51945297e-04, 5.26794000e-04,
           2.39035522e-04],
          [9.99702156e-01, 8.88710856e-05, 1.17120930e-04,
           9.17878788e-05],
          [9.99807537e-01, 5.25885589e-05, 8.08243713e-05,
           5.91013122e-05],
          ...,
          [9.99745071e-01, 8.45695977e-05, 1.07763670e-04,
           6.24873646e-05],
          [9.99434412e-01, 2.01267074e-04, 2.64112139e-04,
           1.00255405e-04],
          [9.98202443e-01, 6.45969936e-04, 8.74007237e-04,
           2.77518382e-04]],

         [[9.97977197e-01, 9.55011579e-04, 7.35278882e-04,
           3.32554046e-04],
          [9.99570310e-01, 1.40825345e-04, 1.46022954e-04,
           1.42809920e-04],
          [9.99785483e-01, 7.01843383e-05, 7.47591621e-05,
           6.95605704e-05],
          ...,
          [9.99726117e-01, 9.82756028e-05, 9.99935801e-05,
           7.55385990e-05],
          [9.98874247e-01, 4.72007785e-04, 4.77315101e-04,
           1.76368529e-04],
          [9.97336209e-01, 8.94335099e-04, 1.47728354e-03,
           2.92160752e-04]],

         [[9.96320248e-01, 1.48796756e-03, 1.71661517e-03,
           4.75164125e-04],
          [9.98249710e-01, 5.16892585e-04, 8.91277567e-04,
           3.42024752e-04],
          [9.99014735e-01, 2.57669803e-04, 5.32343052e-04,
           1.95179789e-04],
          ...,
          [9.97763872e-01, 6.19080907e-04, 1.26694445e-03,
           3.50082089e-04],
          [9.96724784e-01, 1.00233534e-03, 1.80837233e-03,
           4.64521465e-04],
          [9.89648640e-01, 4.02319012e-03, 5.30836824e-03,
           1.01978320e-03]]]]], dtype=float32)>}
output shape:  (1, 160, 160, 80, 4)
/home/ubuntu/uploads/test/test/nifti/processed_ggo.nii.gz
ggo prediction complete in  100.86867761611938  seconds
starting post processing
Traceback (most recent call last):
  File "/root/miniconda3/envs/trt2/lib/python3.7/site-packages/nibabel/loadsave.py", line 42, in load
    stat_result = os.stat(filename)
FileNotFoundError: [Errno 2] No such file or directory: '../uploads/test/test/nifti/processed_lobe.nii.gz'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 75, in <module>
    img_lobe = nib.load(output_folder + 'processed_lobe.nii.gz')
  File "/root/miniconda3/envs/trt2/lib/python3.7/site-packages/nibabel/loadsave.py", line 44, in load
    raise FileNotFoundError("No such file or no access: '%s'" % filename)
FileNotFoundError: No such file or no access: '../uploads/test/test/nifti/processed_lobe.nii.gz'
==24337== Profiling application: python main.py test test
==24337== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   33.60%  14.5902s      9338  1.5625ms     736ns  4.6566ms  [CUDA memset]
                   10.42%  4.52647s      5250  862.18us  4.5120us  7.8959ms  generatedNativePointwise
                    7.84%  3.40631s     24924  136.67us  11.328us  1.1939ms  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    6.59%  2.86082s        54  52.978ms  1.6109ms  121.20ms  void implicit_convolveNd_sgemm<float, int=3, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_convNd_params, __int64, int, float, float, int, float const *, float const *)
                    5.59%  2.42820s       893  2.7191ms  3.2320us  100.28ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    2.35%  1.02034s       251  4.0651ms  10.208us  41.678ms  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=5>, int=5>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=5)
                    1.64%  711.49ms        15  47.433ms  3.5790ms  208.80ms  void implicit_convolveNd_sgemm<__half, int=3, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_convNd_params, __int64, int, float, float, int, __half const *, __half const *)
                    1.38%  598.56ms        24  24.940ms  1.6161ms  47.378ms  void implicit_convolveNd_sgemm<__half, int=3, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_convNd_params, __int64, int, float, float, int, __half const *, __half const *)
                    1.23%  535.49ms        17  31.500ms  26.010ms  35.394ms  volta_scudnn_128x32_3dconv_fprop_small_nn_v1
                    1.16%  503.93ms       248  2.0320ms  8.8000us  36.666ms  void genericReformat::copyPackedKernel<__half, __half, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=5>, int=5>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=5)
                    1.11%  481.23ms       182  2.6441ms  2.7520us  32.966ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    1.09%  475.15ms       128  3.7121ms  11.680us  23.794ms  void genericReformat::copyPackedKernel<__half, __half, bool=0, bool=1, genericReformat::ArrayN<int=5>, int=5>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=5>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=5>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=5)
                    1.07%  466.03ms     60292  7.7290us  1.3760us  2.9483ms  void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)
                    1.03%  449.22ms       570  788.10us  3.2310us  8.8469ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.99%  430.79ms       153  2.8156ms  2.7200us  32.293ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.85%  368.22ms       548  671.93us  3.1030us  5.7301ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.74%  322.20ms     16822  19.153us  6.6870us  1.4290ms  void fft3d_r2c_16x16x16<float, float, float2>(float2*, float*, int3, int3, int3, int3, int3, bool)
                    0.73%  318.22ms       100  3.1822ms  22.815us  26.346ms  void cuPointwise::launchPointwise<cuPointwise::StripMineAlgo<__half, int, int=32>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.73%  317.30ms       378  839.41us  1.5040us  11.007ms  void genericReformat::copyPackedKernel<__half, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.62%  268.21ms       100  2.6821ms  17.407us  16.732ms  void cuPointwise::launchPointwise<cuPointwise::StripMineAlgo<__half, int, int=64>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.61%  264.30ms       279  947.31us  3.0720us  6.8354ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.59%  258.21ms       100  2.5821ms  15.967us  16.603ms  void cuPointwise::launchPointwise<cuPointwise::StripMineAlgo<__half, int, int=128>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.57%  246.39ms       124  1.9870ms  21.151us  14.733ms  void cuPointwise::launchPointwise<cuPointwise::StripMineAlgo<float, float, int=32>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.56%  243.88ms       170  1.4346ms     896ns  22.058ms  [CUDA memcpy DtoH]
                    0.54%  233.45ms       124  1.8827ms  16.576us  10.959ms  void cuPointwise::launchPointwise<cuPointwise::StripMineAlgo<float, float, int=64>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.53%  232.13ms     16782  13.832us  5.0870us  50.975us  void fft3d_c2r_16x16x16<float2, float, float>(float*, float2*, int3, int3, int3, int3, int3, float, float, bool, int, float*, float*)
                    0.53%  231.33ms       293  789.53us  1.4720us  8.0220ms  void genericReformat::copyPackedKernel<float, __half, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.53%  231.04ms       124  1.8632ms  15.007us  10.959ms  void cuPointwise::launchPointwise<cuPointwise::StripMineAlgo<float, float, int=128>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.52%  226.93ms       205  1.1070ms  2.7840us  20.915ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.51%  221.59ms       225  984.84us  2.7840us  21.447ms  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.48%  207.41ms        75  2.7655ms  132.09us  14.209ms  void genericReformat::copyPackedKernel<__half, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.47%  203.92ms     13362  15.261us  5.3440us  1.3361ms  void fft3d_r2c_16x16x16<__half, float, float2>(float2*, __half*, int3, int3, int3, int3, int3, bool)
                    0.47%  202.95ms        20  10.148ms  110.75us  16.889ms  void genericReformat::copyPackedKernel<__half, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=5>, int=5>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=5)
                    0.45%  194.54ms       182  1.0689ms  1.4720us  11.432ms  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.44%  190.64ms         8  23.830ms  2.8733ms  72.623ms  void dgrad_alg1_nd_float_engine<float, int=3, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_gradNd_params, __int64, int, float, float)
                    0.41%  178.15ms       196  908.95us  1.4720us  7.6967ms  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.37%  161.70ms       124  1.3040ms  15.456us  9.4546ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<float, float, int=512>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.35%  150.86ms       382  394.92us  6.1440us  3.8213ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.33%  145.07ms       270  537.30us  1.5360us  7.0363ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.33%  141.89ms     13326  10.647us  5.1200us  44.512us  void fft3d_c2r_16x16x16<float2, float, __half>(__half*, float2*, int3, int3, int3, int3, int3, float, float, bool, int, __half*, __half*)
                    0.33%  141.74ms       124  1.1431ms  14.303us  8.7414ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<float, float, int=256>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.31%  136.55ms       124  1.1012ms  14.176us  8.5150ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<float, float, int=128>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.31%  135.20ms       108  1.2519ms  11.648us  4.7049ms  void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<float, int=256, int=32, int=32, bool=0>(float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<float, int=256, int=32, int=32, bool=0>*)
                    0.31%  133.30ms       156  854.48us  6.0790us  5.7206ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.30%  130.56ms       128  1.0200ms  14.463us  8.1469ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<__half, long, int=128>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.30%  128.42ms       237  541.85us  1.5040us  6.8503ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.29%  126.22ms        27  4.6750ms  2.8781ms  5.7726ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.29%  125.55ms       128  980.82us  16.255us  7.8048ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<__half, long, int=512>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.29%  123.97ms       128  968.53us  14.912us  7.7203ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<__half, long, int=256>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.27%  115.77ms         9  12.864ms  9.4905ms  20.176ms  volta_scudnn_128x64_3dconv_fprop_xregs_large_nn_v1
                    0.27%  115.53ms      5184  22.286us  14.048us  31.776us  void gemmk1_kernel<float2, int=256, int=5, bool=1, bool=0, bool=0, bool=0, cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, float2 const , cublasGemvTensorStridedBatched<float2 const >, float2, biasType<cublasGemvTensorStridedBatched<float2 const >value_type, float2>::type>)
                    0.26%  112.54ms         3  37.512ms  36.921ms  37.836ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Volta_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Volta, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Volta_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Volta, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Volta_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Volta, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Volta_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Volta, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Volta_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Volta, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Volta_hmma_fp32_traitsParams)
                    0.25%  109.69ms       642  170.85us     735ns  5.8212ms  [CUDA memcpy HtoD]
                    0.24%  103.88ms       193  538.26us  1.2480us  5.2277ms  void cuInt8::nchwTonchw<__half, float, int=4>(__half const *, float*, int, int, int, float const *, float const , cuInt8::ReducedDivisorParameters)
                    0.23%  100.73ms         3  33.577ms  33.563ms  33.599ms  void cudnn::ops::softmax_fw_kernel<int=2, float, float, int=256, int=1, int=1, int=0>(cudnnTensorStruct, float const *, cudnn::ops::softmax_fw_kernel<int=2, float, float, int=256, int=1, int=1, int=0>, cudnnTensorStruct*, int, float, cudnnTensorStruct*, int, int)
                    0.23%  100.70ms         3  33.566ms  33.562ms  33.570ms  void cudnn::ops::softmax_fw_kernel<int=2, __half, float, int=256, int=1, int=1, int=0>(cudnnTensorStruct, __half const *, cudnn::ops::softmax_fw_kernel<int=2, __half, float, int=256, int=1, int=1, int=0>, cudnnTensorStruct*, int, float, cudnnTensorStruct*, int, int)
                    0.20%  86.187ms        12  7.1822ms  3.1782ms  14.062ms  void implicit_convolveNd_sgemm<float, int=3, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_convNd_params, __int64, int, float, float, int, float const *, float const *)
                    0.18%  80.248ms        36  2.2291ms  307.77us  2.8946ms  void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)
                    0.18%  76.057ms        64  1.1884ms  17.152us  9.1204ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<__half, int, int=512>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.17%  74.396ms        33  2.2544ms  276.44us  5.2398ms  void convolveNd_dgrad_float_engine<float, int=3, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_gradNd_params, __int64, int, __int64, int, float, int)
                    0.17%  74.167ms       173  428.71us  1.2800us  4.0019ms  void cuInt8::nchwTonchw<float, __half, int=8>(float const *, __half*, int, int, int, float const *, float const , cuInt8::ReducedDivisorParameters)
                    0.17%  72.814ms        64  1.1377ms  15.488us  8.8629ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<__half, int, int=128>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.17%  72.738ms        64  1.1365ms  15.680us  8.8721ms  void cuPointwise::launchPointwise<cuPointwise::SimpleAlgo<__half, int, int=256>>(cuPointwise::LaunchParams, nvinfer1::VirtualMachineProgram)
                    0.16%  71.431ms        42  1.7007ms  63.967us  3.8996ms  void cuInt8::nhwcTonchw<float, int=32, int=32, int=2>(__half const *, float*, int, int, int, int, int, int)
                    0.15%  66.510ms       140  475.07us  1.5680us  4.6991ms  void genericReformat::copyPackedKernel<float, __half, bool=0, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.15%  65.362ms       177  369.28us  1.0880us  3.3367ms  void cuInt8::nchhw2ToNchw<float>(__half const *, float*, int, int, int, int, int, int, cuInt8::ReducedDivisorParameters)
                    0.14%  59.968ms        12  4.9973ms  2.2652ms  8.7514ms  volta_scudnn_128x128_3dconv_fprop_small_nn_v1
                    0.13%  58.073ms        15  3.8716ms  1.6408ms  6.5154ms  void implicit_convolveNd_sgemm<float, int=3, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_convNd_params, __int64, int, float, float, int, float const *, float const *)
                    0.13%  56.649ms        36  1.5736ms  792.43us  2.2292ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.13%  55.838ms       374  149.30us  2.7840us  2.4688ms  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    0.12%  53.559ms        12  4.4632ms  1.6283ms  6.7391ms  void implicit_convolveNd_sgemm<__half, int=3, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_convNd_params, __int64, int, float, float, int, __half const *, __half const *)
                    0.12%  51.644ms        18  2.8691ms  2.8452ms  2.9357ms  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, unsigned long=2> const , Eigen::array<int, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::GpuDevice>, int>(int, unsigned long=2)
                    0.11%  47.876ms       144  332.47us  1.0880us  2.9367ms  void cuInt8::nchhw2ToNchw<__half>(__half const *, __half*, int, int, int, int, int, int, cuInt8::ReducedDivisorParameters)
                    0.11%  46.045ms        32  1.4389ms  41.407us  6.9074ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.10%  44.362ms       101  439.23us  28.832us  2.1227ms  void genericReformat::copyPackedKernel<float, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.10%  42.927ms        18  2.3849ms  2.3782ms  2.3934ms  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)
                    0.10%  42.912ms        48  893.99us  379.29us  1.7949ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.10%  42.859ms        18  2.3811ms  2.3702ms  2.3947ms  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)
                    0.10%  42.372ms        18  2.3540ms  2.3437ms  2.3648ms  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const , int=0>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)
                    0.10%  42.082ms       130  323.71us  1.1200us  3.3923ms  void cuInt8::nchwToNchhw2<float>(float const *, __half*, int, int, int, int, int, int, cuInt8::ReducedDivisorParameters)
                    0.09%  39.613ms        32  1.2379ms  152.16us  2.9041ms  void cuInt8::nchwTonhwc<__half, int=32, int=32, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
                    0.09%  38.105ms       126  302.42us  1.0880us  3.2526ms  void cuInt8::nchwToNchhw2<__half>(__half const *, __half*, int, int, int, int, int, int, cuInt8::ReducedDivisorParameters)
                    0.09%  37.343ms       187  199.70us  3.8720us  1.0961ms  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    0.08%  36.712ms        21  1.7482ms  1.5290ms  1.9031ms  void implicit_convolveNd_sgemm<__half, int=3, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_convNd_params, __int64, int, float, float, int, __half const *, __half const *)
                    0.08%  34.235ms        27  1.2680ms  116.73us  3.4789ms  void cuInt8::nchwTonhwc<float, int=32, int=32, int=2>(float const *, __half*, int, int, int, int, int, int, int, int)
                    0.07%  31.109ms         9  3.4565ms  2.1321ms  4.3516ms  volta_scudnn_128x64_3dconv_fprop_small_nn_v1
                    0.07%  30.759ms        12  2.5633ms  1.4824ms  4.3119ms  void implicit_convolveNd_sgemm<float, int=3, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_convNd_params, __int64, int, float, float, int, float const *, float const *)
                    0.07%  30.304ms        30  1.0101ms  44.191us  3.7269ms  void cuEltwise::eltwise<cuEltwise::StripMineAlgo<float, float>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    0.07%  28.819ms        30  960.63us  54.815us  2.3149ms  void cuInt8::nhwcTonchw<__half, int=32, int=32, int=2>(__half const *, __half*, int, int, int, int, int, int)
                    0.06%  26.423ms        54  489.32us  34.976us  2.1443ms  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<float, float>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    0.06%  26.127ms        28  933.12us  37.984us  3.5066ms  void genericReformat::copyPackedKernel<float, __half, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.06%  25.845ms        23  1.1237ms  145.85us  2.6451ms  void cuInt8::nchhw2Tonhwc8<int=32, int=32, int=2>(__half const *, cuInt8::nchhw2Tonhwc8<int=32, int=32, int=2>*, int, int, int, int, int, int)
                    0.06%  25.165ms        36  699.02us  422.84us  1.1089ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, bool=1>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.06%  24.274ms        27  899.03us  16.863us  6.7257ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.05%  22.216ms        20  1.1108ms  123.23us  3.0912ms  void genericReformat::copyPackedKernel<__half, __half, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.05%  21.872ms        23  950.94us  140.89us  2.2914ms  void cuInt8::nhwc8Tonchhw2<int=32, int=32, int=2>(__half const *, cuInt8::nhwc8Tonchhw2<int=32, int=32, int=2>*, int, int, int, int, int, int)
                    0.05%  21.647ms        50  432.93us  20.448us  1.8867ms  void genericReformat::copyPackedKernel<__half, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.05%  20.935ms        28  747.68us  29.504us  3.0909ms  void genericReformat::copyPackedKernel<__half, __half, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.05%  20.930ms         9  2.3256ms  2.2536ms  2.4061ms  void tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::_GLOBAL__N__64_tmpxft_000035ef_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_72108368::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>(float, float, int, int, float, std::iterator_traits<tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::_GLOBAL__N__64_tmpxft_000035ef_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_72108368::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>>::value_type)
                    0.05%  20.682ms        28  738.66us  14.976us  3.7414ms  void cuEltwise::eltwise<cuEltwise::StripMineAlgo<__half, int>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    0.04%  19.245ms        18  1.0692ms  1.0036ms  1.1306ms  volta_sgemm_32x128_nn
                    0.04%  18.752ms        44  426.17us  18.336us  1.2672ms  void cudnn::ops::setTensor5d_kernel<float, float, int=8, int=8, int=8>(cudnnTensorStruct, float*, float)
                    0.04%  17.969ms        33  544.53us  21.024us  1.2856ms  void cuPoolingNd::pooling_NCDHW<float>(float const *, cuPoolingNd::pooling_NCDHW<float>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<float>*PoolingParameters, cuPoolingNd::pooling_NCDHW<float>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<float>*rt, cuPoolingNd::pooling_NCDHW<float>*rt)
                    0.04%  17.086ms         9  1.8984ms  1.8376ms  1.9563ms  void tensorflow::functor::RowReduceKernel<float const *, float*, cub::Max>(float const *, float*, int, int, cub::Max, std::iterator_traits<tensorflow::functor::RowReduceKernel<float const *, float*, cub::Max>>::value_type)
                    0.03%  14.902ms        56  266.10us  22.624us  926.38us  void cuInt8::nhwcTonchw<float, int=32, int=16, int=2>(__half const *, float*, int, int, int, int, int, int)
                    0.03%  12.306ms        68  180.97us  146.01us  228.41us  redzone_checker
                    0.02%  10.489ms        47  223.17us  9.2150us  1.0724ms  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<__half, long>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    0.02%  10.394ms        47  221.15us  2.4320us  638.84us  cask_cudnn::computeOffsetsKernel3D(cask_cudnn::ComputeOffsetsParams)
                    0.02%  9.4944ms        30  316.48us  10.783us  1.1068ms  void genericReformat::copyPackedKernel<__half2, __half2, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.02%  9.4491ms         3  3.1497ms  3.1468ms  3.1547ms  void cuSoftMaxLayer::nchwSoftmaxAxisWSmall<float, unsigned int=32>(int, float const *, cuSoftMaxLayer::nchwSoftmaxAxisWSmall<float, unsigned int=32>*)
                    0.02%  9.3133ms         3  3.1044ms  3.1039ms  3.1049ms  void cuSoftMaxLayer::nchwSoftmaxAxisWSmall<__half, unsigned int=32>(int, __half const *, cuSoftMaxLayer::nchwSoftmaxAxisWSmall<__half, unsigned int=32>*)
                    0.02%  8.3759ms        46  182.09us  12.320us  559.70us  void cuInt8::nhwcTonchw<__half, int=32, int=16, int=2>(__half const *, __half*, int, int, int, int, int, int)
                    0.02%  7.8526ms        35  224.36us  25.567us  810.32us  void cuInt8::nchwTonhwc<float, int=32, int=16, int=2>(float const *, __half*, int, int, int, int, int, int, int, int)
                    0.02%  7.3505ms        11  668.22us  577.40us  756.44us  void convolveNd_dgrad_float_engine<float, int=3, int=128, int=6, int=8, int=3, int=3, int=5, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_gradNd_params, __int64, int, __int64, int, float, int)
                    0.02%  7.0297ms        39  180.25us  15.232us  612.73us  void cuInt8::nchhw2Tonhwc8<int=32, int=16, int=2>(__half const *, cuInt8::nchhw2Tonhwc8<int=32, int=16, int=2>*, int, int, int, int, int, int)
                    0.02%  6.9863ms        39  179.14us  17.887us  624.05us  void cuInt8::nchwTonhwc<__half, int=32, int=16, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
                    0.02%  6.7467ms        25  269.87us  154.65us  403.16us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.02%  6.5298ms        39  167.43us  11.744us  556.44us  void cuInt8::nhwc8Tonchhw2<int=32, int=16, int=2>(__half const *, cuInt8::nhwc8Tonchhw2<int=32, int=16, int=2>*, int, int, int, int, int, int)
                    0.01%  5.9931ms        14  428.08us  19.776us  1.4821ms  void cuPoolingNd::Kernel_max_pooling_3D_ncdhw<bool=0, float, int=2, int=2, int=2, int=2, int=2, int=2>(cuPoolingNd::KernelParams)
                    0.01%  5.2420ms        19  275.89us  14.944us  1.0864ms  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<__half, int>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    0.01%  5.2101ms        33  157.88us  9.9200us  743.16us  void cuPoolingNd::pooling_NCDHW<__half>(__half const *, cuPoolingNd::pooling_NCDHW<__half>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<__half>*PoolingParameters, cuPoolingNd::pooling_NCDHW<__half>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<__half>*rt, cuPoolingNd::pooling_NCDHW<__half>*rt)
                    0.01%  4.4459ms        44  101.04us  3.1360us  225.44us  void cuInt8::nhwcTonchw<float, int=32, int=8, int=2>(__half const *, float*, int, int, int, int, int, int)
                    0.01%  4.1655ms        12  347.12us  289.18us  375.29us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.01%  3.2885ms         9  365.39us  362.65us  368.57us  void tensorflow::_GLOBAL__N__64_tmpxft_000035ef_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_72108368::GenerateNormalizedProb<float, float, int=4>(float const *, float const *, float const , tensorflow::_GLOBAL__N__64_tmpxft_000035ef_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_72108368::GenerateNormalizedProb<float, float, int=4>*, int, int, bool)
                    0.01%  3.2481ms        15  216.54us  16.000us  753.68us  void cuPoolingNd::Kernel_max_pooling_3D_ncdhw<bool=0, __half, int=2, int=2, int=2, int=2, int=2, int=2>(cuPoolingNd::KernelParams)
                    0.01%  2.9578ms        28  105.64us  4.4800us  245.37us  void cuInt8::nchwTonhwc<float, int=32, int=8, int=2>(float const *, __half*, int, int, int, int, int, int, int, int)
                    0.01%  2.3212ms        28  82.900us  3.3600us  194.43us  void cuInt8::nchhw2Tonhwc8<int=32, int=8, int=2>(__half const *, cuInt8::nchhw2Tonhwc8<int=32, int=8, int=2>*, int, int, int, int, int, int)
                    0.01%  2.2747ms        28  81.238us  4.5120us  187.04us  void cuInt8::nchwTonhwc<__half, int=32, int=8, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
                    0.01%  2.2023ms        32  68.822us  3.1040us  136.48us  void cuInt8::nhwcTonchw<__half, int=32, int=8, int=2>(__half const *, __half*, int, int, int, int, int, int)
                    0.00%  1.8606ms        40  46.515us  2.6240us  76.127us  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=16, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=16 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.00%  1.8115ms        16  113.22us  2.6240us  152.22us  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=16, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=16 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.00%  1.6633ms        28  59.403us  3.0080us  136.19us  void cuInt8::nhwc8Tonchhw2<int=32, int=8, int=2>(__half const *, cuInt8::nhwc8Tonchhw2<int=32, int=8, int=2>*, int, int, int, int, int, int)
                    0.00%  887.15us        54  16.428us  3.1680us  59.455us  void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)
                    0.00%  793.11us        23  34.482us  2.6560us  249.15us  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, bool=0>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)
                    0.00%  778.90us        23  33.865us  2.6240us  243.61us  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, bool=0>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)
                    0.00%  550.61us        23  23.939us  5.1840us  142.46us  void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>(__int64 const *, __int64 const , tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, __int64 const *)
                    0.00%  490.14us         4  122.53us  122.30us  122.88us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=5>, int=5>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=5>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=5)
                    0.00%  261.08us        97  2.6910us  2.4960us  7.5520us  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)
                    0.00%  105.92us        67  1.5800us  1.3760us  2.0160us  void cuInt8::nchwTonhwc<__half, int=32, int=4, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
                    0.00%  76.992us        47  1.6380us  1.2160us  2.3360us  cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)
                    0.00%  63.583us        23  2.7640us  2.5920us  3.2320us  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)
                    0.00%  57.503us        40  1.4370us  1.3440us  1.5040us  void cuInt8::nchwTonhwc<float, int=32, int=4, int=2>(float const *, __half*, int, int, int, int, int, int, int, int)
                    0.00%  52.606us        40  1.3150us  1.1830us  1.4080us  void cuInt8::nchhw2Tonhwc8<int=32, int=4, int=2>(__half const *, cuInt8::nchhw2Tonhwc8<int=32, int=4, int=2>*, int, int, int, int, int, int)
                    0.00%  47.648us        40  1.1910us  1.1520us  1.2480us  void cuInt8::nhwcTonchw<float, int=32, int=4, int=2>(__half const *, float*, int, int, int, int, int, int)
                    0.00%  47.328us        40  1.1830us  1.1520us  1.2160us  void cuInt8::nhwcTonchw<__half, int=32, int=4, int=2>(__half const *, __half*, int, int, int, int, int, int)
                    0.00%  47.295us        40  1.1820us  1.1200us  1.2480us  void cuInt8::nhwc8Tonchhw2<int=32, int=4, int=2>(__half const *, cuInt8::nhwc8Tonchhw2<int=32, int=4, int=2>*, int, int, int, int, int, int)
                    0.00%  47.102us        16  2.9430us  2.6240us  3.3280us  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=16, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=16 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.00%  35.008us        12  2.9170us  2.6560us  3.3280us  void CUTENSOR_NAMESPACE::vectorized_tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=16, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=16 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:   51.82%  34.3956s     14998  2.2933ms  4.4080us  214.37ms  cudaEventSynchronize
                   12.84%  8.52411s      4446  1.9173ms  583.80us  407.63ms  cuModuleLoadData
                   12.18%  8.08404s       118  68.509ms  57.522ms  149.13ms  cuLinkAddData
                    7.27%  4.82696s       238  20.281ms     346ns  1.25745s  cudaFree
                    4.80%  3.18468s      5964  533.98us  2.7570us  32.859ms  cuModuleUnload
                    4.05%  2.68526s    162495  16.525us  3.8590us  960.01ms  cudaLaunchKernel
                    3.19%  2.11759s       542  3.9070ms  1.0230us  260.14ms  cuStreamSynchronize
                    1.89%  1.25702s        28  44.894ms  276.71us  170.26ms  cuEventSynchronize
                    0.41%  275.09ms       161  1.7087ms  13.936us  22.971ms  cuMemcpyDtoHAsync
                    0.31%  203.95ms       288  708.15us  3.3110us  46.498ms  cudaMemcpyAsync
                    0.18%  122.50ms     14998  8.1670us  1.8920us  109.82us  cudaStreamAddCallback
                    0.15%  102.60ms       713  143.90us  137.51us  287.70us  cudaGetDeviceProperties
                    0.13%  88.427ms     31023  2.8500us     508ns  497.52us  cudaEventRecord
                    0.12%  82.689ms      9883  8.3660us     287ns  194.00us  cudaDeviceGetAttribute
                    0.08%  56.330ms      9257  6.0850us  2.0920us  161.42us  cudaMemsetAsync
                    0.08%  54.575ms       294  185.63us  5.2670us  5.8623ms  cuMemcpyHtoDAsync
                    0.08%  49.803ms      5318  9.3640us  4.5130us  30.794us  cuLaunchKernel
                    0.07%  46.590ms     14998  3.1060us  2.0130us  495.74us  cudaEventElapsedTime
                    0.07%  43.236ms    235844     183ns     121ns  510.35us  cudaGetLastError
                    0.05%  35.594ms        68  523.44us     171ns  34.938ms  cudaMemcpy
                    0.03%  22.828ms     35328     646ns     441ns  192.45us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    0.03%  21.778ms     31324     695ns     527ns  17.522us  cudaStreamWaitEvent
                    0.03%  17.399ms        57  305.25us  4.7630us  16.611ms  cuMemAlloc
                    0.02%  11.781ms      4281  2.7520us  1.0260us  157.63us  cudaStreamSynchronize
                    0.01%  9.6949ms       118  82.160us  75.339us  103.64us  cuLinkComplete
                    0.01%  9.6055ms       181  53.068us  3.2270us  830.97us  cudaMalloc
                    0.01%  7.2981ms     10292     709ns     377ns  165.53us  cudaFuncSetAttribute
                    0.01%  5.6863ms       118  48.188us  39.951us  74.885us  cuLinkCreate
                    0.01%  4.3680ms        19  229.89us  91.147us  371.00us  cuDeviceTotalMem
                    0.01%  4.3605ms        56  77.866us  51.860us  259.81us  cuModuleLoadFatBinary
                    0.01%  3.9355ms         3  1.3118ms  991.57us  1.8276ms  cuMemHostAlloc
                    0.00%  3.0566ms      1167  2.6190us     141ns  89.568us  cuDeviceGetAttribute
                    0.00%  2.9836ms      4502     662ns     399ns  116.36us  cuModuleGetFunction
                    0.00%  2.1709ms        15  144.72us  14.527us  937.68us  cudaHostAlloc
                    0.00%  1.7807ms      4910     362ns     157ns  11.342us  cuCtxSetCurrent
                    0.00%  1.5919ms       120  13.266us  1.7330us  363.29us  cudaStreamCreateWithFlags
                    0.00%  1.2460ms       694  1.7950us     630ns  13.843us  cuEventQuery
                    0.00%  1.0795ms       898  1.2020us     408ns  11.217us  cuEventRecord
                    0.00%  858.60us        60  14.309us  1.7440us  342.38us  cudaStreamCreateWithPriority
                    0.00%  632.74us       893     708ns     424ns  2.5250us  cudaEventCreateWithFlags
                    0.00%  584.63us        80  7.3070us  3.5790us  33.152us  cuMemsetD32Async
                    0.00%  547.02us         9  60.779us  11.193us  399.65us  cudaFreeHost
                    0.00%  506.23us       108  4.6870us  2.9800us  39.526us  cudaStreamDestroy
                    0.00%  442.21us        19  23.274us  13.233us  46.888us  cuDeviceGetName
                    0.00%  438.05us       421  1.0400us     634ns  2.5720us  cuStreamWaitEvent
                    0.00%  405.70us        29  13.989us  10.376us  25.856us  cudaMemcpyToSymbol
                    0.00%  402.64us       526     765ns     417ns  4.6600us  cudaEventDestroy
                    0.00%  383.78us       769     499ns     352ns  4.2110us  cudaGetDevice
                    0.00%  310.73us        56  5.5480us  4.1220us  11.201us  cuMemFree
                    0.00%  207.93us        76  2.7350us  1.3550us  4.8180us  cudaEventCreate
                    0.00%  134.62us        72  1.8690us  1.2000us  3.6960us  cudaDeviceSynchronize
                    0.00%  104.02us       627     165ns     133ns  1.3410us  cudaGetDeviceCount
                    0.00%  95.070us       611     155ns     118ns  1.3330us  cudaRuntimeGetVersion
                    0.00%  69.838us       118     591ns     461ns     978ns  cuLinkDestroy
                    0.00%  55.672us        61     912ns     325ns  6.6950us  cuEventCreate
                    0.00%  53.430us        28  1.9080us  1.1870us  3.8210us  cuEventElapsedTime
                    0.00%  44.714us         1  44.714us  44.714us  44.714us  cuMemGetInfo
                    0.00%  37.711us        56     673ns     264ns  3.3160us  cuEventDestroy
                    0.00%  29.890us       112     266ns     186ns     448ns  cuFuncGetAttribute
                    0.00%  29.424us        10  2.9420us  2.6200us  3.5650us  cuInit
                    0.00%  28.085us         4  7.0210us  1.8010us  21.998us  cuStreamCreate
                    0.00%  25.161us         1  25.161us  25.161us  25.161us  cuMemsetD32
                    0.00%  16.540us        16  1.0330us     721ns  2.7180us  cudaDeviceGetStreamPriorityRange
                    0.00%  14.814us         9  1.6460us  1.0850us  3.0570us  cuDeviceGetPCIBusId
                    0.00%  14.704us        15     980ns     833ns  1.4040us  cudaHostGetDevicePointer
                    0.00%  9.6090us        19     505ns     175ns  1.3260us  cuDriverGetVersion
                    0.00%  9.2040us        22     418ns     195ns  1.2720us  cuDeviceGet
                    0.00%  7.2490us        17     426ns     162ns  1.1040us  cuDeviceGetCount
                    0.00%  6.1350us         9     681ns     538ns     984ns  cuDevicePrimaryCtxRelease
                    0.00%  4.7420us         2  2.3710us  2.3220us  2.4200us  cudaSetDevice
                    0.00%  3.3360us        10     333ns     283ns     440ns  cuDeviceGetUuid
                    0.00%  2.0620us         6     343ns     254ns     478ns  cudaPeekAtLastError
                    0.00%     880ns         1     880ns     880ns     880ns  cuDevicePrimaryCtxGetState
                    0.00%     342ns         1     342ns     342ns     342ns  cuDevicePrimaryCtxRetain
                    0.00%     223ns         1     223ns     223ns     223ns  cuCtxGetDevice
                    0.00%     218ns         1     218ns     218ns     218ns  cuCtxGetCurrent

==24337== NVTX result:
==24337==   Thread "<unnamed>" (id = 3355440896)
==24337==     Domain "TensorRT"
==24337==       Range "ExecutionContext::enqueue"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  23.938ms        36  664.96us  299.58us  1.7261ms  ExecutionContext::enqueue
 GPU activities:   16.53%  84.252ms       252  334.33us  7.5840us  1.7796ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   16.17%  82.415ms        18  4.5786ms  2.8781ms  5.7543ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   11.15%  56.861ms       144  394.86us  6.3680us  2.7792ms  generatedNativePointwise
                    8.46%  43.127ms        27  1.5973ms  792.43us  2.2292ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    6.57%  33.470ms       270  123.96us  2.7840us  1.2329ms  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    6.41%  32.700ms        36  908.33us  380.86us  1.7949ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    5.04%  25.693ms        27  951.60us  7.6800us  2.6888ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    4.54%  23.131ms       135  171.34us  4.3520us  1.0961ms  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    3.69%  18.835ms        27  697.58us  438.52us  1.1089ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, bool=1>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    3.37%  17.173ms         9  1.9081ms  1.8982ms  1.9209ms  void cuInt8::nhwcTonchw<float, int=32, int=32, int=2>(__half const *, float*, int, int, int, int, int, int)
                    3.19%  16.281ms         9  1.8089ms  1.6032ms  1.9031ms  void implicit_convolveNd_sgemm<__half, int=3, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_convNd_params, __int64, int, float, float, int, __half const *, __half const *)
                    2.81%  14.339ms        63  227.60us  5.3110us  636.98us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    2.43%  12.390ms        18  688.35us  92.287us  1.2856ms  void cuPoolingNd::pooling_NCDHW<float>(float const *, cuPoolingNd::pooling_NCDHW<float>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<float>*PoolingParameters, cuPoolingNd::pooling_NCDHW<float>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<float>*rt, cuPoolingNd::pooling_NCDHW<float>*rt)
                    2.37%  12.107ms         9  1.3452ms  1.2958ms  1.3684ms  void cuInt8::nchwTonhwc<__half, int=32, int=32, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
                    2.36%  12.054ms        45  267.86us  29.632us  567.45us  void genericReformat::copyPackedKernel<float, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    1.20%  6.0955ms        18  338.64us  129.85us  551.48us  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<float, float>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    1.02%  5.1817ms        18  287.87us  187.13us  403.16us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.90%  4.5655ms         9  507.27us  506.46us  508.31us  void cuInt8::nchwTonchw<float, __half, int=8>(float const *, __half*, int, int, int, float const *, float const , cuInt8::ReducedDivisorParameters)
                    0.68%  3.4854ms        45  77.453us  14.464us  253.69us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.64%  3.2856ms         9  365.07us  349.98us  375.29us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    0.39%  1.9874ms        18  110.41us  12.991us  211.23us  void cuPoolingNd::pooling_NCDHW<__half>(__half const *, cuPoolingNd::pooling_NCDHW<__half>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<__half>*PoolingParameters, cuPoolingNd::pooling_NCDHW<__half>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<__half>*rt, cuPoolingNd::pooling_NCDHW<__half>*rt)
                    0.04%  184.44us         9  20.493us  16.863us  21.983us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                    0.02%  124.77us         9  13.863us  11.808us  14.784us  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<__half, long>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
                    0.01%  48.991us        27  1.8140us  1.5040us  2.0160us  void cuInt8::nchwTonhwc<__half, int=32, int=4, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
      API calls:   88.55%  8.1766ms      1107  7.3860us  4.6130us  30.017us  cudaLaunchKernel
                   11.45%  1.0569ms       144  7.3390us  5.1660us  13.585us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d/BiasAdd-sum + StatefulPartitionedCall/model/conv3d/Relu-activation, StatefulPartitionedCall/model/batch_normalization/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  128.37us         9  14.262us  9.8720us  20.906us  PWN(PWN(StatefulPartitionedCall/model/conv3d/BiasAdd-sum + StatefulPartitionedCall/model/conv3d/Relu-activation, StatefulPartitionedCall/model/batch_normalization/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization/batchnorm/add_1)
 GPU activities:  100.00%  23.786ms         9  2.6428ms  2.3446ms  2.7792ms  generatedNativePointwise
      API calls:  100.00%  82.519us         9  9.1680us  6.5350us  13.585us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_1/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_1/Relu-activation, StatefulPartitionedCall/model/batch_normalization_1/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_1/batchnorm/add_1) input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  609.71us        54  11.290us  7.7580us  18.060us  PWN(PWN(StatefulPartitionedCall/model/conv3d_1/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_1/Relu-activation, StatefulPartitionedCall/model/batch_normalization_1/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_1/batchnorm/add_1) input reformatter 0
 GPU activities:   40.27%  17.173ms         9  1.9081ms  1.8982ms  1.9209ms  void cuInt8::nhwcTonchw<float, int=32, int=32, int=2>(__half const *, float*, int, int, int, int, int, int)
                   31.23%  13.318ms         9  1.4798ms  1.4268ms  1.5181ms  generatedNativePointwise
                   28.39%  12.107ms         9  1.3452ms  1.2958ms  1.3684ms  void cuInt8::nchwTonhwc<__half, int=32, int=32, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
                    0.11%  48.991us        27  1.8140us  1.5040us  2.0160us  void cuInt8::nchwTonhwc<__half, int=32, int=4, int=2>(__half const *, __half*, int, int, int, int, int, int, int, int)
      API calls:   80.89%  316.58us        45  7.0350us  5.1140us  10.294us  cudaLaunchKernel
                   19.11%  74.794us         9  8.3100us  5.8880us  12.427us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_10/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_10/Relu-activation, StatefulPartitionedCall/model/batch_normalization_10/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_10/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  95.393us         9  10.599us  9.1720us  11.891us  PWN(PWN(StatefulPartitionedCall/model/conv3d_10/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_10/Relu-activation, StatefulPartitionedCall/model/batch_normalization_10/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_10/batchnorm/add_1)
 GPU activities:  100.00%  155.13us         9  17.236us  14.752us  18.687us  generatedNativePointwise
      API calls:  100.00%  65.696us         9  7.2990us  6.4000us  8.4490us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_11/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_11/Relu-activation, StatefulPartitionedCall/model/batch_normalization_11/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_11/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  222.03us        18  12.334us  7.6140us  16.888us  PWN(PWN(StatefulPartitionedCall/model/conv3d_11/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_11/Relu-activation, StatefulPartitionedCall/model/batch_normalization_11/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_11/batchnorm/add_1)
 GPU activities:   66.57%  298.33us         9  33.147us  32.383us  34.111us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   33.43%  149.82us         9  16.647us  13.664us  18.016us  generatedNativePointwise
      API calls:   53.41%  65.364us         9  7.2620us  6.5620us  8.1030us  cudaLaunchKernel
                   46.59%  57.014us         9  6.3340us  5.1880us  7.2000us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_12/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_12/Relu-activation, StatefulPartitionedCall/model/batch_normalization_12/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_12/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  92.624us         9  10.291us  8.9260us  12.367us  PWN(PWN(StatefulPartitionedCall/model/conv3d_12/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_12/Relu-activation, StatefulPartitionedCall/model/batch_normalization_12/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_12/batchnorm/add_1)
 GPU activities:  100.00%  728.95us         9  80.994us  71.391us  90.142us  generatedNativePointwise
      API calls:  100.00%  61.369us         9  6.8180us  6.0760us  7.8450us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_13/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_13/Relu-activation, StatefulPartitionedCall/model/batch_normalization_13/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_13/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  226.70us        18  12.594us  7.9120us  19.983us  PWN(PWN(StatefulPartitionedCall/model/conv3d_13/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_13/Relu-activation, StatefulPartitionedCall/model/batch_normalization_13/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_13/batchnorm/add_1)
 GPU activities:   62.52%  1.2532ms         9  139.25us  136.96us  141.47us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   37.48%  751.19us         9  83.465us  71.359us  92.479us  generatedNativePointwise
      API calls:   53.29%  66.925us         9  7.4360us  6.8190us  9.7540us  cudaLaunchKernel
                   46.71%  58.664us         9  6.5180us  5.5810us  7.6150us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_14/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_14/Relu-activation, StatefulPartitionedCall/model/batch_normalization_14/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_14/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  102.21us         9  11.356us  9.7000us  13.288us  PWN(PWN(StatefulPartitionedCall/model/conv3d_14/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_14/Relu-activation, StatefulPartitionedCall/model/batch_normalization_14/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_14/batchnorm/add_1)
 GPU activities:  100.00%  4.2926ms         9  476.96us  355.90us  502.90us  generatedNativePointwise
      API calls:  100.00%  71.897us         9  7.9880us  6.5060us  9.8630us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_15/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_15/Relu-activation, StatefulPartitionedCall/model/batch_normalization_15/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_15/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  223.56us        18  12.419us  7.8150us  16.334us  PWN(PWN(StatefulPartitionedCall/model/conv3d_15/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_15/Relu-activation, StatefulPartitionedCall/model/batch_normalization_15/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_15/batchnorm/add_1)
 GPU activities:   56.17%  5.5553ms         9  617.26us  612.34us  623.67us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   43.83%  4.3348ms         9  481.64us  355.80us  514.33us  generatedNativePointwise
      API calls:   50.29%  62.424us         9  6.9360us  6.5180us  7.3700us  cudaLaunchKernel
                   49.71%  61.711us         9  6.8560us  5.6470us  7.7550us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_2/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_2/Relu-activation, StatefulPartitionedCall/model/batch_normalization_2/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_2/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  100.80us         9  11.199us  8.9750us  16.912us  PWN(PWN(StatefulPartitionedCall/model/conv3d_2/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_2/Relu-activation, StatefulPartitionedCall/model/batch_normalization_2/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_2/batchnorm/add_1)
 GPU activities:  100.00%  3.7338ms         9  414.86us  387.42us  439.99us  generatedNativePointwise
      API calls:  100.00%  69.263us         9  7.6950us  5.9160us  11.956us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_3/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_3/Relu-activation, StatefulPartitionedCall/model/batch_normalization_3/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_3/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  251.37us        18  13.964us  7.7130us  19.801us  PWN(PWN(StatefulPartitionedCall/model/conv3d_3/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_3/Relu-activation, StatefulPartitionedCall/model/batch_normalization_3/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_3/batchnorm/add_1)
 GPU activities:   60.02%  5.6371ms         9  626.34us  618.42us  636.98us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   39.98%  3.7552ms         9  417.24us  386.94us  440.06us  generatedNativePointwise
      API calls:   55.24%  78.518us         9  8.7240us  6.7670us  10.163us  cudaLaunchKernel
                   44.76%  63.613us         9  7.0680us  5.1660us  12.939us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_4/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_4/Relu-activation, StatefulPartitionedCall/model/batch_normalization_4/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_4/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  92.180us         9  10.242us  8.3740us  16.948us  PWN(PWN(StatefulPartitionedCall/model/conv3d_4/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_4/Relu-activation, StatefulPartitionedCall/model/batch_normalization_4/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_4/batchnorm/add_1)
 GPU activities:  100.00%  703.03us         9  78.114us  73.759us  80.638us  generatedNativePointwise
      API calls:  100.00%  63.500us         9  7.0550us  5.8480us  11.810us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_5/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_5/Relu-activation, StatefulPartitionedCall/model/batch_normalization_5/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_5/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  228.87us        18  12.714us  8.3430us  17.225us  PWN(PWN(StatefulPartitionedCall/model/conv3d_5/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_5/Relu-activation, StatefulPartitionedCall/model/batch_normalization_5/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_5/batchnorm/add_1)
 GPU activities:   64.01%  1.2501ms         9  138.90us  137.63us  140.86us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   35.99%  702.87us         9  78.096us  73.887us  80.863us  generatedNativePointwise
      API calls:   51.41%  67.607us         9  7.5110us  5.9480us  12.467us  cuLaunchKernel
                   48.59%  63.899us         9  7.0990us  6.2500us  8.1550us  cudaLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_6/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_6/Relu-activation, StatefulPartitionedCall/model/batch_normalization_6/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_6/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  94.640us         9  10.515us  8.7760us  16.016us  PWN(PWN(StatefulPartitionedCall/model/conv3d_6/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_6/Relu-activation, StatefulPartitionedCall/model/batch_normalization_6/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_6/batchnorm/add_1)
 GPU activities:  100.00%  158.33us         9  17.592us  17.056us  18.688us  generatedNativePointwise
      API calls:  100.00%  67.214us         9  7.4680us  6.0040us  12.845us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_7/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_7/Relu-activation, StatefulPartitionedCall/model/batch_normalization_7/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_7/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  222.72us        18  12.373us  8.6180us  15.300us  PWN(PWN(StatefulPartitionedCall/model/conv3d_7/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_7/Relu-activation, StatefulPartitionedCall/model/batch_normalization_7/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_7/batchnorm/add_1)
 GPU activities:   65.12%  295.84us         9  32.870us  32.191us  33.951us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
                   34.88%  158.43us         9  17.603us  16.991us  18.560us  generatedNativePointwise
      API calls:   50.45%  65.004us         9  7.2220us  5.8600us  11.063us  cuLaunchKernel
                   49.55%  63.839us         9  7.0930us  6.4670us  7.5330us  cudaLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_8/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_8/Relu-activation, StatefulPartitionedCall/model/batch_normalization_8/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_8/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  94.988us         9  10.554us  8.5160us  16.422us  PWN(PWN(StatefulPartitionedCall/model/conv3d_8/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_8/Relu-activation, StatefulPartitionedCall/model/batch_normalization_8/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_8/batchnorm/add_1)
 GPU activities:  100.00%  59.071us         9  6.5630us  6.3680us  6.9440us  generatedNativePointwise
      API calls:  100.00%  64.767us         9  7.1960us  6.0050us  11.496us  cuLaunchKernel

==24337==       Range "PWN(PWN(StatefulPartitionedCall/model/conv3d_9/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_9/Relu-activation, StatefulPartitionedCall/model/batch_normalization_9/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_9/batchnorm/add_1)"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  87.243us         9  9.6930us  8.1440us  13.392us  PWN(PWN(StatefulPartitionedCall/model/conv3d_9/BiasAdd-sum + StatefulPartitionedCall/model/conv3d_9/Relu-activation, StatefulPartitionedCall/model/batch_normalization_9/batchnorm/mul_1), StatefulPartitionedCall/model/batch_normalization_9/batchnorm/add_1)
 GPU activities:  100.00%  73.663us         9  8.1840us  7.8720us  8.3840us  generatedNativePointwise
      API calls:  100.00%  62.222us         9  6.9130us  5.7300us  10.566us  cuLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  579.67us         9  64.407us  43.691us  81.338us  StatefulPartitionedCall/model/conv3d/Conv3D-conv
 GPU activities:  100.00%  16.281ms         9  1.8089ms  1.6032ms  1.9031ms  void implicit_convolveNd_sgemm<__half, int=3, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_convNd_params, __int64, int, float, float, int, __half const *, __half const *)
      API calls:  100.00%  135.11us         9  15.011us  11.793us  22.385us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d/Conv3D-conv input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  415.20us         9  46.133us  33.491us  57.898us  StatefulPartitionedCall/model/conv3d/Conv3D-conv input reformatter 0
 GPU activities:  100.00%  509.85us         9  56.649us  55.807us  57.599us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  212.18us         9  23.575us  18.249us  30.017us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  229.52us         9  25.502us  19.568us  36.756us  StatefulPartitionedCall/model/conv3d/Conv3D-to_NDHWC
 GPU activities:  100.00%  14.207ms         9  1.5786ms  1.5043ms  1.6091ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  109.25us         9  12.139us  7.8810us  24.895us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_1/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.0041ms         9  111.57us  85.108us  135.89us  StatefulPartitionedCall/model/conv3d_1/Conv3D-conv
 GPU activities:   70.40%  49.362ms         9  5.4846ms  4.9387ms  5.7543ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   15.64%  10.966ms        18  609.24us  2.7840us  1.2329ms  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                   13.96%  9.7910ms         9  1.0879ms  1.0856ms  1.0961ms  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  304.51us        36  8.4580us  4.8990us  12.264us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_1/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  142.66us         9  15.851us  13.648us  26.628us  StatefulPartitionedCall/model/conv3d_1/Conv3D-to_NCDHW
 GPU activities:  100.00%  14.871ms         9  1.6523ms  1.5332ms  1.7796ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  71.828us         9  7.9800us  6.1760us  18.635us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_1/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  147.58us         9  16.397us  15.112us  17.785us  StatefulPartitionedCall/model/conv3d_1/Conv3D-to_NDHWC
 GPU activities:  100.00%  13.943ms         9  1.5492ms  1.5094ms  1.5767ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  65.597us         9  7.2880us  6.5290us  8.0040us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_10/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  987.99us         9  109.78us  82.177us  227.57us  StatefulPartitionedCall/model/conv3d_10/Conv3D-conv
 GPU activities:   90.16%  9.2670ms         9  1.0297ms  868.72us  1.1089ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, bool=1>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    8.56%  879.41us        18  48.855us  33.887us  64.255us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    1.29%  132.22us         9  14.691us  13.663us  15.360us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  277.29us        36  7.7020us  4.7730us  13.977us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_10/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  145.61us         9  16.178us  14.509us  18.209us  StatefulPartitionedCall/model/conv3d_10/Conv3D-to_NCDHW
 GPU activities:  100.00%  470.52us         9  52.279us  47.967us  55.007us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  67.684us         9  7.5200us  6.3850us  8.7590us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_10/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  141.37us         9  15.707us  14.837us  19.200us  StatefulPartitionedCall/model/conv3d_10/Conv3D-to_NDHWC
 GPU activities:  100.00%  217.73us         9  24.191us  20.096us  26.016us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  61.967us         9  6.8850us  6.4560us  7.6390us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_11/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  589.99us         9  65.554us  61.921us  74.770us  StatefulPartitionedCall/model/conv3d_11/Conv3D-conv
 GPU activities:   89.55%  4.7590ms         9  528.78us  438.52us  566.10us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, bool=1>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    7.99%  424.47us        18  23.581us  12.928us  33.119us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    2.46%  130.81us         9  14.534us  13.632us  15.040us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  218.53us        36  6.0700us  4.7720us  8.1880us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_11/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  113.62us         9  12.624us  12.084us  13.340us  StatefulPartitionedCall/model/conv3d_11/Conv3D-to_NCDHW
 GPU activities:  100.00%  206.05us         9  22.893us  18.975us  24.416us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  54.610us         9  6.0670us  5.7030us  6.4430us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_11/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  143.08us         9  15.898us  13.356us  31.708us  StatefulPartitionedCall/model/conv3d_11/Conv3D-to_NDHWC
 GPU activities:  100.00%  216.54us         9  24.059us  20.415us  25.887us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  75.087us         9  8.3430us  6.0530us  23.595us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_12/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  985.78us         9  109.53us  81.880us  212.29us  StatefulPartitionedCall/model/conv3d_12/Conv3D-conv
 GPU activities:   83.16%  14.462ms         9  1.6069ms  1.3492ms  1.7949ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   13.01%  2.2626ms        18  125.70us  15.520us  237.69us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    3.83%  665.20us         9  73.911us  73.630us  74.366us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  275.36us        36  7.6480us  4.9590us  13.719us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_12/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  177.90us         9  19.766us  17.597us  29.901us  StatefulPartitionedCall/model/conv3d_12/Conv3D-to_NCDHW
 GPU activities:  100.00%  1.8055ms         9  200.61us  191.29us  211.04us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  68.676us         9  7.6300us  6.4710us  10.626us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_12/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  151.03us         9  16.781us  15.847us  18.519us  StatefulPartitionedCall/model/conv3d_12/Conv3D-to_NDHWC
 GPU activities:  100.00%  919.44us         9  102.16us  90.110us  112.03us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  62.314us         9  6.9230us  6.6370us  7.4160us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_13/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  585.80us         9  65.088us  61.269us  72.220us  StatefulPartitionedCall/model/conv3d_13/Conv3D-conv
 GPU activities:   81.58%  7.4431ms         9  827.01us  674.96us  914.80us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   11.00%  1.0035ms        18  55.751us  8.2880us  103.46us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    7.42%  677.46us         9  75.273us  74.847us  75.774us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  218.21us        36  6.0610us  4.6130us  8.2240us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_13/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  116.41us         9  12.934us  12.596us  13.396us  StatefulPartitionedCall/model/conv3d_13/Conv3D-to_NCDHW
 GPU activities:  100.00%  872.15us         9  96.905us  89.567us  103.87us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  55.914us         9  6.2120us  5.8010us  6.5240us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_13/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  127.57us         9  14.173us  13.575us  15.248us  StatefulPartitionedCall/model/conv3d_13/Conv3D-to_NDHWC
 GPU activities:  100.00%  930.45us         9  103.38us  90.399us  110.17us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  59.330us         9  6.5920us  6.1600us  7.3390us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_14/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  791.54us         9  87.948us  80.447us  113.02us  StatefulPartitionedCall/model/conv3d_14/Conv3D-conv
 GPU activities:   77.48%  33.053ms         9  3.6726ms  2.8781ms  3.9569ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   16.70%  7.1245ms        18  395.80us  5.6960us  791.86us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    5.82%  2.4808ms         9  275.65us  274.49us  281.85us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  260.90us        36  7.2470us  4.8080us  11.833us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_14/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  168.42us         9  18.713us  17.399us  23.325us  StatefulPartitionedCall/model/conv3d_14/Conv3D-to_NCDHW
 GPU activities:  100.00%  7.2228ms         9  802.53us  771.28us  838.87us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  64.880us         9  7.2080us  6.4480us  10.178us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_14/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  147.35us         9  16.371us  15.378us  17.873us  StatefulPartitionedCall/model/conv3d_14/Conv3D-to_NDHWC
 GPU activities:  100.00%  3.7680ms         9  418.66us  367.71us  435.03us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  59.701us         9  6.6330us  6.3890us  6.9930us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_15/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  632.57us         9  70.285us  67.971us  76.807us  StatefulPartitionedCall/model/conv3d_15/Conv3D-conv
 GPU activities:   78.04%  19.043ms         9  2.1159ms  1.5937ms  2.2292ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   11.73%  2.8636ms        18  159.09us  3.7440us  316.67us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                   10.23%  2.4962ms         9  277.36us  276.06us  283.74us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  238.30us        36  6.6190us  4.6850us  9.9180us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_15/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  117.23us         9  13.025us  11.985us  13.603us  StatefulPartitionedCall/model/conv3d_15/Conv3D-to_NCDHW
 GPU activities:  100.00%  3.6344ms         9  403.82us  384.19us  414.30us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  55.714us         9  6.1900us  5.5470us  6.7600us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_15/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  127.61us         9  14.178us  13.623us  14.797us  StatefulPartitionedCall/model/conv3d_15/Conv3D-to_NDHWC
 GPU activities:  100.00%  3.7857ms         9  420.64us  357.72us  435.29us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  58.508us         9  6.5000us  6.2660us  6.7340us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_2/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  779.67us         9  86.629us  73.420us  100.46us  StatefulPartitionedCall/model/conv3d_2/Conv3D-conv
 GPU activities:   66.05%  7.6042ms         9  844.91us  792.43us  896.53us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   21.87%  2.5182ms         9  279.80us  278.81us  281.40us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                   12.08%  1.3903ms        18  77.241us  3.2640us  153.69us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  269.62us        36  7.4890us  4.7860us  12.644us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_2/Conv3D-conv input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  137.97us         9  15.329us  13.994us  16.175us  StatefulPartitionedCall/model/conv3d_2/Conv3D-conv input reformatter 0
 GPU activities:  100.00%  2.2558ms         9  250.64us  247.32us  253.69us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  66.864us         9  7.4290us  6.5250us  8.1810us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_2/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  144.88us         9  16.097us  14.475us  18.746us  StatefulPartitionedCall/model/conv3d_2/Conv3D-to_NDHWC
 GPU activities:  100.00%  3.4843ms         9  387.14us  375.58us  398.36us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  64.103us         9  7.1220us  6.3630us  8.1250us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_3/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  610.44us         9  67.826us  61.921us  94.062us  StatefulPartitionedCall/model/conv3d_3/Conv3D-conv
 GPU activities:   75.49%  16.479ms         9  1.8310ms  1.6932ms  1.9355ms  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=256>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=256, int=64, int=32, int=4, int=1, int=1, int=1, int=1>, bool=0>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   13.01%  2.8393ms        18  157.74us  3.9680us  313.02us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                   11.51%  2.5119ms         9  279.10us  278.17us  281.60us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  247.05us        36  6.8620us  4.6760us  22.146us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_3/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  116.17us         9  12.907us  12.449us  13.353us  StatefulPartitionedCall/model/conv3d_3/Conv3D-to_NCDHW
 GPU activities:  100.00%  3.2765ms         9  364.05us  354.78us  377.85us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  55.640us         9  6.1820us  5.8310us  6.4980us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_3/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  128.63us         9  14.292us  13.266us  15.422us  StatefulPartitionedCall/model/conv3d_3/Conv3D-to_NDHWC
 GPU activities:  100.00%  3.4875ms         9  387.50us  374.94us  396.79us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  58.851us         9  6.5390us  6.1310us  7.0020us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_4/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  684.90us         9  76.099us  68.101us  89.306us  StatefulPartitionedCall/model/conv3d_4/Conv3D-conv
 GPU activities:   77.28%  3.6753ms         9  408.36us  380.86us  423.55us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   14.28%  679.16us         9  75.461us  75.327us  75.679us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    8.44%  401.14us        18  22.285us  6.0480us  38.783us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  261.28us        36  7.2570us  4.8200us  12.536us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_4/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  136.91us         9  15.211us  14.144us  18.669us  StatefulPartitionedCall/model/conv3d_4/Conv3D-to_NDHWC
 GPU activities:  100.00%  899.57us         9  99.952us  96.286us  102.82us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  63.288us         9  7.0320us  6.5200us  8.5240us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_5/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  562.57us         9  62.507us  60.034us  71.597us  StatefulPartitionedCall/model/conv3d_5/Conv3D-conv
 GPU activities:   80.87%  7.1191ms         9  791.01us  737.72us  818.80us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=32, int=128>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=128, int=128, int=32, int=2, int=2, int=1, int=1, int=1>, bool=0>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   11.51%  1.0136ms        18  56.311us  8.9280us  107.04us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    7.62%  670.39us         9  74.487us  74.303us  74.782us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  220.20us        36  6.1160us  4.8200us  8.6240us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_5/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  113.98us         9  12.664us  12.205us  13.196us  StatefulPartitionedCall/model/conv3d_5/Conv3D-to_NCDHW
 GPU activities:  100.00%  852.30us         9  94.700us  93.054us  95.934us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  55.407us         9  6.1560us  5.9430us  6.4290us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_5/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  124.86us         9  13.873us  13.400us  14.346us  StatefulPartitionedCall/model/conv3d_5/Conv3D-to_NDHWC
 GPU activities:  100.00%  898.19us         9  99.799us  95.262us  103.23us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  56.749us         9  6.3050us  5.9740us  6.6960us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_6/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  671.89us         9  74.654us  66.929us  91.459us  StatefulPartitionedCall/model/conv3d_6/Conv3D-conv
 GPU activities:   90.03%  3.2856ms         9  365.07us  349.98us  375.29us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=64, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    5.73%  209.08us        18  11.615us  5.8550us  17.632us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    4.24%  154.81us         9  17.201us  16.895us  17.695us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  273.47us        36  7.5960us  4.7870us  21.416us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_6/Conv3D-conv input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  124.74us         9  13.860us  12.663us  14.544us  StatefulPartitionedCall/model/conv3d_6/Conv3D-conv input reformatter 0
 GPU activities:  100.00%  133.31us         9  14.812us  14.464us  15.136us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  63.598us         9  7.0660us  6.1960us  7.5440us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_6/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  131.14us         9  14.570us  14.093us  15.416us  StatefulPartitionedCall/model/conv3d_6/Conv3D-to_NDHWC
 GPU activities:  100.00%  226.33us         9  25.148us  24.384us  26.879us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  60.106us         9  6.6780us  6.3780us  6.9670us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_7/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  638.34us         9  70.926us  63.989us  78.804us  StatefulPartitionedCall/model/conv3d_7/Conv3D-conv
 GPU activities:   90.08%  4.8087ms         9  534.31us  515.38us  563.19us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=256, int=64, int=1, int=4, int=2, int=1, int=1>, bool=1>>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                    7.48%  399.42us        18  22.189us  11.232us  33.024us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    2.44%  130.17us         9  14.463us  14.080us  15.039us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  240.77us        36  6.6870us  4.8160us  9.2840us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_7/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  111.98us         9  12.442us  11.945us  13.043us  StatefulPartitionedCall/model/conv3d_7/Conv3D-to_NCDHW
 GPU activities:  100.00%  204.32us         9  22.701us  21.887us  23.807us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  54.173us         9  6.0190us  5.5900us  6.5470us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_7/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  128.05us         9  14.228us  13.673us  14.907us  StatefulPartitionedCall/model/conv3d_7/Conv3D-to_NDHWC
 GPU activities:  100.00%  225.18us         9  25.020us  24.320us  26.496us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  60.262us         9  6.6950us  6.3990us  7.1580us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_8/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  653.59us         9  72.620us  67.840us  81.021us  StatefulPartitionedCall/model/conv3d_8/Conv3D-conv
 GPU activities:   73.73%  1.7427ms         9  193.64us  187.13us  206.78us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   24.47%  578.36us        18  32.130us  2.8150us  61.535us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    1.80%  42.431us         9  4.7140us  4.3520us  5.0560us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  250.22us        36  6.9500us  4.6550us  14.442us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_8/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  130.48us         9  14.497us  14.258us  14.837us  StatefulPartitionedCall/model/conv3d_8/Conv3D-to_NDHWC
 GPU activities:  100.00%  71.006us         9  7.8890us  7.5840us  8.3830us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  61.043us         9  6.7820us  6.5310us  7.0320us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_9/Conv3D-conv"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  546.43us         9  60.714us  59.211us  62.343us  StatefulPartitionedCall/model/conv3d_9/Conv3D-conv
 GPU activities:   74.71%  3.4390ms         9  382.11us  374.01us  403.16us  void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, bool=0, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=16, xmma_new::Row, int=64, int=64>>, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, int=16, xmma_new::Fragment_c<xmma_new::Turing_hmma_fp32_traits, xmma_new::Cta_tile<xmma_new::Turing, int=64, int=32, int=64, int=1, int=1, int=2, int=1, int=1>, bool=1>, bool=0>, xmma_new::implicit_gemm::Input_related<int=0, int=0, int=0, bool=0>, int=1>>(xmma_new::Turing_hmma_fp32_traitsParams)
                   24.21%  1.1144ms        18  61.913us  3.9040us  120.41us  void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
                    1.09%  49.951us         9  5.5500us  5.2480us  5.8880us  void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)
      API calls:  100.00%  216.30us        36  6.0080us  4.7610us  8.4710us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_9/Conv3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  111.11us         9  12.345us  12.023us  12.697us  StatefulPartitionedCall/model/conv3d_9/Conv3D-to_NCDHW
 GPU activities:  100.00%  71.646us         9  7.9600us  7.8080us  8.3200us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  54.947us         9  6.1050us  5.7120us  6.4520us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_9/Conv3D-to_NDHWC"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  122.12us         9  13.569us  12.639us  14.261us  StatefulPartitionedCall/model/conv3d_9/Conv3D-to_NDHWC
 GPU activities:  100.00%  70.910us         9  7.8780us  7.6800us  8.3510us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  61.447us         9  6.8270us  6.0700us  7.4650us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_9/Conv3D-to_NDHWC input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  135.91us         9  15.101us  14.490us  15.603us  StatefulPartitionedCall/model/conv3d_9/Conv3D-to_NDHWC input reformatter 0
 GPU activities:  100.00%  49.119us         9  5.4570us  5.3110us  5.7280us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  65.545us         9  7.2820us  6.8080us  7.6370us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose/BiasAdd copy"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  173.91us         9  19.323us  15.026us  32.239us  StatefulPartitionedCall/model/conv3d_transpose/BiasAdd copy
 GPU activities:  100.00%  184.44us         9  20.493us  16.863us  21.983us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  80.868us         9  8.9850us  7.2060us  9.9530us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose/BiasAdd-sum"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  128.90us         9  14.322us  10.699us  16.692us  StatefulPartitionedCall/model/conv3d_transpose/BiasAdd-sum
 GPU activities:  100.00%  124.77us         9  13.863us  11.808us  14.784us  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<__half, long>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
      API calls:  100.00%  79.168us         9  8.7960us  6.8520us  11.259us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose/BiasAdd-sum input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  231.31us         9  25.701us  22.328us  39.934us  StatefulPartitionedCall/model/conv3d_transpose/BiasAdd-sum input reformatter 0
 GPU activities:  100.00%  273.72us         9  30.413us  24.927us  31.999us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  95.563us         9  10.618us  8.4140us  23.877us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose_1/BiasAdd copy"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  130.82us         9  14.535us  11.892us  22.862us  StatefulPartitionedCall/model/conv3d_transpose_1/BiasAdd copy
 GPU activities:  100.00%  1.1574ms         9  128.60us  111.65us  140.06us  void genericReformat::copyPackedKernel<float, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
      API calls:  100.00%  75.032us         9  8.3360us  6.5370us  11.895us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose_1/BiasAdd-sum"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  149.12us         9  16.568us  12.131us  33.617us  StatefulPartitionedCall/model/conv3d_transpose_1/BiasAdd-sum
 GPU activities:  100.00%  1.2382ms         9  137.57us  129.85us  139.93us  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<float, float>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
      API calls:  100.00%  101.24us         9  11.249us  7.7100us  26.553us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose_2/BiasAdd copy"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  124.99us         9  13.887us  12.279us  17.500us  StatefulPartitionedCall/model/conv3d_transpose_2/BiasAdd copy
 GPU activities:  100.00%  4.6983ms         9  522.04us  437.85us  563.00us  void genericReformat::copyPackedKernel<float, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
      API calls:  100.00%  73.135us         9  8.1260us  6.7600us  11.114us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/conv3d_transpose_2/BiasAdd-sum"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  135.72us         9  15.080us  12.860us  26.704us  StatefulPartitionedCall/model/conv3d_transpose_2/BiasAdd-sum
 GPU activities:  100.00%  4.8574ms         9  539.71us  531.16us  551.48us  void cuEltwise::eltwise<cuEltwise::SimpleAlgo<float, float>, cuEltwise::Compute<nvinfer1::ElementWiseOperation>>(cuEltwise::LaunchParams)
      API calls:  100.00%  91.254us         9  10.139us  8.2890us  21.203us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d/MaxPool3D-pooling"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  124.94us         9  13.881us  10.794us  18.921us  StatefulPartitionedCall/model/max_pooling3d/MaxPool3D-pooling
 GPU activities:  100.00%  11.558ms         9  1.2842ms  1.2826ms  1.2856ms  void cuPoolingNd::pooling_NCDHW<float>(float const *, cuPoolingNd::pooling_NCDHW<float>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<float>*PoolingParameters, cuPoolingNd::pooling_NCDHW<float>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<float>*rt, cuPoolingNd::pooling_NCDHW<float>*rt)
      API calls:  100.00%  78.597us         9  8.7330us  6.6230us  13.175us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d/MaxPool3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  159.76us         9  17.750us  15.871us  19.411us  StatefulPartitionedCall/model/max_pooling3d/MaxPool3D-to_NCDHW
 GPU activities:  100.00%  24.082ms         9  2.6757ms  2.6534ms  2.6888ms  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  79.399us         9  8.8220us  7.2910us  10.602us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_1/MaxPool3D-pooling"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  108.65us         9  12.072us  9.6550us  17.146us  StatefulPartitionedCall/model/max_pooling3d_1/MaxPool3D-pooling
 GPU activities:  100.00%  1.8658ms         9  207.31us  200.29us  211.23us  void cuPoolingNd::pooling_NCDHW<__half>(__half const *, cuPoolingNd::pooling_NCDHW<__half>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<__half>*PoolingParameters, cuPoolingNd::pooling_NCDHW<__half>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<__half>*rt, cuPoolingNd::pooling_NCDHW<__half>*rt)
      API calls:  100.00%  72.188us         9  8.0200us  6.1270us  12.782us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_1/MaxPool3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  117.09us         9  13.010us  12.323us  13.573us  StatefulPartitionedCall/model/max_pooling3d_1/MaxPool3D-to_NCDHW
 GPU activities:  100.00%  3.2602ms         9  362.25us  357.02us  366.62us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  57.196us         9  6.3550us  5.9600us  6.7330us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_1/MaxPool3D-to_NCDHW input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  105.69us         9  11.743us  10.320us  13.222us  StatefulPartitionedCall/model/max_pooling3d_1/MaxPool3D-to_NCDHW input reformatter 0
 GPU activities:  100.00%  4.5655ms         9  507.27us  506.46us  508.31us  void cuInt8::nchwTonchw<float, __half, int=8>(float const *, __half*, int, int, int, float const *, float const , cuInt8::ReducedDivisorParameters)
      API calls:  100.00%  67.963us         9  7.5510us  6.7530us  8.5100us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_2/MaxPool3D-pooling"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  90.814us         9  10.090us  9.6330us  11.284us  StatefulPartitionedCall/model/max_pooling3d_2/MaxPool3D-pooling
 GPU activities:  100.00%  832.82us         9  92.535us  92.287us  92.798us  void cuPoolingNd::pooling_NCDHW<float>(float const *, cuPoolingNd::pooling_NCDHW<float>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<float>*PoolingParameters, cuPoolingNd::pooling_NCDHW<float>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<float>*rt, cuPoolingNd::pooling_NCDHW<float>*rt)
      API calls:  100.00%  59.516us         9  6.6120us  6.2290us  7.4070us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_2/MaxPool3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  128.66us         9  14.295us  13.592us  15.060us  StatefulPartitionedCall/model/max_pooling3d_2/MaxPool3D-to_NCDHW
 GPU activities:  100.00%  1.5406ms         9  171.18us  168.35us  172.67us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, float, float, float, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  67.024us         9  7.4470us  6.9150us  8.2510us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_3/MaxPool3D-pooling"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  97.934us         9  10.881us  9.8100us  12.252us  StatefulPartitionedCall/model/max_pooling3d_3/MaxPool3D-pooling
 GPU activities:  100.00%  121.66us         9  13.518us  12.991us  14.304us  void cuPoolingNd::pooling_NCDHW<__half>(__half const *, cuPoolingNd::pooling_NCDHW<__half>*, int, int, nvinfer1::Dims, nvinfer1, cuPoolingNd::pooling_NCDHW<__half>*PoolingParameters, cuPoolingNd::pooling_NCDHW<__half>*rt::reduced_divisor, cuPoolingNd::pooling_NCDHW<__half>*rt, cuPoolingNd::pooling_NCDHW<__half>*rt)
      API calls:  100.00%  63.076us         9  7.0080us  6.2000us  7.5690us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_3/MaxPool3D-to_NCDHW"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  110.89us         9  12.321us  11.849us  13.043us  StatefulPartitionedCall/model/max_pooling3d_3/MaxPool3D-to_NCDHW
 GPU activities:  100.00%  224.64us         9  24.959us  24.256us  26.176us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=2, int=32, unsigned int=256, unsigned int=1, unsigned int=1, unsigned int=0, unsigned int=2, unsigned int=1, unsigned int=0, unsigned int=2>, __half, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=1, int=32 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=256 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  55.036us         9  6.1150us  5.7070us  6.6460us  cudaLaunchKernel

==24337==       Range "StatefulPartitionedCall/model/max_pooling3d_3/MaxPool3D-to_NCDHW input reformatter 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  117.74us         9  13.082us  12.447us  13.852us  StatefulPartitionedCall/model/max_pooling3d_3/MaxPool3D-to_NCDHW input reformatter 0
 GPU activities:  100.00%  312.76us         9  34.751us  34.175us  35.199us  void CUTENSOR_NAMESPACE::tensor_elementwise_kernel<CUTENSOR_NAMESPACE::pw_config_t<unsigned int=1, int=256, unsigned int=64, unsigned int=1, unsigned int=0, unsigned int=1, unsigned int=2, unsigned int=0, unsigned int=1, unsigned int=2>, float, float, __half, float, bool=1, cutensorOperator_t=1, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t, cutensorOperator_t>(CUTENSOR_NAMESPACE::pw_params_t, int, int, unsigned int=0, int=256 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=64 const *, CUTENSOR_NAMESPACE::pw_params_t, unsigned int=1 const *, unsigned int=64 const **, cutensorOperator_t, void const *, cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const , cutensorOperator_t, void const )
      API calls:  100.00%  59.678us         9  6.6300us  6.2370us  7.0870us  cudaLaunchKernel

==24337==       Range "TensorRTInputPH_1 copy"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  289.34us        27  10.716us  8.1210us  16.888us  TensorRTInputPH_1 copy
 GPU activities:  100.00%  6.1981ms        27  229.56us  29.632us  567.45us  void genericReformat::copyPackedKernel<float, __half, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
      API calls:  100.00%  190.70us        27  7.0620us  5.3270us  11.111us  cudaLaunchKernel

==24337==       Range "_tftrt_constant_-0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  42.120us        36  1.1700us     325ns  2.6550us  _tftrt_constant_-0
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-1"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  11.269us        36     313ns     197ns     522ns  _tftrt_constant_-1
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-10"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.8240us         9     202ns     153ns     278ns  _tftrt_constant_-10
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-11"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.7050us         9     189ns     156ns     285ns  _tftrt_constant_-11
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-12"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.3130us         9     257ns     213ns     296ns  _tftrt_constant_-12
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-13"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.0880us         9     232ns     168ns     417ns  _tftrt_constant_-13
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-14"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.7770us         9     197ns     152ns     285ns  _tftrt_constant_-14
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-15"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.1850us         9     242ns     196ns     317ns  _tftrt_constant_-15
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-16"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.4630us         9     162ns     153ns     183ns  _tftrt_constant_-16
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-17"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.5910us         9     176ns     153ns     275ns  _tftrt_constant_-17
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-18"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.3380us         9     259ns     218ns     298ns  _tftrt_constant_-18
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-19"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.1890us         9     243ns     153ns     307ns  _tftrt_constant_-19
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-2"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  8.8330us        36     245ns     153ns     586ns  _tftrt_constant_-2
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-20"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.0390us         9     226ns     155ns     328ns  _tftrt_constant_-20
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-21"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.2400us         9     248ns     204ns     313ns  _tftrt_constant_-21
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-22"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.0620us         9     229ns     156ns     280ns  _tftrt_constant_-22
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-23"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.0350us         9     226ns     159ns     279ns  _tftrt_constant_-23
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-24"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.4700us         9     274ns     227ns     376ns  _tftrt_constant_-24
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-25"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.0460us         9     227ns     155ns     311ns  _tftrt_constant_-25
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-26"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.7830us         9     198ns     153ns     275ns  _tftrt_constant_-26
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-27"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.3430us         9     260ns     223ns     333ns  _tftrt_constant_-27
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-28"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.9580us         9     217ns     156ns     280ns  _tftrt_constant_-28
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-29"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.0580us         9     228ns     157ns     280ns  _tftrt_constant_-29
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-3"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  9.1380us        36     253ns     156ns     540ns  _tftrt_constant_-3
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-4"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  9.2270us        36     256ns     192ns     447ns  _tftrt_constant_-4
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-5"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  7.2660us        36     201ns     153ns     290ns  _tftrt_constant_-5
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-6"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  9.2930us        36     258ns     164ns     596ns  _tftrt_constant_-6
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-7"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.2880us         9     254ns     187ns     310ns  _tftrt_constant_-7
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-8"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.2650us         9     251ns     170ns     309ns  _tftrt_constant_-8
No kernels were profiled in this range.
No API activities were profiled in this range.

==24337==       Range "_tftrt_constant_-9"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.1690us         9     241ns     220ns     318ns  _tftrt_constant_-9
No kernels were profiled in this range.
No API activities were profiled in this range.

======== Error: Application returned non-zero code 1
